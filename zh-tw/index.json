


[{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/ai/","section":"Categories","summary":"","title":"AI","type":"categories"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/gemini/","section":"Tags","summary":"","title":"Gemini","type":"tags"},{"content":"é€™æ˜¯ä¸€ä»½ Googel åœ¨2024å¹´10æœˆé‡å° Gemini æ¨¡å‹ä¸¦å¦‚ä½•æ­£ç¢ºä¸‹ Prompt çš„ä¸€ä»½æ–‡ä»¶ã€‚å› ç‚ºå°æ–¼æ–°æ‰‹ä¾†èªªé€™å°ä¸‹ Prompt ä¹Ÿç®—æ˜¯ä¸€å€‹ä¸éŒ¯çš„æ•™å­¸ï¼\nPromprt ä¸»è¦è€ƒæ…®4å¤§ä¸»è¦è¦ç´  # è§’è‰² (Persona) ä»»å‹™ (Task) ä¸Šä¸‹æ–‡ (Context) é¢¨æ ¼ æˆ– æ ¼å¼ (Format) ç¯„ä¾‹ï¼š\næ‡‰ç”¨4å¤§è¦ç´ ä½¿ â€œgemini åœ¨ Gmail å’Œ Google æ–‡æª”â€ æ•ˆæœæ›´å¥½\nè‹±æ–‡ç‰ˆï¼š\nYou are a program manager in [industry]. Draft an executive summary email to [persona] based on [details about relevant program docs]. Limit to bullet points.\nä¸­æ–‡ç‰ˆï¼š\næ‚¨æ˜¯ [è¡Œæ¥­] çš„é …ç›®ç¶“ç†ã€‚æ ¹æ“š [ç›¸é—œé …ç›®æ–‡æª”çš„è©³ç´°ä¿¡æ¯]ï¼Œç‚º [è§’è‰²] è‰æ“¬ä¸€å°åŸ·è¡Œæ‘˜è¦éƒµä»¶ã€‚é™åˆ¶ä½¿ç”¨é …ç›®ç¬¦è™Ÿã€‚\né€™é‚Šçš„ç¯„ä¾‹,æˆ‘å€‘å¯ä»¥åˆ†æå‡º4å¤§è¦ç´ \nè§’è‰²: You are a program manager in [industry] ä»»å‹™: Draft an executive summary email to ä¸Šä¸‹æ–‡: [persona] based on [details about relevant program docs]. æ ¼å¼: Limit to bullet points. ä½ ä¸ç”¨æ¯æ¬¡ä¸€å®šéœ€è¦é€™4å€‹è¦ç´ åœ¨ä½ çš„ Prompt ä¸­, ä½†ä½¿ç”¨ Promptæ™‚å¸¶æœ‰å…¶ä¸­å¹¾å€‹è¦ç´ æœƒå° LLM æœ‰æ‰€å¹«åŠ©! ä½†è¦è¨˜ä½åœ¨ \u0026ldquo;ä»»å‹™\u0026rdquo; ä¸­ä¸€å®šè¦åŒ…å« \u0026ldquo;å‹•ä½œ\u0026rdquo; æˆ–æ˜¯ \u0026ldquo;å‘½ä»¤\u0026rdquo; é€™æ˜¯ Prompt çµ„æˆä¸­æœ€é‡è¦çš„éƒ¨åˆ†ã€‚\næç¤ºè© # ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¹«åŠ©æ‚¨é–‹å§‹ä½¿ç”¨ Gemini for Google Workspace çš„å¿«é€Ÿæç¤ºï¼š\nUse natural language (ä½¿ç”¨è‡ªç„¶èªè¨€):\nåƒèˆ‡äººäº¤è«‡ä¸€æ¨£å¯«ä½œã€‚ç”¨å®Œæ•´çš„å¥å­è¡¨é”å®Œæ•´çš„æ€æƒ³ã€‚\nBe specific and iterate (å…·é«”åŒ–ä¸¦æŒçºŒç–Šä»£):\nå‘Šè¨´ Gemini æ‚¨éœ€è¦å®ƒåšä»€éº¼ï¼ˆç¸½çµã€æ’°å¯«ã€æ”¹è®Šèªæ°£ã€å‰µå»ºï¼‰ã€‚æä¾›ç›¡å¯èƒ½å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\nBe concise and avoid complexity (ç°¡æ½”èˆ‡é¿å…è¤‡é›œ):\nç”¨ç°¡çŸ­ä½†å…·é«”çš„èªè¨€é™³è¨´ä½ çš„è«‹æ±‚ã€‚é¿å…ä½¿ç”¨å°ˆæ¥­è¡“èª(æˆ–æ˜¯ä¸€äº›æ™‚ä¸‹çš„è©å½™æˆ–æ˜¯ç°¡å¯« ç­‰ç­‰â€¦)ã€‚\nMake it a conversation (å°‡å…¶è¦–ç‚ºå°è©±):\nå¦‚æœçµæœä¸ç¬¦åˆæ‚¨çš„æœŸæœ›ï¼Œæˆ–è€…æ‚¨èªç‚ºæœ‰æ”¹é€²ç©ºé–“ï¼Œè«‹èª¿æ•´æ‚¨çš„æç¤ºè¯ã€‚ä½¿ç”¨å¾ŒçºŒèª¿æ•´çš„ Prompt ä¸¦ å¯©æŸ¥ å’Œ æœ€ä½³åŒ– çš„ç–Šä»£éç¨‹æ¥ç”¢ç”Ÿæ›´å¥½çš„çµæœã€‚\nUse your documents (åˆ©ç”¨ä½ çš„æ–‡ä»¶æª”æ¡ˆ):\nä½¿ç”¨æ‚¨åœ¨ Google Drive ä¸­çš„æ–‡ä»¶è³‡è¨Šæ¥å€‹æ€§åŒ– Gemini çš„è¼¸å‡ºã€‚\nMake Gemini your prompt editor (è®“ Gemini æˆç‚ºæ‚¨çš„Promptç·¨è­¯å™¨):\nåœ¨ä½¿ç”¨ Gemini Advanced æ™‚ï¼Œä»¥å¦‚ä¸‹å…§å®¹é–‹å§‹æ‚¨çš„ Promptï¼šâ€å°‡æ­¤å†…å®¹è½‰åŒ–ç‚ºä¸€å€‹å¼·å¤§çš„æç¤ºè©ï¼š[åœ¨æ­¤è™•å¡«å…¥åŸå§‹ prompt]ã€‚â€ Gemini å°‡é‡å°å¦‚ä½•æ”¹é€²æ‚¨çš„æç¤ºè©æå‡ºå»ºè­°ã€‚ç¢ºä¿å…¶è¡¨é”äº†æ‚¨æ‰€éœ€çš„å†…å®¹ï¼Œç„¶å¾Œå°‡å…¶è¤‡è£½è²¼å› Gemini Advanced ä»¥ç²å–è¼¸å‡ºã€‚\nPrompt æ’°å¯«æ˜¯ä¸€é …å¤§å®¶éƒ½å¯ä»¥å­¸ç¿’çš„æŠ€èƒ½ã€‚æ‚¨ä¸å¿…æ˜¯æç¤ºè©å·¥ç¨‹å¸«æ‰èƒ½ä½¿ç”¨ç”Ÿæˆå¼ AIã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨ä½¿ç”¨ç¬¬ä¸€æ¬¡æ²’æœ‰å¾—åˆ°æœŸæœ›çš„çµæœï¼Œæ‚¨å¯èƒ½éœ€è¦å¤šå˜—è©¦å¹¾ç¨®ä¸åŒçš„æç¤ºè©æ–¹æ³•ã€‚\næ ¹æ“šçµ±è¨ˆæœ€æœ‰æˆæ•ˆçš„ Prompt å¹³å‡ç´„åŒ…å« 21å€‹å–®è©å’Œç›¸é—œçš„ä¸Šä¸‹æ–‡ï¼Œä½†äººå€‘å˜—è©¦çš„æç¤ºè©é€šå¸¸å°‘æ–¼ 9 å€‹å–®è©ã€‚ æå‡æ‚¨æ’°å¯« Prompt æ°´å¹³çš„æ–¹æ³• # Brake it up (åˆ†è§£ä»»å‹™):\nå¦‚æœæ‚¨å¸Œæœ› Gemini for Workspace åŸ·è¡Œå¤šå€‹ç›¸é—œä»»å‹™ï¼Œè«‹å°‡å®ƒå€‘åˆ†è§£ç‚ºå–®ç¨çš„ Promptã€‚\nGive constraints (çµ¦å‡ºé™åˆ¶):\nç‚ºäº†ç”Ÿæˆç‰¹å®šçš„çµæœï¼Œè«‹åœ¨ Prompt ä¸­åŒ…å«è©³ç´°ä¿¡æ¯ï¼Œä¾‹å¦‚å­—ç¬¦æ•°é™åˆ¶æˆ–æ‚¨å¸Œæœ›ç”Ÿæˆçš„é€‰é¡¹æ•°é‡ã€‚\nAssign a role (åˆ†é…è…³è‰²):\nç‚ºäº†é¼“å‹µå‰µé€ åŠ›ï¼Œè«‹åˆ†é…ä¸€å€‹è§’è‰²ã€‚æ‚¨å¯ä»¥é€šéä»¥ä¸‹ Prompt æ¥å¯¦ç¾é€™ä¸€é»ï¼š\nè‹±æ–‡:\nâ€œYou are the head of a creative department for a leading advertising agency â€¦â€\nä¸­æ–‡:\nâ€æ‚¨æ˜¯ä¸€å®¶é ˜å…ˆå»£å‘Šå…¬å¸çš„å‰µæ„éƒ¨é–€è² è²¬äººâ€¦â€¦â€\nAsk for feedback (å°‹æ±‚å›é¥‹):\nåœ¨èˆ‡ Gemini Advanced çš„å°è©±ä¸­ï¼Œå‘Šè¨´å®ƒæ‚¨æ­£åœ¨çµ¦å®ƒä¸€å€‹é …ç›®ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç›¸é—œç´°ç¯€ï¼Œç„¶å¾Œæè¿°æ‚¨æƒ³è¦çš„è¼¸å‡ºã€‚é€šéæå‡º ä¾‹å¦‚: â€œæ‚¨æœ‰ä»€éº¼å•é¡Œå¯ä»¥å¹«åŠ©æ‚¨æä¾›æœ€ä½³è¼¸å‡ºï¼Ÿâ€ ä¹‹é¡çš„å•é¡Œä¾†ç¹¼çºŒå°è©±ã€‚\nè‹±æ–‡:\nâ€œWhat questions do you have for me that would help you provide the best output?â€\nä¸­æ–‡:\nâ€œæ‚¨æœ‰ä»€éº¼å•é¡Œå¯ä»¥å¹«åŠ©æ‚¨æä¾›æœ€ä½³è¼¸å‡ºï¼Ÿâ€\nConsider tone (è€ƒæ…®èªæ°£é¢¨æ ¼):\næ ¹æ“šæ‚¨çš„ç›®æ¨™å—çœ¾èª¿æ•´æ‚¨çš„ Promptã€‚è¦æ±‚è¼¸å‡ºå…·æœ‰ç‰¹å®šçš„èªæ°£ï¼Œä¾‹å¦‚: æ­£å¼ã€éæ­£å¼ã€æŠ€è¡“æ€§ã€å‰µæ„æ€§ æˆ– ä¼‘é–’æ€§ã€‚\nSay it another way (å˜—è©¦ä¸åŒèªªæ³•):\nå¦‚æœç”¢ç”Ÿçµæœä¸ç¬¦åˆæ‚¨çš„æœŸæœ›ï¼Œæˆ–è€…æ‚¨èªç‚ºæœ‰æ”¹é€²çš„ç©ºé–“ï¼Œè«‹èª¿æ•´æ‚¨çš„ Promptã€‚å¯©æŸ¥ å’Œ æœ€ä½³åŒ–çš„ç–Šä»£éç¨‹é€šå¸¸æœƒç”¢ç”Ÿæ›´å¥½çš„ç»“æœ ã€‚\næ–‡ç« æœ€å¾Œé‚„æ‰“å€‹é é˜²é‡:\nå› ç‚º AI Model ä¸€ç›´åœ¨é€²æ­¥ï¼Œæ‰€ä»¥ Prompt æœ‰æ™‚å¯èƒ½æœƒç”¢ç”Ÿä¸å¯é æ¸¬çš„éŸ¿æ‡‰ã€‚\nåœ¨ä¸‹ Prompt å‰è«‹å…ˆç¢ºèª Prompt ä¿æœ‰å…¶æ¸…æ™°æ€§ã€ç›¸é—œæ€§ å’Œ æº–ç¢ºæ€§ã€‚\næœ€å¾Œé‚„è£œä¸Šä¸€å¥è«‹ç‰¢è¨˜ä¸€é» \u0026ldquo;ç”Ÿæˆå¼ AI æ—¨åœ¨å¹«åŠ©äººé¡ä½†æœ€çµ‚è¼¸å‡ºç”±æ‚¨è² è²¬\u0026rdquo;ã€‚\næ‡¶äººåŒ…å¤§æ¦‚å°±æ˜¯:\nä½ ç”¨äº†ä¸Šè¿°æŠ€å·§å¦‚æœå›æ‡‰é‚„æ˜¯å¾ˆç³Ÿç³•è¦ä¸æ˜¯ä½ çš„å•é¡Œï¼Œå°±æ˜¯AIçš„ä¸å¯é æ¸¬æ€§å•é¡Œï¼Œåˆ¥ä¾†æ‰¾æˆ‘éº»ç…©ã€‚\nå› ç‚ºæˆ‘åªæƒ³çœ‹ Prompt éƒ¨åˆ†æ–‡ä»¶ä¹‹å¾Œéƒ½æ˜¯å„è¡Œæ¥­çš„ä½¿ç”¨æƒ…å¢ƒä½¿ä½¿ç”¨ç¯„ä¾‹å¦‚æœå¤§å®¶æœ‰èˆˆè¶£å¯ä»¥å»çœ‹çœ‹!!\né¡å¤–è£œå……: å¦‚æœæ˜¯ä½¿ç”¨Gemini API æœ‰ thinking å¯ä»¥ä½¿ç”¨\nfrom google import genai from google.genai import types client = genai.Client(api_key=\u0026#34;GOOGLE_API_KEY\u0026#34;) prompt = \u0026#34;What is the sum of the first 50 prime numbers?\u0026#34; response = client.models.generate_content( model=\u0026#34;gemini-2.5-pro-preview-06-05\u0026#34;, contents=prompt, config=types.GenerateContentConfig( thinking_config=types.ThinkingConfig( include_thoughts=True ) ) ) Reference # Google WorkspaceGemini for Google Workspace Prompt Guide\n","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/gemini-workspace-prompt/","section":"Posts","summary":"\u003cp\u003eé€™æ˜¯ä¸€ä»½ Googel åœ¨2024å¹´10æœˆé‡å° Gemini æ¨¡å‹ä¸¦å¦‚ä½•æ­£ç¢ºä¸‹ Prompt çš„ä¸€ä»½æ–‡ä»¶ã€‚å› ç‚ºå°æ–¼æ–°æ‰‹ä¾†èªªé€™å°ä¸‹ Prompt ä¹Ÿç®—æ˜¯ä¸€å€‹ä¸éŒ¯çš„æ•™å­¸ï¼\u003c/p\u003e","title":"Gemini for Workspace Prompt","type":"posts"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/","section":"OKH@nd's Blog","summary":"","title":"OKH@nd's Blog","type":"page"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/prompt/","section":"Tags","summary":"","title":"Prompt","type":"tags"},{"content":"","date":"2025å¹´08æœˆ31æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025å¹´08æœˆ22æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/api/","section":"Tags","summary":"","title":"API","type":"tags"},{"content":"","date":"2025å¹´08æœˆ22æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/model/","section":"Tags","summary":"","title":"Model","type":"tags"},{"content":"å› æ‡‰æœ€æ–°çš„ GPT-5 å‡ºä¾†çš„åŒæ™‚ API å¤šäº†å¹¾å€‹(å°æˆ‘ä¾†èªªçš„)æ–°åƒæ•¸ï¼ŒReasoning Effort è·Ÿ Verbosity\nreasoning effort æ¨ç† # reasoning.effort åƒæ•¸æœ‰ä»¥ä¸‹å¹¾ç¨®ç¨‹åº¦å¯é¸æ“‡\nminimal low medium high é è¨­å€¼ç‚ºÂ medium\nåƒæ•¸æ§åˆ¶æ¨¡å‹åœ¨ç”¢ç”Ÿå›æ‡‰ä¹‹å‰ æ¨ç†å¤šä¹… èˆ‡ ç”¢ç”Ÿå¤šå°‘æ¨ç† Tokenã€‚\nå…¶å¯¦ reasoning.effort åœ¨ä¹‹å‰ o ç³»åˆ—(Exï¼šo1, o3)èƒ½ä½¿ç”¨ï¼Œé€™æ¬¡æ–°å¢çš„æ˜¯ minimal æœƒä»¥æœ€å¿«çš„è¼•é‡åŒ–çš„æ–¹å¼æ€è€ƒ(éœ€è¦æˆ–ä¸éœ€è¦)æ·»åŠ éå¸¸å°‘çš„æ¨ç† token ã€‚\nVerbosityÂ è©³ç´°ç¨‹åº¦ # verbosity åƒæ•¸æœ‰ä»¥ä¸‹å¹¾ç¨®ç¨‹åº¦å¯é¸æ“‡\nlow medium high verbosity æ±ºå®šäº†ç”¢ç”Ÿå¤šå°‘è¼¸å‡º Tokenã€‚\nä¸‹é¢æ˜¯è©¢å•åŒä¸€å€‹å•é¡Œä¸¦ä¸”ä½¿ç”¨åŒå€‹ Model èˆ‡ reasoning éšæ®µèª¿æ•´ verbosity çš„å›æ‡‰\nmodel: gpt-5-nano\neffort: high\nverbosity: low\ncompletion_tokens=3959, prompt_tokens=30, total_tokens=3989 é‡å­ç³¾çºæ˜¯æŒ‡å¤šå€‹é‡å­ç³»çµ±çš„æ•´é«”ç‹€æ…‹ç„¡æ³•å¯«æˆå„è‡ªå­ç³»çµ±ç‹€æ…‹çš„ä¹˜ç©ï¼Œå¿…é ˆä»¥å…±åŒçš„é‡å­æ…‹å­˜åœ¨ï¼Œå…©è€…ä¹‹é–“æœ‰è‘—ä¸èƒ½ç”¨å¤å…¸æ–¹å¼è§£é‡‹çš„å¼·ç›¸é—œã€‚\\n\\nç›´è§€è¦é»\\n- å…©å€‹ç²’å­ï¼ˆæˆ–é‡å­ä½ï¼‰ä¸€èµ·è¢«å‰µå»ºï¼Œå½¼æ­¤å³ä½¿åˆ†é–‹å¾ˆé ï¼Œæ¸¬é‡çµæœä»é¡¯ç¤ºé«˜åº¦ç›¸é—œã€‚\\n- é€™ç¨®ç›¸é—œæ€§åœ¨å¤šå€‹æ¸¬é‡åŸºåº•ï¼ˆå¦‚ Zã€X åŸºåº•ï¼‰éƒ½èƒ½çœ‹åˆ°ï¼Œä¸”ä¸æ˜¯å–®ç´”çš„æ¦‚ç‡é æ¸¬ï¼Œè€ŒåŒ…å«é‡å­ç›¸å¹²ï¼ˆå¹²æ¶‰ï¼‰ä¿¡æ¯ã€‚\\n\\næ•¸å­¸ç¯„ä¾‹\\n- ä¸€å€‹å¸¸è¦‹çš„ç³¾çºæ…‹æ˜¯ Bell æ€ |Î¦+\u0026gt; = (|00\u0026gt; + |11\u0026gt;)/âˆš2ã€‚\\n - åœ¨ Z åŸºåº•æ¸¬é‡ï¼šè‹¥ç¬¬ä¸€ç²’å­æ˜¯ 0ï¼Œç¬¬äºŒç²’å­å¿…å®šæ˜¯ 0ï¼›è‹¥ç¬¬ä¸€ç²’å­æ˜¯ 1ï¼Œç¬¬äºŒç²’å­å¿…å®šæ˜¯ 1ã€‚\\n - åœ¨ X åŸºåº•æ¸¬é‡ï¼šè‹¥å°ç¬¬ä¸€ç²’å­å¾—åˆ° +ï¼Œç¬¬äºŒç²’å­ä¹Ÿå¾—åˆ° +ï¼›è‹¥å¾—åˆ° âˆ’ï¼Œç¬¬äºŒç²’å­ä¹Ÿå¾—åˆ° âˆ’ã€‚\\n- å–®ç²’å­é‚Šéš›çš„å¯†åº¦çŸ©é™£æ˜¯æ··åˆæ…‹ï¼ˆè³‡è¨Šè¢«ã€Œåˆ†è£ã€åœ¨æ•´é«”ä¸­ï¼‰ï¼Œä½†æ•´é«”æ˜¯ç´”æ…‹ï¼Œä¸”åŒ…å«è·¨åŸºåº•çš„ç›¸å¹²æ€§ã€‚\\n- èˆ‡å¤å…¸æ··åˆç›¸æ¯”ï¼Œç³¾çºæ…‹å…·æœ‰ç„¡æ³•ç”¨ä¹˜ç©ç‹€æ…‹çµ„åˆä¾†æè¿°çš„ç‰¹æ€§ï¼›åŒæ¨£çš„é‚Šéš›åˆ†å¸ƒåœ¨æŸäº›æƒ…æ³ä¸‹å¯èƒ½çœ‹èµ·ä¾†ç›¸åŒï¼Œä½†ç¼ºå°‘è·¨åŸºåº•çš„ç›¸å¹²æ€§ã€‚\\n\\né‡è¦æ€§èˆ‡é™åˆ¶\\n- é€™äº›é‡å­ç›¸é—œæ€§ç„¡æ³•ç”¨å±€éƒ¨éš±è®Šé‡æ¨¡å‹è§£é‡‹ï¼Œå±¬æ–¼é‡å­éå±€éƒ¨æ€§çš„ä¸€ç¨®è¡¨ç¾ã€‚\\n- ä¸èƒ½ç”¨å–®å–®ç³¾çºé‡å­æ…‹ä¾†å‚³éè¨Šæ¯ï¼›éœ€è¦ç¶“ç”±ç¶“å…¸é€šè¨Šä¾†æ¯”å°çµæœã€‚\\n- äº®é»æ‡‰ç”¨ï¼šé‡å­æ…‹å‚³é€ï¼ˆ teleportation ï¼‰ã€è¶…å¯†ç·¨ç¢¼ï¼ˆ superdense coding ï¼‰ã€é‡å­å¯†é‘°åˆ†ç™¼ï¼ˆ QKDï¼Œå¦‚ Ekert91ï¼‰ç­‰ã€‚\\n\\nç°¡å–®æ€»ç»“\\nç³¾çºæ˜¯å¤šç²’å­ç³»çµ±çš„ä¸€ç¨®ã€Œå…±åŒå­˜åœ¨çš„ã€é‡å­ç‹€æ…‹ï¼Œé«”ç¾åœ¨è·¨ç²’å­çš„æ¸¬é‡çµæœä¸Šï¼Œæ—¢å¼·çƒˆç›¸é—œåˆä¸èƒ½ç”¨å¤å…¸æ©Ÿåˆ¶å®Œå…¨è§£é‡‹ï¼Œä¸¦ä¸”æ˜¯è¨±å¤šé‡å­è³‡è¨ŠæŠ€è¡“çš„æ ¸å¿ƒè³‡æºã€‚ model: gpt-5-nano\neffort: high\nverbosity: medium\ncompletion_tokens=5433, prompt_tokens=30, total_tokens=5463, ä¸‹é¢ç”¨æ¯”è¼ƒç›´è§€èˆ‡å¹¾ä½•çš„æ–¹å¼ï¼Œè¬›è§£ä»€éº¼æ˜¯é‡å­ç³¾çºï¼Œä»¥åŠå®ƒç‚ºä»€éº¼é‡è¦ã€‚\\n\\n1) ä»€éº¼æ˜¯é‡å­ç³¾çº\\n- å¤šå€‹é‡å­ç³»çµ±ï¼ˆä¾‹å¦‚å…©å€‹ç²’å­ã€å…©å€‹å…‰å­ï¼‰è¢«è™•æ–¼ä¸€å€‹æ•´é«”çš„é‡å­æ…‹ï¼Œé€™å€‹æ…‹ä¸èƒ½å¯«æˆå„è‡ªç³»çµ±æ…‹çš„ç›´ç©ï¼šÏˆ â‰  Ïˆ_A âŠ— Ïˆ_Bã€‚ä¹Ÿå°±æ˜¯èªªï¼Œæ•´å€‹ç³»çµ±çš„ç‹€æ…‹ç„¡æ³•åˆ†è§£æˆå„éƒ¨åˆ†å„è‡ªçš„â€œé å…ˆæ±ºå®šçš„å€¼â€ã€‚\\n- é€™æ„å‘³è‘—ï¼šå°å…¶ä¸­ä»»ä¸€å­ç³»çµ±çš„æ¸¬é‡çµæœï¼Œèˆ‡å¦ä¸€å­ç³»çµ±çš„æ¸¬é‡çµæœä¹‹é–“å­˜åœ¨è‘—ã€Œéç¶“å…¸çš„ç›¸é—œæ€§ã€ï¼Œå³ä½¿å…©å€‹ç³»çµ±ç›¸éš”å¾ˆé ï¼Œé€™ç¨®ç›¸é—œæ€§ä¹Ÿä¸ä¾è³´æ–¼å‚³éä¿¡è™Ÿã€‚\\n\\n2) ç”¨æœ€å¸¸è¦‹çš„å…©ç²’å­ä¾‹å­èªªæ˜\\n- è²çˆ¾æ…‹ï¼ˆBell statesï¼‰æ˜¯å…©å€‹é‡å­æ¯”ç‰¹æœ€å…¸å‹çš„ç³¾çºæ…‹ï¼Œä¾‹å¦‚å…¶ä¸­ä¸€å€‹æ˜¯ï¼š\\n - |Î¦+âŸ© = (|00âŸ© + |11âŸ©) / âˆš2\\n å¦å¤–é‚„æœ‰ |Î¦âˆ’âŸ©ã€|Î¨+âŸ©ã€|Î¨âˆ’âŸ©ï¼Œæ¯ä¸€å€‹éƒ½ç„¡æ³•å¯«æˆ |aâŸ©âŠ—|bâŸ© çš„å½¢å¼ã€‚\\n- å¦ä¸€å€‹å¸¸è¦‹ä¾‹å­æ˜¯â€œsingletâ€æ…‹ï¼š\\n - |Î¨âˆ’âŸ© = (|01âŸ© âˆ’ |10âŸ©) / âˆš2\\n é€™å€‹æ…‹åœ¨æ¸¬é‡å…©å€‹ç²’å­è‡ªæ—‹æ²¿åŒä¸€è»¸æ™‚ï¼Œçµæœæ˜¯å®Œå…¨åç›¸é—œçš„ï¼ˆä¸€å€‹ +1ï¼Œå¦ä¸€å€‹ âˆ’1ï¼‰ã€‚\\n- ç›´è¦ºé‡é»ï¼šå°å–®ä¸€ç²’å­çš„æ€§è³ªä¾†èªªï¼Œé‡å­ç³¾çºæ…‹çš„å€‹åˆ¥é‚Šéš›ç‹€æ…‹é€šå¸¸æ˜¯æ··åˆçš„ï¼ˆçœ‹èµ·ä¾†åƒæ˜¯â€œæœªçŸ¥çš„â€ï¼Œæˆ–æ˜¯æ²’æœ‰ definite å€¼ï¼‰ï¼Œåªæœ‰æŠŠå…©å€‹ç²’å­ä¸€èµ·æ¸¬é‡æ™‚ï¼Œæ‰æœƒçœ‹åˆ°ç©©å®šçš„è¯ç¹«ã€‚\\n\\n3) æ¸¬é‡èˆ‡ç›¸é—œæ€§ï¼ˆä¸ç­‰æ–¼â€œè³‡è¨Šä»¥å…‰é€Ÿç¬é–“å‚³éâ€ï¼‰\\n- å°ç³¾çºå°è€Œè¨€ï¼Œè‹¥åœ¨æŸå€‹æ–¹å‘æ¸¬é‡ç¬¬ä¸€å€‹ç²’å­è‡ªæ—‹ï¼ˆæˆ–åæŒ¯ï¼‰ï¼Œç¬¬äºŒå€‹ç²’å­çš„çµæœæœƒä»¥æŸç¨®æ–¹å¼è¢«â€œè‡ªå‹•åœ°â€ç›¸é—œåœ°é¡¯ç¤ºå‡ºä¾†ï¼Œé€™ç¨®ç›¸é—œæ€§ä¸éœ€è¦ä»»ä½•ä¿¡è™Ÿå‚³éã€‚\\n- å°ä¸åŒæ¸¬é‡æ–¹å‘çš„è¨­å®šï¼Œç›¸é—œæ€§å¯ä»¥å¯«æˆï¼šå°å…©å€‹ç²’å­åˆ†åˆ¥åœ¨æ¸¬é‡æ–¹å‘ a å’Œ bï¼Œå…¶çµæœçš„ç›¸é—œå‡½æ•¸ E(a,b) = âŸ¨Ïƒ(a) âŠ— Ïƒ(b)âŸ©ï¼Œåœ¨ singlet æ€ä¸­æœ‰ E(a,b) = -a Â· bï¼Œå³å…©æ¸¬é‡æ–¹å‘çš„å¤¾è§’ Î¸ çš„é¤˜å¼¦è² å€¼ã€‚\\n- é€™ç¨®ç¾è±¡ä¸ç­‰æ–¼â€œé å…ˆè¨­å®šçš„å€¼â€æˆ–â€œå±€éƒ¨å› æœå½±éŸ¿â€ï¼›å¦‚æœä½ ç”¨å±€éƒ¨å¯¦åœ¨è«–å»è§£é‡‹ï¼Œå°±æœƒé‡åˆ° Bell ä¸ç­‰å¼ç­‰é™åˆ¶ã€‚\\n\\n4) Bell ä¸ç­‰å¼èˆ‡å¯¦é©—é©—è­‰\\n- å±€éƒ¨å¯¦åœ¨è«–è€…æœƒèªç‚ºæ¯å€‹ç²’å­åœ¨è¢«æ¸¬é‡å‰å°±å·²ç¶“æœ‰é å…ˆæ±ºå®šçš„çµæœï¼Œæ¸¬é‡åªæ˜¯æ­ç¤ºé€™äº›å€¼ï¼›é€™å°è‡´æŸäº›æ•¸å­¸ä¸ç­‰å¼ï¼ˆå¦‚ CHSH ä¸ç­‰å¼ï¼‰å¿…é ˆæˆç«‹ã€‚\\n- é‡å­åŠ›å­¸çš„é æ¸¬åœ¨é©ç•¶çš„è¨­å®šä¸‹æœƒé•èƒŒé€™äº›ä¸ç­‰å¼ï¼Œæœ€å¤§å¯é”åˆ°çš„é‡å­å€¼æ˜¯ S = 2âˆš2ï¼ˆCirelâ€™son æ¥µé™ï¼‰ã€‚\\n- å¯¦é©—ä¸­å¸¸åšä½›è¿°çš„ Bell æ¸¬è©¦ï¼ˆå¦‚ CHSH æ¸¬è©¦ï¼‰ã€‚å¤šå€‹å¯¦é©—å·²ç¶“è§€å¯Ÿåˆ°å°æ‡‰çš„é‡å­é æ¸¬çš„é•èƒŒï¼Œæ”¯æŒé‡å­ç³¾çºèˆ‡é‡å­åŠ›å­¸çš„éå±€éƒ¨ç›¸é—œæ€§ã€‚ä¹Ÿå‡ºç¾äº†â€œæ¼æ´è‡ªç”±â€çš„å¯¦é©—è¨­è¨ˆï¼Œä»¥æ’é™¤æŸäº›æ›¿ä»£è§£é‡‹ã€‚\\n\\n5) å¦‚ä½•ç”¢ç”Ÿèˆ‡æª¢é©—ç³¾çº\\n- ç”¢ç”Ÿï¼šå¯¦é©—å®¤å¸¸ç”¨æ©Ÿåˆ¶åŒ…æ‹¬å…‰å­çš„è‡ªç™¼åƒé‡ä¸‹è½‰æ›ï¼ˆSPDCï¼‰å°‡ä¸€æ¬¡å…‰å­å°è®Šç‚ºç³¾çºçš„äºŒå­å…‰å­ï¼ˆåæŒ¯ã€æ™‚é–“ä½ã€è·¯å¾‘ç­‰ä»»ä¸€åº¦æ…‹ï¼‰ã€‚ä¹Ÿæœ‰åˆ©ç”¨åŸå­ã€é›¢å­ã€è¶…å°é‡å­æ¯”ç‰¹ã€æ°®ç©ºä½ï¼ˆNVï¼‰ä¸­å¿ƒç­‰ç³»çµ±çš„ç³¾çºã€‚\\n- æª¢é©—/è­‰æ˜ï¼š\\n - é‡å­æ…‹å±¤æï¼ˆquantum state tomographyï¼‰ä»¥é‡è¤‡æ¸¬é‡èˆ‡çµ±è¨ˆæ¨ä¼°æ•´é«”æ…‹ã€‚\\n - ç³¾çºæª¢é©—ï¼ˆentanglement witnessesï¼‰æˆ–è¨ˆç®—ç³¾çºåº¦ï¼ˆå¦‚ concurrenceã€negativityï¼‰ã€‚\\n - Bell æ¸¬è©¦ï¼ˆCHSH ä¸ç­‰å¼ï¼‰ç”¨ä»¥è­‰æ˜éå±€éƒ¨ç›¸é—œæ€§ã€‚\\n- é‡å­æ…‹çš„éƒ¨åˆ†è·¡ï¼ˆä¾‹å¦‚å–®ä¸€ç²’å­é‚Šéš›å¯†åº¦çŸ©é™£ï¼‰å¾€å¾€æ˜¯å®Œå…¨æ··åˆçš„ï¼Œè€Œåªæœ‰çµåˆèµ·ä¾†æ‰å‘ˆç¾æ˜é¡¯çš„ç³¾çºæ€§ã€‚\\n\\n6) ç‚ºä»€éº¼é‡å­ç³¾çºé‡è¦ï¼ˆæ‡‰ç”¨å±¤é¢ï¼‰\\n- é‡å­éé€ï¼ˆé‡å­ teleportationï¼‰ï¼šä¸ä»¥å‚³é€ç‰©ç†ç²’å­ç‚ºå‰æï¼Œè€Œæ˜¯åˆ©ç”¨ç³¾çºå°çµåˆä¸€å€‹æœªçŸ¥é‡å­æ…‹çš„å‚³é€ã€‚\\n- è¶…å¯†ç¢¼ç·¨ç¢¼ï¼ˆsuperdense codingï¼‰ï¼šç”¨ä¸€å€‹é‡å­æ¯”ç‰¹èˆ‡é å…ˆå…±äº«çš„ç³¾çºå°ï¼Œå‚³é€å…©å€‹è³‡æ–™æ¯”ç‰¹çš„è³‡è¨Šã€‚\\n- é‡å­é‘°åŒ™åˆ†é…ï¼ˆquantum key distribution, QKDï¼Œç‰¹åˆ¥æ˜¯ Ekert å”è­°ï¼‰ï¼šåˆ©ç”¨ç³¾çºå¸¶ä¾†çš„æ¸¬é‡çµæœç›¸é—œæ€§ï¼Œæ¢æ¸¬ç«Šè½ä¸¦å®‰å…¨åˆ†ç™¼å¯†é‘°ã€‚\\n- é‡å­è¨ˆç®—ä¸­çš„è³‡æºï¼šç³¾çºæ˜¯å¯¦ç¾æŸäº›é‡å­æ¼”ç®—æ³•èˆ‡é‡å­éŒ¯èª¤æ›´æ­£çš„æ ¸å¿ƒè³‡æºã€‚\\n\\n7) å¸¸è¦‹èª¤è§£èˆ‡è¦é»\\n- ä¸å­˜åœ¨â€œè¶…å…‰é€Ÿè³‡è¨Šå‚³éâ€ï¼šæ¸¬é‡çµæœæœ¬èº«æ˜¯éš¨æ©Ÿçš„ï¼Œåªæœ‰æŠŠå…©ç«¯çš„çµæœé€éç¶“å…¸é€šé“æ¯”å°å¾Œï¼Œæ‰å‡ºç¾å°æ‡‰çš„ç›¸é—œæ€§ã€‚\\n- ç³¾çºä¸æ˜¯ã€Œå…©å€‹ç²’å­åŒæ™‚æ“æœ‰æŸå€‹ç¢ºå®šå€¼ã€çš„è­‰æ˜ï¼›ç›¸åï¼Œç›´åˆ°æ¸¬é‡ï¼Œå€‹åˆ¥ç²’å­çš„æ€§è³ªå¾€å¾€æ˜¯æœªç¢ºå®šçš„ã€‚\\n- Entanglement æ˜¯ä¸å¯åˆ†å‰²çš„è³‡æºï¼Œä½†ä¹Ÿæœ‰â€œå–®å‘åˆ†äº«â€é™åˆ¶ï¼ˆmonogamy of entanglementï¼‰ï¼šä¸€å€‹é‡å­å°çš„ç³¾çºç¨‹åº¦ä¸èƒ½è¢«ä»»æ„åœ°åˆ†é…çµ¦ç¬¬ä¸‰æ–¹ã€‚\\n\\nå¦‚æœä½ æƒ³ï¼Œæˆ‘å¯ä»¥å†æ·±å…¥æŸä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼š\\n- å…·é«”æ¨å°å…©ç²’å­ Bell state çš„æ¸¬é‡ç›¸é—œæ€§èˆ‡ E(a,b) çš„å…¬å¼\\n- CHSH ä¸ç­‰å¼çš„æ¨å°èˆ‡ä¸€å€‹å…·é«”çš„å¯¦é©—è¨­å®šä¾‹å­\\n- å¦‚ä½•ç”¨é‡å­æ…‹å±¤æé€²è¡Œç³¾çºåº¦çš„é‡æ¸¬èˆ‡è¨ˆç®—\\n- å…·é«”çš„å¯¦é©—å¹³å°æ¯”è¼ƒï¼ˆå…‰å­ã€é›¢å­ã€è¶…å°é‡å­æ¯”ç‰¹ç­‰ï¼‰çš„ç³¾çºç”¢ç”Ÿèˆ‡æ¸¬é‡æ–¹å¼\\n\\nå‘Šè¨´æˆ‘ä½ æƒ³æ›´æ·±å…¥å“ªå€‹éƒ¨åˆ†ï¼Œæˆ‘å¯ä»¥çµ¦ä½ æ›´ç²¾ç¢ºçš„å…¬å¼èˆ‡æ­¥é©Ÿã€‚ model: gpt-5-nano\neffort: high\nverbosity: high\ncompletion_tokens=8620, prompt_tokens=30, total_tokens=8650 ä»¥ä¸‹ç”¨æ¯”è¼ƒç›´ç™½çš„èªè¨€ï¼Œä¸¦è¼”ä»¥ä¸€é»é»æ•¸å­¸è¦é»ï¼Œå¹«ä½ ç†è§£ä»€éº¼æ˜¯é‡å­ç³¾çºã€ç‚ºä»€éº¼å®ƒé‡è¦ï¼Œä»¥åŠå®ƒåœ¨å¯¦é©—å’Œæ‡‰ç”¨ä¸Šçš„æ„ç¾©ã€‚\\n\\nä¸€ã€ä»€éº¼æ˜¯é‡å­ç³¾çºï¼ˆQ.E.ï¼šé‡å­ç³¾çºï¼‰\\n- å®šç¾©è¦é»ï¼šç•¶å…©å€‹æˆ–ä»¥ä¸Šçš„é‡å­ç³»çµ±çµ„æˆä¸€å€‹æ•´é«”æ™‚ï¼Œå®ƒå€‘çš„é‡å­ç‹€æ…‹æœ‰åˆ¥æ–¼å„è‡ªå–®ç¨ç‹€æ…‹çš„ä¹˜ç©å½¢å¼ã€‚ä¹Ÿå°±æ˜¯èªªï¼Œç„¡æ³•æŠŠæ•´å€‹ç³»çµ±å¯«æˆå…©éƒ¨åˆ†å„è‡ªçš„ç‹€æ…‹çš„ä¹˜ç© |Ïˆ\u0026gt; â‰  |a\u0026gt;âŠ—|b\u0026gt;ã€‚é€™ç¨®â€œä¸å¯åˆ†å‰²â€çš„æ•´é«”ç‹€æ…‹å°±å«ä½œç³¾çºç‹€æ…‹ã€‚\\n- æ ¸å¿ƒç‰¹å¾µï¼šå°å…¶ä¸­ä¸€å€‹ç³»çµ±çš„æ¸¬é‡çµæœï¼Œæœƒèˆ‡å¦ä¸€å€‹ç³»çµ±çš„çµæœå‡ºç¾æ·±åˆ»çš„ç›¸é—œæ€§ï¼Œé€™äº›ç›¸é—œæ€§åœ¨å¾ˆå¤šæƒ…æ³ä¸‹ç„¡æ³•ç”¨ä»»ä½•å±€éƒ¨çš„â€œé å…ˆå­˜åœ¨çš„å±¬æ€§â€ä¾†è§£é‡‹ã€‚\\n- é‡è¦çš„ç´„æŸï¼šé›–ç„¶é€™ç¨®ç›¸é—œæ€§å¾ˆã€Œç¥ç¥•ã€ï¼Œä½†å®ƒä¸¦ä¸æœƒè®“ä½ ç”¨å®ƒé€²è¡Œè¶…å…‰é€Ÿè¨Šæ¯å‚³éï¼ˆç„¡æ³•å–®ç¨ç”¨ç³¾çºä¾†å‚³é€ä¿¡æ¯ï¼Œå¿…é ˆå€ŸåŠ©ç¶“å…¸é€šé“çš„æ¯”è¼ƒæ‰èƒ½çœ‹åˆ°ç›¸é—œæ€§ï¼‰ã€‚\\n\\näºŒã€ç”¨ä¸€å€‹æœ€å¸¸è¦‹çš„ä¾‹å­èªªæ˜\\n- è²çˆ¾å°ï¼ˆBell pairï¼‰æ˜¯å…©å€‹é‡å­ç³»çµ±æœ€å…¸å‹çš„ç³¾çºæ…‹ä¹‹ä¸€ã€‚æœ€å¸¸è¦‹çš„å½¢å¼æ˜¯ï¼š\\n |Î¦+\u0026gt; = (|00\u0026gt; + |11\u0026gt;)/âˆš2\\n é€™è£¡çš„â€œ|0\u0026gt; èˆ‡ |1\u0026gt;â€æ˜¯å…©å€‹é‡å­æ¯”ç‰¹çš„åŸºæ…‹ã€‚\\n- å¦‚æœä½ åœ¨å…©å€‹é‡å­æ¯”ç‰¹ä¸Šéƒ½æ¸¬é‡â€œè¨ˆç®—åŸºåº•â€ZåŸºåº•ï¼ˆå³åˆ¤å®šæ˜¯0é‚„æ˜¯1ï¼‰ï¼Œä½ æœƒå¾—åˆ°å…©å€‹çµæœç¸½æ˜¯ç›¸åŒçš„ï¼šè¦éº¼åŒæ™‚æ˜¯ 0-0ï¼Œè¦éº¼åŒæ™‚æ˜¯ 1-1ï¼Œå„æœ‰ 1/2 çš„æ©Ÿç‡ã€‚\\n- å¦‚æœä½ åœ¨å…©å€‹é‡å­æ¯”ç‰¹ä¸Šéƒ½æ¸¬é‡å¦ä¸€å€‹åŸºåº•ï¼ˆä¾‹å¦‚XåŸºåº•ï¼Œ|+\u0026gt; = (|0\u0026gt;+|1\u0026gt;)/âˆš2 èˆ‡ |-\u0026gt; = (|0\u0026gt;-|1\u0026gt;)/âˆš2ï¼‰ï¼Œä½ ä¹Ÿæœƒçœ‹åˆ°åŒæ¨£çš„çµæœï¼šå…©è€…ç¸½æ˜¯ç›¸åŒã€‚\\n- é€™ç¨®åœ¨ä¸åŒæ¸¬é‡åŸºåº•ä¸‹ä»ä¿æŒé«˜åº¦ç›¸é—œçš„ç¾è±¡ï¼Œå°±æ˜¯é‡å­ç³¾çºçš„ç›´è§€å¯«ç…§ã€‚å°æ–¼ä¸åŒçš„æ¸¬é‡è§’åº¦ï¼Œç›¸é—œçš„å¼·åº¦æœƒä¾è§’åº¦è®ŠåŒ–ï¼ˆé€™ä¹Ÿæ­£æ˜¯å¾Œé¢è¦è«‡çš„â€œä¸ç­‰å¼â€èƒŒå¾Œçš„ç‰©ç†æ„ç¾©ï¼‰ã€‚\\n\\nä¸‰ã€ç‚ºä»€éº¼ç³¾çºæ¯”ä¸€èˆ¬çš„ã€Œç›¸é—œã€é‚„è¦ç‰¹åˆ¥\\n- å€åˆ¥æ–¼ç¶“å…¸ç›¸é—œï¼šå¦‚æœæŠŠå…©å€‹ç²’å­æ”¾åœ¨ä¸€èµ·ï¼Œä½†å¯¦éš›ä¸Šæ¯å€‹ç²’å­äº‹å…ˆå°±æœ‰æŸäº›å±¬æ€§ï¼ˆæå‰è®¾å®šå¥½ï¼Œä¾‹å¦‚é¡è‰²ã€æ–¹å‘ç­‰ï¼‰å¯ä»¥è¢«æˆ‘å€‘åœ¨å¯¦é©—æ™‚å°±é æ¸¬ï¼Œé€™å«ã€Œå±€éƒ¨å¯¦åœ¨è«–ã€ã€‚é‡å­ç³¾çºçš„ç›¸é—œæ€§ï¼Œè®“é€™ç¨®å±€éƒ¨å¯¦åœ¨è«–é›£ä»¥è§£é‡‹ï¼Œå› è€Œå‡ºç¾äº†è‘—åçš„ Bell ä¸ç­‰å¼åŠå¯¦é©—ä¸Šçš„é•èƒŒã€‚\\n- æ··åˆæ…‹ä¹Ÿå¯èƒ½ç³¾çºï¼šä¸¦éåªæœ‰â€œç´”æ…‹â€çš„ |Î¦+\u0026gt; é¡å‹æ‰ç³¾çºã€‚æ··åˆæ…‹çš„å¯†åº¦çŸ©é™£ Ï ä¹Ÿå¯èƒ½æ˜¯ç³¾çºçš„ï¼ˆä½†æœ‰æ™‚å€™çœ‹èµ·ä¾†åƒæ˜¯â€œéƒ¨åˆ†é å…ˆæ±ºå®šçš„æ··åˆâ€ï¼Œè¦ç”¨å…·é«”çš„ç³¾çºæª¢é©—æ‰è¡Œï¼‰ã€‚\\n- ç³¾çºèˆ‡â€œè³‡è¨Šçš„æ§åˆ¶â€é—œä¿‚ï¼šç³¾çºæä¾›äº†ä¸€ç¨®éå±€éƒ¨çš„é‡å­ç›¸é—œè³‡æºï¼Œè®“é‡å­é€šè¨Šã€é‡å­è¨ˆç®—ç­‰æŠ€è¡“æˆç‚ºå¯èƒ½ï¼›ä½†å®ƒæœ¬èº«ä¸ç­‰æ–¼å‚³éè¨Šæ¯çš„å·¥å…·ï¼Œå¿…é ˆçµåˆç¶“å…¸é€šé“èˆ‡æ¸¬é‡çš„å¾Œè™•ç†ã€‚\\n\\nå››ã€æ•¸å­¸è§€é»çš„å¿«é€Ÿå…¥é–€ï¼ˆå¯é¸åŠ æ·±ï¼‰\\n- å°æ–¼å…©å€‹é‡å­ç³»çµ±ï¼Œæ•´é«”ç‹€æ…‹åœ¨å¸Œçˆ¾ä¼¯ç‰¹ç©ºé–“ H_A âŠ— H_Bã€‚è‹¥å­˜åœ¨å…©å€‹å–®ç¨çš„ç‹€æ…‹ |Î±\u0026gt;_Aã€|Î²\u0026gt;_Bï¼Œä½¿å¾— |Ïˆ\u0026gt; = |Î±\u0026gt;_A âŠ— |Î²\u0026gt;_Bï¼Œå‰‡è©²ç‹€æ…‹æ˜¯â€œéç³¾çºçš„â€ã€‚è‹¥ä¸èƒ½é€™æ¨£å¯«ï¼Œå‰‡ç‚ºç³¾çºç‹€æ…‹ã€‚\\n- Schmidt å±•é–‹ï¼šä»»æ„ç´”æ…‹ |Ïˆ\u0026gt;_AB éƒ½å¯ä»¥å¯«æˆ |Ïˆ\u0026gt; = âˆ‘_i âˆšÎ»_i |u_i\u0026gt;_A âŠ— |v_i\u0026gt;_Bï¼Œå…¶ä¸­ Î»_i ç‚ºéè² å¯¦æ•¸ä¸” âˆ‘ Î»_i = 1ã€‚è‹¥åªæœ‰ä¸€å€‹éé›¶ Î»_iï¼Œå‰‡è©²ç‹€æ…‹æ˜¯éç³¾çºçš„ï¼›è‹¥æœ‰å¤šå€‹éé›¶ Î»_iï¼Œå‰‡ç³¾çºå­˜åœ¨ã€‚\\n- ç›´è§€çš„å¯¦é©—æª¢é©—æ³•ï¼šBell ä¸ç­‰å¼èˆ‡ CHSH ä¸ç­‰å¼æä¾›ä¸€å€‹ã€Œå±€éƒ¨å¯¦åœ¨è«–çš„é‚Šç•Œã€ï¼Œç”¨å¯¦é©—ä¸Šçš„æ¸¬é‡ä¾†æª¢é©—æ˜¯å¦æœ‰é¡¯è‘—é•èƒŒã€‚è‹¥é•èƒŒï¼Œæ„å‘³è‘—é‡å­åŠ›å­¸çš„ç³¾çºç‰¹æ€§ç„¡æ³•è¢«å±€éƒ¨éš±è®Šé‡è§£é‡‹ã€‚\\n\\näº”ã€å¯¦é©—è­‰æ“šèˆ‡é‡Œç¨‹ç¢‘\\n- æ­·å²ä¸Šçš„èµ·é»ï¼šEPR è«–è­‰ï¼ˆæ„›å› æ–¯å¦ã€æ³¢å¤šçˆ¾æ–¯åŸºã€ç¾…æ£®ï¼‰èªç‚ºé‡å­åŠ›å­¸ä¼¼ä¹ç¼ºä¹å®Œå‚™æ€§ï¼Œç³¾çºè¢«è¦–ç‚ºâ€œè¶…è·ä½œç”¨â€çš„å•é¡Œã€‚ä¹‹å¾Œ Bell çš„ä¸ç­‰å¼æä¾›äº†å¯æª¢é©—çš„é æ¸¬ã€‚\\n- å¯¦é©—ç™¼å±•ï¼š Aspect ç­‰äººï¼ˆ1980sï¼‰ç”¨å…‰å­å¯¦é©—æ¸¬è©¦ CHSH ä¸ç­‰å¼ï¼Œçœ‹åˆ°é‡å­é æ¸¬çš„é•èƒŒã€‚\\n- å¾ŒçºŒæ”¹é€²ï¼šå‡ºç¾äº†â€œ loophole-free Bell testï¼ˆä¸è¨­æ¼æ´çš„è²çˆ¾æ¸¬è©¦ï¼‰â€åœ¨ 2015 å¹´å·¦å³åˆ†åˆ¥ç”±å¤šå€‹åœ˜éšŠå®Œæˆï¼ŒåŒæ™‚å…‹æœäº†æ¢æ¸¬ç‡èˆ‡ å±€åŸŸæ€§ç­‰æ¼æ´çš„å•é¡Œï¼Œçµ¦äºˆå°é‡å­ç³¾çºçš„æ›´å¼·è­‰æ“šã€‚\\n- ç›®å‰å¯¦é©—å°è±¡å»£æ³›ï¼šå…‰å­ã€å†·é›¢å­ã€è¶…å°é‡å­æ¯”ç‰¹ã€ä¸­æ€§åŸå­ç­‰å¹³å°éƒ½èƒ½è£½å‚™èˆ‡æ“æ§ç³¾çºæ…‹ã€‚\\n\\nå…­ã€å¯¦éš›çš„æ‡‰ç”¨ï¼ˆç³¾çºä½œç‚ºè³‡æºï¼‰\\n- é‡å­ teleportationï¼ˆé‡å­éš§é“å‚³è¼¸ï¼‰ï¼šåˆ©ç”¨äº‹å…ˆå…±äº«çš„ç³¾çºå°èˆ‡ç¶“å…¸é€šé“ï¼Œåœ¨ä¸ç›´æ¥å‚³é€é‡å­æ¯”ç‰¹çš„æƒ…æ³ä¸‹ï¼Œå°‡ä¸€å€‹æœªçŸ¥é‡å­ç‹€æ…‹â€œå‚³é€â€åˆ°é ç«¯ã€‚æ ¸å¿ƒæ­¥é©Ÿæ˜¯å…ˆåšä¸€å€‹ Bell åŸºæ…‹æ¸¬é‡ï¼Œç„¶å¾Œæ ¹æ“šæ¸¬é‡çµæœé€²è¡Œç¶“å…¸ä½å…ƒçš„æ§åˆ¶æ“ä½œã€‚\\n- è¶…å¯†ç¼–ç ï¼ˆSuperdense Codingï¼‰ï¼šç”¨ä¸€å€‹é‡å­æ¯”ç‰¹èˆ‡ä¸€å°ç³¾çºæ¯”ç‰¹ï¼Œèƒ½è®“ä¸€æ–¹å‚³é€å…©ä½ç¶“å…¸è¨Šæ¯åˆ°å¦ä¸€æ–¹ï¼Œè¶…å‡ºå–®æ¯”ç‰¹åŸæœ¬çš„è³‡è¨Šå®¹é‡ã€‚\\n- é‡å­å¯†é‘°åˆ†ç™¼ï¼ˆQKDï¼‰ï¼šä¾‹å¦‚ Ekert æŒ‡å‡ºï¼Œç³¾çºå°çš„æ¸¬é‡çµæœå¯ä»¥ç”¨ä¾†å»ºç«‹å®‰å…¨çš„å¯†é‘°ï¼Œä»»ä½•ç«„æ”¹éƒ½æœƒè¢«æ¢æ¸¬åˆ°ã€‚\\n- ç³¾çºè’é›†èˆ‡ç³¾çºæ·¨åŒ–ï¼šåœ¨å¯¦éš›ç¶²è·¯æˆ–é‡å­è¨ˆç®—ä¸­ï¼Œå¸¸éœ€è¦å¾é›œè¨Šä¸­æå–â€œé«˜å“è³ªâ€çš„ç³¾çºå°ï¼Œé€™å°±éœ€è¦ç³¾çºæ·¨åŒ–/è’é›†ç­‰æŠ€è¡“ã€‚\\n\\nä¸ƒã€å¸¸è¦‹çš„èª¤è§£èˆ‡é‡æ¸…\\n- èª¤è§£1ï¼šç³¾çºå°±æ˜¯â€œèƒ½ç¬é–“å‚³éè¨Šæ¯â€ã€‚å¯¦éš›ä¸Šï¼Œå…©ç«¯çš„æ¸¬é‡çµæœåœ¨å±€éƒ¨çœ‹éƒ½æ˜¯éš¨æ©Ÿçš„ï¼Œåªæœ‰æŠŠå…©ç«¯çš„çµæœç¶“éå‚³çµ±é€šé“æ¯”å°å¾Œæ‰çœ‹åˆ°ç›¸é—œæ€§ï¼Œå› æ­¤ä¸èƒ½ç”¨ä¾†è¶…å…‰é€Ÿå‚³éè³‡è¨Šã€‚\\n- èª¤è§£2ï¼šç³¾çºç­‰æ–¼â€œå·²ç¶“é å…ˆæ±ºå®šå¥½äº†å…©å€‹çµæœâ€ã€‚å…¶å¯¦ï¼Œå°æ–¼å–®ç«¯çš„ä»»ä½•æ¸¬é‡ï¼Œçµæœéƒ½æ˜¯éš¨æ©Ÿçš„ï¼›é—œéµåœ¨æ–¼è¯åˆæ¸¬é‡çš„çµ±è¨ˆé—œä¿‚ï¼Œé€™ç¨®é—œä¿‚æ˜¯ç„¡æ³•ç”¨å–®ç´”çš„é å…ˆå­˜åœ¨çš„å€¼ä¾†è§£é‡‹ã€‚\\n- èª¤è§£3ï¼šæ‰€æœ‰ç›¸é—œéƒ½æ˜¯â€œç³¾çºâ€ã€‚æœ‰äº›ç›¸é—œæ˜¯å› ç‚ºå¤å…¸ç›¸é—œæ€§ï¼ˆä¾‹å¦‚åŒæ™‚çœ‹åˆ°å…©å€‹è£ç½®çš„å…±åŒæƒ…æ³ï¼‰ï¼Œè€Œé‡å­ç³¾çºæŒ‡çš„æ˜¯ç„¡æ³•ç”¨å±€éƒ¨å®šç¾©çš„éš±è®Šé‡å»è§£é‡‹çš„ç›¸é—œæ€§ï¼Œé€šå¸¸éœ€è¦ç”¨ Bell ä¸ç­‰å¼ä¾†é©—è­‰ã€‚\\n\\nå…«ã€æƒ³æ›´æ·±å…¥å—ï¼Ÿå¯ä»¥å¾ä»¥ä¸‹æ–¹å‘æ‹“å±•\\n- é€²éšæ•¸å­¸ï¼šå­¸ç¿’å¯†åº¦çŸ©é™£ã€éƒ¨åˆ†è½‰ç½®ï¼ˆPPTï¼‰åˆ¤åˆ¥ã€è² æ€§ï¼ˆNegativityï¼‰ä½œç‚ºç³¾çºé‡åº¦ã€ Schmidt åˆ†è§£ç­‰å·¥å…·ã€‚\\n- ä¸ç­‰å¼èˆ‡å¯¦é©—è¨­è¨ˆï¼šç†Ÿæ‚‰ CHSH ä¸ç­‰å¼ã€å¯¦é©—ä¸­çš„æª¢æ¸¬ç‡ã€å±€åŸŸæ€§èˆ‡è‡ªç”±æ„å¿—å‡èªªç­‰å¯¦é©—ç´°ç¯€ã€‚\\n- é‡å­ç³¾çºèˆ‡é‡å­è¨ˆç®—çš„é€£çµï¼šç†è§£åœ¨é‡å­é›»è…¦ä¸­å¦‚ä½•ç”¨ç³¾çºä½œç‚ºé‡å­é–€å’Œå¤šé‡å­æ¯”ç‰¹å¹²æ¶‰çš„è³‡æºã€‚\\n- åƒè€ƒæ¡ˆä¾‹èˆ‡è®€ç‰©ï¼šEkert 1991 çš„ QKD è«–æ–‡ã€Bell ä¸ç­‰å¼çš„æ•™ç§‘æ›¸æ¨å°ã€Hensen/Shalm/Giustina ç­‰çš„å¯¦é©—å ±å‘Šï¼Œä»¥åŠã€ŒWerner stateã€ç­‰æ··åˆç‹€æ…‹çš„ç ”ç©¶ã€‚\\n\\nå¦‚æœä½ é¡˜æ„ï¼Œæˆ‘å¯ä»¥å†æ·±æŒ–æŸä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼š\\n- æ›´è©³ç´°çš„æ•¸å­¸æ¨å°ï¼ˆä¾‹å¦‚ Schmidt å±•é–‹ã€CHSH ä¸ç­‰å¼çš„æ¨å°èˆ‡é‡å­æ©Ÿåˆ¶ï¼‰\\n- å…·é«”å¯¦é©—è£ç½®èˆ‡æ¸¬é‡è¨­è¨ˆçš„ç‰©ç†åŸç†ï¼ˆæ¯”å¦‚ SPDC ç”¢ç”Ÿçš„ç³¾çºå…‰å­å°ã€é›¢å­é–˜æ§èˆ‡æ¸¬é‡ç­‰ï¼‰\\n- é‡å­ teleportationã€dense codingã€QKD çš„æ­¥é©Ÿèˆ‡å¯¦ä¾‹\\n\\nå‘Šè¨´æˆ‘ä½ æƒ³å…ˆæ·±æŒ–å“ªå€‹éƒ¨åˆ†ï¼Œæˆ‘å¯ä»¥çµ¦ä½ æ›´å…·é«”çš„èªªæ˜èˆ‡ä¾‹å­ã€‚ æ¨è–¦å¤§å®¶å¯ä»¥è‡ªå·±å»è©¦è©¦çœ‹è‡ªå·±å“ªç¨®çµ„åˆæ¯”è¼ƒå–œæ­¡ï¼Œç­†è€…æ˜¯æ¯”è¼ƒå–œæ­¡ Low çš„ç°¡çŸ­å›ç­”ã€‚\nç¯„ä¾‹ Codeï¼š\nfrom openai import OpenAI client = OpenAI( base_url=\u0026#34;\u0026lt;router-url\u0026gt;\u0026#34;, api_key=\u0026#34;\u0026lt;your-api-key\u0026gt;\u0026#34;, ) completion = client.chat.completions.create( model=\u0026#34;openai/gpt-5-nano\u0026#34;, reasoning_effort= \u0026#34;low\u0026#34;, verbosity=\u0026#39;low\u0026#39;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;ä½ æ˜¯ä¸€ä½ç§‘å­¸ç ”ç©¶åŠ©ç†ã€‚\u0026#34; } ] }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;è«‹è§£é‡‹é‡å­ç³¾çºã€‚\u0026#34; } ] } ] ) Reference # OpenAI Platform - Using GPT-5\n","date":"2025å¹´08æœˆ22æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/gpt-5_api_feature/","section":"Posts","summary":"\u003cp\u003eå› æ‡‰æœ€æ–°çš„ GPT-5 å‡ºä¾†çš„åŒæ™‚ API å¤šäº†å¹¾å€‹(å°æˆ‘ä¾†èªªçš„)æ–°åƒæ•¸ï¼ŒReasoning Effort è·Ÿ Verbosity\u003c/p\u003e","title":"New API feature in GPT-5","type":"posts"},{"content":"","date":"2025å¹´08æœˆ22æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/openai/","section":"Tags","summary":"","title":"OpenAI","type":"tags"},{"content":" Hi ğŸ‘‹, I\u0026rsquo;m OKH@nd_ZiYu # å¾ˆé«˜èˆˆèƒ½åœ¨é€™è£¡èˆ‡ä½ ç›¸é‡ã€‚\næˆ‘æ˜¯ä¸€åå·¥ç¨‹å¸«ï¼Œè‡´åŠ›æ–¼ç”¨æˆ‘æœ‰é™çš„çŸ¥è­˜ï¼Œå˜—è©¦å»æ”¹è®Šç¾ä»Šçš„æ•™è‚²åŠç¤¾æœƒï¼Œè®“ä¸–ç•Œè®Šå¾—æ›´ç¾å¥½ã€‚\né€™æ˜¯æˆ‘ç”¨ä¾†è¨˜éŒ„å­¸ç¿’ã€åˆ†äº«ç¶“é©—çš„è§’è½ã€‚\næˆ‘æœƒå°‡æ¥­ç•Œçš„å¯¦å‹™ç¶“é©—èˆ‡å­¸è¡“ä¸Šçš„æ–°çŸ¥çµåˆï¼Œè½‰åŒ–æˆå¥½æ‡‚ã€å¯¦ç”¨çš„å…§å®¹ã€‚\næˆ‘çš„ç›®æ¨™å¾ˆç°¡å–®ï¼šå¸Œæœ›é€éåˆ†äº«ï¼Œå¹«åŠ©åƒæˆ‘ä¸€æ¨£èµ°åœ¨æŠ€è¡“è·¯ä¸Šçš„å¤¥ä¼´ï¼Œä¸¦ä¸€èµ·æ€è€ƒå¦‚ä½•é‹ç”¨æˆ‘å€‘çš„æ‰€å­¸ï¼Œç‚ºæ•™è‚²èˆ‡ç¤¾æœƒå¸¶ä¾†æ­£å‘çš„æ”¹è®Šã€‚\nè¬è¬ä½ çš„ä¾†è¨ªï¼ŒæœŸå¾…èˆ‡ä½ ä¸€åŒæˆé•·ï¼\n","date":"2025å¹´08æœˆ15æ—¥","externalUrl":null,"permalink":"/zh-tw/about/","section":"OKH@nd's Blog","summary":"","title":"é—œæ–¼ æˆ‘","type":"page"},{"content":"","date":"2025å¹´06æœˆ20æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/cloudflare/","section":"Categories","summary":"","title":"Cloudflare","type":"categories"},{"content":"å› ç‚º Imgur å¤§ç´„å¾2025å¹´5æœˆ16æ—¥é–‹å§‹ï¼Œç„¡é è­¦åœ°å°é–äº†ä¾†è‡ªå°ç£çš„ IPï¼Œä¸å†å…è¨±å°ç£ä½¿ç”¨è€…ç™»å…¥æˆ–æ˜¯ä¸Šå‚³åœ–ç‰‡ç­‰\u0026hellip;å‹•ä½œã€‚æ‰€ä»¥å°±æƒ³èªªä¹‹å¾Œéƒ½æŠŠåœ–ç‰‡æ”¹æ”¾åœ¨ Cloudflare R2 ä¸Šé¢ã€‚\né€™é‚Šå…ˆå‡è¨­æˆ‘å€‘éƒ½æœ‰è‡ªå·±çš„ Domain åç¨±ï¼Œä¸¦ä¸”å·²ç¶“åœ¨ Cloudflare ä¸Šè¨­å®šå¥½äº†ã€‚ Cloudflare R2 çš„å¥½è™•æ˜¯ä»–æ˜¯èˆ‡ Amazon S3 API æ˜¯ç›¸å®¹çš„æ‰€ä»¥ä½ è¦ç™»å…¥å°±ç”¨ Amazon S3 çš„æ–¹å¼å°±èƒ½é€£æ¥æ“ä½œã€‚\nè²»ç”¨çš„éƒ¨åˆ†çœ‹é€™é‚Šï¼šcloudflare-r2 pricing\næˆ‘å€‘å…ˆå»ºç«‹ä¸€å€‹ Cloudflare R2 Storage\næ¥è‘—æˆ‘å€‘åˆ° è¨­å®š -\u0026gt; Custom Domains\nå»ºç«‹ä¸€å€‹å¯ä»¥è®“å¤–éƒ¨ä½¿ç”¨çš„è‡ªè¨‚åŸŸåï¼Œæˆ‘é€™é‚Šå°±ç”¨ myimage åŠ ä¸Šæˆ‘çš„ Domain ï¼Œå¦‚æœä½ æ˜¯ç”¨ Claudflare DNS çš„è©±ä»–æœƒè‡ªå‹•å¹«ä½ æ–°å¢ä¸Šå»ã€‚\nä¹‹å¾Œæˆ‘å€‘ç¢ºå®š ç‹€æ…‹æ˜¯\u0026quot;ä½¿ç”¨ä¸­\u0026quot; èˆ‡ Accessæ˜¯\u0026quot;å·²å•Ÿç”¨\u0026quot; æœ€å¾Œç¢ºèªä¸Šæ–¹å…¬é–‹å­˜å–çš„ç‹€æ…‹æ˜¯\u0026quot;å·²å•Ÿç”¨\u0026quot;å°±ä»£è¡¨å¯ä»¥æ‘Ÿï¼ï¼\nä¹‹å¾Œæˆ‘å€‘ä¾†è¨­å®š APIï¼Œé€™æ˜¯å¦‚æœä½ ä¸æƒ³åœ¨ç¶²é ä¸Šä½¿ç”¨å°±è¦è¨­å®šã€‚ é»æ“Š \u0026ldquo;ç®¡ç† API æ¬Šæ–\u0026rdquo;\næˆ‘é€™é‚Šæ˜¯å»ºç«‹ \u0026ldquo;ä½¿ç”¨è€… API æ¬Šæ–\u0026rdquo; æ¬Šé™ï¼šé¸æ“‡ \u0026ldquo;ç³»çµ±ç®¡ç†å“¡è®€å–å’Œå¯«å…¥\u0026rdquo; (çœ‹å€‹äººæˆ‘æ˜¯å› ç‚ºæ–¹ä¾¿æ“ä½œæ‰€ä»¥é¸æ“‡é€™å€‹) å»ºç«‹ä¹‹å¾Œå°±æœƒè·³å‡ºé‡‘é‘°é€™é‚Šè¦ä¿å­˜å¥½ï¼Œä¹‹å¾Œå°±èƒ½ç”¨é€™å€‹è·Ÿæˆ‘å€‘çš„ R2 é€£æ¥äº†ã€‚\nä¹‹å¾Œä½ è¦ä½¿ç”¨åˆ° R2 ä¸Šçš„æª”æ¡ˆæ™‚ URL æœƒé•·ä»¥ä¸‹é€™æ¨£\nç„¡è³‡æ–™å¤¾ URLï¼š https://\u0026lt;Custom_Domain\u0026gt;/\u0026lt;æª”å\u0026gt; æœ‰è³‡æ–™å¤¾ URLï¼š https://\u0026lt;Custom_Domain\u0026gt;/\u0026lt;è³‡æ–™å¤¾å\u0026gt;/\u0026lt;æª”å\u0026gt; ä¹‹å¾Œå°±èƒ½ç”¨ä½ æ–¹ä¾¿çš„å·¥å…·é€£ä¸Šé€²è¡Œæ”¾ç½®è³‡æ–™ç­‰ç­‰\u0026hellip;çš„æ“ä½œäº†ã€‚ ç°¡å–®å§ï¼ä¸éæœ€ç´¯çš„é‚„æ˜¯è¦æŠŠåœ–ç‰‡åˆ†é¡æ¬éå»\u0026hellip;.\nReference # Imgur å°é–å°ç£ IPï¼Œæˆ‘æŠŠåœ–åºŠæ¬åˆ° Cloudflare R2\næ¶è¨­Cloudflare R2å…è²»åœ–åºŠï¼Œçµ¦Hugoéœæ…‹ç¶²ç«™è¨—ç®¡åœ–ç‰‡\nç™½å«–CloudFlare R2æ­å»ºä¸ªäººå›¾åºŠ\n","date":"2025å¹´06æœˆ20æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/cloudflare-r2/","section":"Posts","summary":"\u003cp\u003eå› ç‚º Imgur å¤§ç´„å¾2025å¹´5æœˆ16æ—¥é–‹å§‹ï¼Œç„¡é è­¦åœ°å°é–äº†ä¾†è‡ªå°ç£çš„ IPï¼Œä¸å†å…è¨±å°ç£ä½¿ç”¨è€…ç™»å…¥æˆ–æ˜¯ä¸Šå‚³åœ–ç‰‡ç­‰\u0026hellip;å‹•ä½œã€‚æ‰€ä»¥å°±æƒ³èªªä¹‹å¾Œéƒ½æŠŠåœ–ç‰‡æ”¹æ”¾åœ¨ Cloudflare R2 ä¸Šé¢ã€‚\u003c/p\u003e","title":"Cloudflare R2","type":"posts"},{"content":"","date":"2025å¹´06æœˆ20æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/cloudflare-r2/","section":"Tags","summary":"","title":"Cloudflare-R2","type":"tags"},{"content":"","date":"2025å¹´06æœˆ20æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/storage/","section":"Tags","summary":"","title":"Storage","type":"tags"},{"content":"","date":"2025å¹´01æœˆ27æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/sid/","section":"Tags","summary":"","title":"SID","type":"tags"},{"content":"åœ¨ Windows ä¸Š Clone åŒä»½ Image ç‚ºå¤šå€‹ VM ä¸Šè¦åŠ å…¥ Domain æ™‚ç™¼ç”Ÿçš„ SID ç›¸åŒå•é¡Œèˆ‡è§£æ±ºæ–¹æ³•ï¼\næœ€è¿‘å› ç‚ºéœ€è¦å¯¦é©—æ±è¥¿ï¼Œæ‰€ä»¥ Clone åŒä¸€å°çš„ Image ç•¶ä½œ VM çš„åŸºåº•ï¼Œä½†ç•¶æˆ‘éœ€è¦åŠ å…¥ Domain æ™‚æœƒç™¼ç”Ÿ SID ç›¸åŒçš„å•é¡Œã€‚ æ ¹æ“šç¶²è·¯ä¸Šçš„æ–‡ç« æ˜¯èªªå¦‚æœéœ€è¦ Clone VM ä½¿ç”¨å»ºè­° Clone å‰å…ˆä½¿ç”¨ sysrep å»å»é™¤å®‰å…¨æ€§è­˜åˆ¥ç¢¼(SID)ç­‰ç­‰\u0026hellip;å³å¯è§£æ±ºé€™å•é¡Œã€‚ æˆ‘å€‘å¯ä»¥åˆ° Windows\\System32\\Sysrep ä¸‹æ‰¾åˆ°åŒåå·¥å…·ä¸¦ä½¿ç”¨ ä½¿ç”¨å®Œä¹‹å¾Œæœƒé‡æ–°è¨­å®šæ©Ÿå°çš„å¯†ç¢¼å°±å®Œæˆäº†ï¼ï¼\nReference # clone a windows VM with unique SSID - #2 by chivo243 - Virtualization - Spiceworks Community\nå¾·ç‘å…‹ï¼šSQL Server å­¸ç¿’ç­†è¨˜: Sysprep è®Šæ›´SID(Security Identifier)ï¼Œä»¥ Windows Server 2012 ç‚ºä¾‹\n","date":"2025å¹´01æœˆ27æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/win-sid-error/","section":"Posts","summary":"\u003cp\u003eåœ¨ Windows ä¸Š Clone åŒä»½ Image ç‚ºå¤šå€‹ VM ä¸Šè¦åŠ å…¥ Domain æ™‚ç™¼ç”Ÿçš„ SID ç›¸åŒå•é¡Œèˆ‡è§£æ±ºæ–¹æ³•ï¼\u003c/p\u003e","title":"Window SID ç›¸åŒéŒ¯èª¤","type":"posts"},{"content":"","date":"2025å¹´01æœˆ27æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/windows-server/","section":"Categories","summary":"","title":"Windows Server","type":"categories"},{"content":"","date":"2025å¹´01æœˆ26æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":"Claude Model Context Protocol(MCP)ï¼Œåœ¨ Windows ç’°å¢ƒä¸­ Step By Step å®‰è£æ­¥é©Ÿï¼\nç’°å¢ƒç¢ºèªï¼š # Enable Develop Mode Claude Desktop å·¦ä¸Šè§’é¸é … -\u0026gt; Help -\u0026gt; Enable Develop Mode æŒ‰ Enable ä¹‹å¾Œé‡å•Ÿå°±èƒ½åœ¨çœ‹åˆ° å·¦ä¸Šè§’é¸é … -\u0026gt; Developer -\u0026gt; Open MCP Log File\nç¢ºèª Node.js and Python Env\nç‰ˆæœ¬è¦æ±‚ï¼š\nNode.js \u0026gt;= 18 Python \u0026gt;= 3.10 Nodeï¼š\ninstall node.js or npm # Check Version Command node --version # or npm --version # Check root Path Command where node # or npm root -g # Record the paths returned by the last two commands - you\u0026#39;ll need them later # Ex: C:\\Users\\\u0026lt;UserName\u0026gt;\\AppData\\Roaming\\npm\\node_modules Pythonï¼š\ninstall python\u0026gt;=3.10 and \u0026ldquo;Add Python to PATH\u0026rdquo; # Check Python Version Command python -V # Show Env Python Version Python 3.12.8 Install Package Managers # å®‰è£ Python ç®¡ç†å¥—ä»¶ :\nnpm install -g uv Install MCP Servers # æœ‰ä¸‰ç¨®å®‰è£æ–¹å¼ npm(npx), uv, pip\nä½¿ç”¨ Global npm å®‰è£ï¼Œéœ€è¦çš„ Servers\n# Install core servers globally npm install -g @modelcontextprotocol/server-filesystem npm install -g @modelcontextprotocol/server-memory npm install -g @modelcontextprotocol/server-brave-search Python-based Servers\n# Using uvx uvx mcp-server-git # Using pip pip install mcp-server-git python -m mcp_server_git (Windows) Configure Claude Desktop\nClaude æ–‡ä»¶ä½ç½®ï¼š%AppData%\\Claude Desktop\\\nå‰µå»ºæˆ–ä¿®æ”¹ Claude Config æ–‡ä»¶ï¼šclaude_desktop_config.json\nConfig ä½¿ç”¨ä»¥ä¸‹ json é…ç½® (è«‹è‡ªè¡Œæ›¿æ›æˆä½ ç’°å¢ƒä¸­çš„ Node.js æˆ– npm è·¯å¾‘):\n{ \u0026#34;globalShortcut\u0026#34;: \u0026#34;Ctrl+Space\u0026#34;, \u0026#34;mcpServers\u0026#34;: { \u0026#34;sqlite\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;uvx\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;mcp-server-sqlite\u0026#34;, \u0026#34;--db-path\u0026#34;, \u0026#34;C:\\\\Users\\\\YourUsername\\\\test.db\u0026#34;] }, \u0026#34;filesystem\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;-y\u0026#34;, \u0026#34;@modelcontextprotocol/server-filesystem\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Downloads\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Documents\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Desktop\u0026#34; ], \u0026#34;env\u0026#34;: { \u0026#34;DEBUG\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;memory\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;C:\\\\Program Files\\\\nodejs\\\\node.exe\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\@modelcontextprotocol\\\\server-memory\\\\dist\\\\index.js\u0026#34; ], \u0026#34;env\u0026#34;: { \u0026#34;DEBUG\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;mcp-installer\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;@anaisbetts/mcp-installer\u0026#34; ] } } } è£œå……ï¼š\nMCP å®‰è£èˆ‡è³‡æ–™è¨­å®šå¥½å¾Œé‡å•Ÿ Claude Desktop é–‹é€²å»å› è©²å°±æœ‰é¡¯ç¤º MCP Tool å› ç‚ºæˆ‘å€‘é‚„æ²’è¨­å®šå¥½ SQLite æ‰€ä»¥æœƒæœ‰ Error SQLite æˆ‘æ˜¯ç”¨Dockeræ¶è¨­æ‰€ä»¥ç­‰ç­‰æœƒä¿®æ”¹ filesystem è£¡çš„ args ä¸­çš„ Path æ˜¯ä»–èƒ½ä½¿ç”¨åˆ°çš„åœ°æ–¹ memory ä¸­çš„ args è¦è¨­å®šæˆå‰›å‰› node or npm çš„ path ä¸­çš„ model ä½ç½® SQLite - Dockerç‰ˆ # modelcontextprotocol/servers - sqlite Â· GitHub\nå…ˆæŠŠæª”æ¡ˆä¸‹è¼‰ä¸‹ä¾†ä¸¦åŸ·è¡Œä¸‹åˆ— commandï¼š\ndocker build -t mcp/sqlite . docker volume create claude_sqlite ä¿®æ”¹ claude_desktop_config.jsonï¼š\n//claude_desktop_config.json \u0026#34;mcpServers\u0026#34;: { \u0026#34;sqlite\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;run\u0026#34;,\u0026#34;--rm\u0026#34;,\u0026#34;-i\u0026#34;,\u0026#34;-v\u0026#34;,\u0026#34;claude_sqlite:/mcp\u0026#34;,\u0026#34;mcp/sqlite\u0026#34;,\u0026#34;--db-path\u0026#34;,\u0026#34;/mcp/claude_sqlite.db\u0026#34;] }, } å˜—è©¦åŸ·è¡Œ Claude ä½¿ç”¨ MCPï¼š å˜—è©¦å«ä»–å¹«æˆ‘æ‰¾å°‹ D:\\Project åº•ä¸‹æœ‰å“ªäº›å°ˆæ¡ˆçš„è³‡æ–™å¤¾ ä»–æœƒå…ˆè·Ÿä½ ç¢ºèªè¦ç”¨å“ªå€‹ MCP Serve ä¸¦ä¹‹å¾ŒåŸ·è¡Œ å®Œç¾çš„æ‰¾å‡º Project ä¸‹çš„è³‡æ–™å¤¾æœ‰å“ªäº›ï¼ï¼ ä¹‹å¾Œè¦ä½¿ç”¨åˆ¥çš„å¥—ä»¶åŸºæœ¬ä¸Šä¹Ÿæ˜¯åƒç…§ MCP Server å®‰è£æ–¹å¼å®‰è£å³å¯ä½¿ç”¨ï¼ æª¢æŸ¥ MCP Server éŒ¯èª¤æ™‚å¯ä»¥é€é Developer ä¸­çš„ Open MCP Log File æª¢æŸ¥ Log\nReference # MCP-Windows Â· GitHub\nmodelcontextprotocol/servers: Model Context Protocol Servers Â· GitHub\nmodelcontextprotocol.io\n","date":"2025å¹´01æœˆ26æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/claude_mcp/","section":"Posts","summary":"\u003cp\u003eClaude Model Context Protocol(MCP)ï¼Œåœ¨ Windows ç’°å¢ƒä¸­ Step By Step å®‰è£æ­¥é©Ÿï¼\u003c/p\u003e","title":"Claude MCP","type":"posts"},{"content":"","date":"2025å¹´01æœˆ26æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/mcp/","section":"Tags","summary":"","title":"MCP","type":"tags"},{"content":"","date":"2025å¹´01æœˆ26æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/tool/","section":"Tags","summary":"","title":"Tool","type":"tags"},{"content":"","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/database/","section":"Categories","summary":"","title":"DataBase","type":"categories"},{"content":"","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/elastic/","section":"Tags","summary":"","title":"Elastic","type":"tags"},{"content":"ä»Šå¤©ä¾†å˜—è©¦ä½¿ç”¨ Elastic å‘é‡ DB è½èªªæ˜¯æœ‰é‡å°è³‡æ–™æœå°‹ç‰¹åŒ–çš„ä¸€å€‹å‘é‡DBï¼Œé‚£æˆ‘å€‘å°±ä¾†è©¦è©¦çœ‹å§ï¼ï¼\næˆ‘æ˜¯ä½¿ç”¨ Docker ä¾†æ­å»º Service æ‰€ä»¥ä»¥ä¸‹ç¯„ä¾‹éƒ½æ˜¯ä»¥ Docker ä¾†æ“ä½œã€‚ æˆ‘é€™é‚Šæ˜¯ä½¿ç”¨ Single Node ä¾†æ¶è¨­DBï¼Œä½†å› ç‚º Elastic æ˜¯å¯ä»¥æœ‰å¤šç¯€é»ä¾†ä½œåˆ†æ•£å¼å‚™ä»½ç­‰åŠŸèƒ½æœ‰èˆˆè¶£å¯ä»¥åƒè€ƒæœ€ä¸‹é¢çš„åƒè€ƒè³‡æ–™ã€‚\nå»ºç«‹ç’°å¢ƒ # Step1. (Option) Create a new docker network docker network create elastic Step2. docker run elastic é€™é‚Šæœ‰åˆ†æœ‰ç„¡è¦åœ¨ Elastic å…§éƒ¨ä½¿ç”¨ LLM è¨­å®šå› ç‚ºæœƒæœ‰é—œ Ram ä½¿ç”¨çš„å¤§å° æ™®é€šå»ºæ§‹ ç„¡é ˆåœ¨å…§éƒ¨ä½¿ç”¨ LLM docker run --name elasticsearch --net elastic -p 9200:9200 -it -m 1GB -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:8.16.1 éœ€ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’åŠŸèƒ½ï¼Œä¾‹å¦‚ä½¿ç”¨ ELSER é€²è¡Œèªç¾©æœç´¢Â éœ€è¦è¨˜æ†¶é«”è¶…é 1GB çš„æ›´å¤§å®¹å™¨ã€‚ docker run -d --name elasticsearch --net elastic -p 9200:9200 -m 6GB -it -e \u0026#34;xpack.ml.use_auto_machine_memory_percent=true\u0026#34; -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:8.16.1 è£œå……ï¼š ä¸è¦å•Ÿå‹• security feature (å¼·åˆ¶ä½¿ç”¨httpsé¸é …) â‡’ \u0026ldquo;xpack.security.enabled=false\u0026rdquo; è¨­å®š single-node â‡’ \u0026ldquo;discovery.type=single-node\u0026rdquo; Step3. Kibana çš„ elastic ä½¿ç”¨è€…å¯†ç¢¼å’Œè¨»å†Šä»¤ç‰Œ æˆ‘å€‘åœ¨æœ‰å•Ÿç”¨ security feature æƒ…æ³ä¸‹é¦–æ¬¡ç™»å…¥ elastic (https://0.0.0.0:9200) æ˜¯éœ€è¦è¼¸å…¥å¸³è™Ÿå¯†ç¢¼çš„ docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic å°±èƒ½çœ‹åˆ° elastic é‡è£½å¥½çš„å¯†ç¢¼é¡¯ç¤ºåœ¨ä¸Šé¢ â¯ docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic WARNING: Owner of file [/usr/share/elasticsearch/config/users] used to be [root], but now is [elasticsearch] WARNING: Owner of file [/usr/share/elasticsearch/config/users_roles] used to be [root], but now is [elasticsearch] This tool will reset the password of the [elastic] user to an autogenerated value. The password will be printed in the console. Please confirm that you would like to continue [y/N]y Password for the [elastic] user successfully reset. New value: 4If*lQS*fXrh3iq_bvnc What\u0026#39;s next: Try Docker Debug for seamless, persistent debugging tools in any container or image â†’ docker debug elasticsearch Learn more at https://docs.docker.com/go/debug-cli/ Step4. docker run kibana (GUI Web) é€™é‚Šå»ºç«‹ä¸€å€‹å®˜æ–¹ç”¨ä¾†æ–¹ä¾¿ç®¡ç† Elastic çš„ GUI Web Kibana docker run -d --name kibana --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.16.1 ä¹‹å¾Œæˆ‘å€‘å°±èƒ½åˆ° http://0.0.0.0:5601 çœ‹åˆ° Kibana Web ä¸€æ¨£å¦‚æœæœ‰å•Ÿç”¨ security feature æƒ…æ³ä¸‹é¦–æ¬¡ç™»å…¥Token Step5. å–å¾— Kibana Token docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana â¯ docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana eyJ2ZXIiOiI4LjE0LjAiLCJhZHIiOlsiMTcyLjE4LjAuMjo5MjAwIl0sImZnciI6ImJjMjI0N2Q3ODNlY2FjYWQ1Zjc0YzdlN2I4ZjM1YTU4YWMyYjBjZGM4NTI3Mzc5MWM0Yjc4OTVmNjQxMWIyNDUiLCJrZXkiOiJMOGFKZHBNQlRra0lBWHVNTk40Zzpqa3RxQ1Q4U1JHaXRlb25YMExjdm9RIn0= What\u0026#39;s next: Try Docker Debug for seamless, persistent debugging tools in any container or image â†’ docker debug elasticsearch Learn more at https://docs.docker.com/go/debug-cli/ ä¹‹å¾Œæˆ‘å€‘å°±èƒ½è¼¸å…¥Tokenï¼Œè®“ Kibana è·Ÿ Elastic é€£æ¥ä¹‹å¾Œå°±æœƒçœ‹åˆ°è¦è¼¸å…¥èªè­‰ Code Step6. å–å¾—èªè­‰ Code \u0026gt; docker exec -it kibana /bin/bash \u0026gt; kibana@da057b8cc1fa:~$ bin/kibana-verification-code Kibana is currently running with legacy OpenSSL providers enabled! For details and instructions on how to disable see https://www.elastic.co/guide/en/kibana/8.16/production.html#openssl-legacy-provider Your verification code is: 632 200 kibana@da057b8cc1fa:~$ æ‰‹å‹•å–æ¶ˆå®‰å…¨å®‰å…¨èªè­‰ # ç‚ºäº†ä¹‹å¾Œæˆ‘å€‘æ–¹ä¾¿é–‹ç™¼æ™‚é€£ç·šä¸ç”¨å¸¶é‡‘é‘°ç­‰ç­‰â€¦éº»ç…©çš„è¨­å®š\nElastic â¯ docker exec -u root -it elasticsearch /bin/bash root@1604ebd3d6d6:/usr/share/elasticsearch# cd config/ root@1604ebd3d6d6:/usr/share/elasticsearch/config# cat elasticsearch.yml cluster.name: \u0026#34;docker-cluster\u0026#34; network.host: 0.0.0.0 #----------------------- BEGIN SECURITY AUTO CONFIGURATION ----------------------- # # The following settings, TLS certificates, and keys have been automatically # generated to configure Elasticsearch security features on 29-11-2024 07:00:36 # # -------------------------------------------------------------------------------- # Enable security features xpack.security.enabled: false xpack.security.enrollment.enabled: true # Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents xpack.security.http.ssl: enabled: false keystore.path: certs/http.p12 # Enable encryption and mutual authentication between cluster nodes xpack.security.transport.ssl: enabled: true verification_mode: certificate keystore.path: certs/transport.p12 truststore.path: certs/transport.p12 #----------------------- END SECURITY AUTO CONFIGURATION ------------------------- root@1604ebd3d6d6:/usr/share/elasticsearch/config# è£œå……ï¼š é€™é‚Šæ˜¯è¦æŠŠ xpack.security.enabled è·Ÿ xpack.security.http.ssl ä¿®æ”¹æˆ false å³å¯ Kibana â¯ docker exec -u root -it kibana /bin/bash root@7bf3cda51529:/usr/share/kibana# cd config/ root@7bf3cda51529:/usr/share/kibana/config# cat kibana.yml # # ** THIS IS AN AUTO-GENERATED FILE ** # # Default Kibana configuration for docker target server.host: \u0026#34;0.0.0.0\u0026#34; server.shutdownTimeout: \u0026#34;5s\u0026#34; elasticsearch.hosts: [ \u0026#34;http://elasticsearch:9200\u0026#34; ] monitoring.ui.container.elasticsearch.enabled: true root@7bf3cda51529:/usr/share/kibana/config# è£œå……ï¼š elasticsearch.hosts: [ \u0026ldquo;http://elasticsearch:9200\u0026rdquo; ] é€™é‚Šçš„ elasticsearch æ˜¯ä¾ç…§ä½ çš„ elastic çš„ container åå»ä¿®æ”¹(é€™æ˜¯å› ç‚º DNSæŒ‡å‘çš„é—œä¿‚) , ä¸¦ä¸”æ³¨æ„è¦æ˜¯ http é–‹é ­ åœç”¨å¾Œé é¢æœƒé¡¯ç¤º Could not retrieve current user, security plugin is not ready ä¸ç”¨æ€•ç…§æ¨£èƒ½ç”¨ é€™æ¨£å°±å»ºç«‹å¥½ä¸€å€‹ ElasticSearch çš„æœå‹™äº†ï¼ï¼\nReference # [Elasticsearch] åˆ†æ•£å¼ç‰¹æ€§ \u0026amp; åˆ†æ•£å¼æœå°‹çš„æ©Ÿåˆ¶ - å°ä¿¡è±¬çš„åŸå§‹éƒ¨è½\n","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/elastic/","section":"Posts","summary":"\u003cp\u003eä»Šå¤©ä¾†å˜—è©¦ä½¿ç”¨ Elastic å‘é‡ DB è½èªªæ˜¯æœ‰é‡å°è³‡æ–™æœå°‹ç‰¹åŒ–çš„ä¸€å€‹å‘é‡DBï¼Œé‚£æˆ‘å€‘å°±ä¾†è©¦è©¦çœ‹å§ï¼ï¼\u003c/p\u003e","title":"Elastic æ­å»º","type":"posts"},{"content":"æƒ³èªªéƒ½å»ºç«‹ Elastic ä¸è©¦è©¦çœ‹é€™ DB çš„æœå°‹æ•ˆæœå°±ä¸å¤ æ„æ€äº†å§ï¼Œå°±æœ‰äº†é€™ç¯‡ Elastic æœå°‹ç¯‡\nä¸Šæ¬¡æˆ‘å€‘å»ºç«‹å¥½äº†ä¸€å€‹åŸºç¤çš„ Elastic ç’°å¢ƒï¼Œé€™éƒ¨ä»½å°±ä¾†è©¦è©¦å¦‚ä½•æ·»åŠ è³‡æ–™é€² Elastic ä¸¦æœå°‹å‡ºä¾†ã€‚\nï¼ï¼æ³¨æ„ï¼ï¼ ä»¥ä¸‹å› ç‚º Elastic å·²é—œé–‰å®‰å…¨é©—è­‰ï¼Œä¸¦ä¸”æ¥æ˜¯ä½¿ç”¨ Python å»ä½œæ“ä½œ\nNormal Search # å¯«å…¥ Data # from elasticsearch import Elasticsearch # 1. é€£æ¥åˆ° Elasticsearch es = Elasticsearch(\u0026#34;http://172.20.10.8:9200/\u0026#34;) # ç¢ºä¿ Elasticsearch åœ¨è©²ä½å€é‹è¡Œ # 2. å»ºç«‹ç´¢å¼• index_name = \u0026#34;defect_data\u0026#34; mapping = { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;project\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # æ–°å¢ keyword é¡å‹ } }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # æ–°å¢ keyword é¡å‹ } }, \u0026#34;description\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, \u0026#34;project_title\u0026#34;: { # çµ„åˆç´¢å¼•æ¬„ä½ \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } } if not es.indices.exists(index=index_name): es.indices.create(index=index_name, body=mapping) print(f\u0026#34;Index \u0026#39;{index_name}\u0026#39; created.\u0026#34;) # 3. æ’å…¥æ–‡ä»¶ for key, value in data.items(): title = key description = value document = { \u0026#34;project\u0026#34;: f\u0026#34;{project}\u0026#34;, \u0026#34;title\u0026#34;: f\u0026#34;{title}\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;{description}\u0026#34;, \u0026#34;project_title\u0026#34;: f\u0026#34;{project}|{title}\u0026#34; # çµ„åˆç´¢å¼•å€¼ } # æª¢æŸ¥æ˜¯å¦åœ¨åŒä¸€å€‹ Project ä¸‹æœ‰ç›¸åŒçš„ Title query = { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;project_title\u0026#34;: f\u0026#34;{project}|{title}\u0026#34; } } } search_response = es.search(index=index_name, body=query) if search_response[\u0026#34;hits\u0026#34;][\u0026#34;total\u0026#34;][\u0026#34;value\u0026#34;] == 0: response = es.index(index=index_name, body=document) print(\u0026#34;Document inserted:\u0026#34;, response) else: print(\u0026#34;Document already exists. Skipping insert.\u0026#34;) æŸ¥è©¢ # from elasticsearch import Elasticsearch # 1. é€£æ¥åˆ° Elasticsearch es = Elasticsearch(\u0026#34;http://0.0.0.0:9200/\u0026#34;) # ç¢ºä¿ Elasticsearch åœ¨è©²ä½å€é‹è¡Œ index_name = \u0026#34;defect_data\u0026#34; query = { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;RM\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;] } } } search_response = es.search(index=index_name, body=query) print(len(search_response[\u0026#39;hits\u0026#39;][\u0026#39;hits\u0026#39;])) for hits in search_response[\u0026#39;hits\u0026#39;][\u0026#39;hits\u0026#39;]: print(hits) print(\u0026#34;===================\u0026#34;) Hybrid Search # æ­¤æ–¹æ³•æ˜¯è—‰ç”±å¤–éƒ¨å•Ÿå‹• LLM Embedding æ‰€ä»¥ä¸ç”¨æ­å»ºè¼ƒå¤š Ram çš„ Elastic\nå¯«å…¥ Data # from elasticsearch import Elasticsearch from sentence_transformers import SentenceTransformer # åˆå§‹åŒ– Elasticsearch å®¢æˆ¶ç«¯ es = Elasticsearch(\u0026#34;http://0.0.0.0:9200\u0026#34;) model = SentenceTransformer(\u0026#34;Alibaba-NLP/gte-Qwen2-1.5B-instruct\u0026#34;, trust_remote_code=True) # In case you want to reduce the maximum length: model.max_seq_length = 131072 def generate_embedding(text): # ä½¿ç”¨ SentenceTransformer ç›´æ¥ç”ŸæˆåµŒå…¥ embedding = model.encode(text, convert_to_numpy=True) # å¦‚æœéœ€è¦è½‰æ›ç‚ºåˆ—è¡¨ï¼Œä½¿ç”¨ tolist() return embedding.tolist() # å®šç¾©ç´¢å¼•çµæ§‹ï¼ŒåŒ…å« kNN å‘é‡æ¬„ä½ index_name = \u0026#34;defect_embed_data\u0026#34; index_mapping = { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;project\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # ä¿ç•™ keyword ç”¨æ–¼ç²¾ç¢ºæŸ¥è©¢ } }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # ä¿ç•™ keyword ç”¨æ–¼ç²¾ç¢ºæŸ¥è©¢ } }, \u0026#34;description\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; # ä¿ç•™ description ä½œç‚ºå…¨æ–‡æª¢ç´¢ç”¨ }, \u0026#34;project_title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; # ç”¨æ–¼çµ„åˆç´¢å¼•æŸ¥è©¢ }, \u0026#34;embedding\u0026#34;: { # æ–°å¢ embedding æ¬„ä½ \u0026#34;type\u0026#34;: \u0026#34;dense_vector\u0026#34;, \u0026#34;dims\u0026#34;: 1536, # åµŒå…¥å‘é‡çš„ç¶­åº¦ï¼Œéœ€èˆ‡åµŒå…¥æ¨¡å‹ä¸€è‡´ \u0026#34;similarity\u0026#34;: \u0026#34;cosine\u0026#34; } } } } # å»ºç«‹ç´¢å¼• if not es.indices.exists(index=index_name): es.indices.create(index=index_name, body=index_mapping) data = [ { \u0026#34;project\u0026#34;: \u0026#34;Login System\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Fix login timeout issue\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Users are experiencing timeouts when logging in.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;Login System - Fix login timeout issue\u0026#34; }, { \u0026#34;project\u0026#34;: \u0026#34;Database\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Database connection failure\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Database connection intermittently fails.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;Database - Connection failure\u0026#34; }, { \u0026#34;project\u0026#34;: \u0026#34;UI\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;UI layout breaks on small screens\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Responsive design issue causing layout to break.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;UI - Layout issue on small screens\u0026#34; } ] # åŒ¯å…¥è³‡æ–™åˆ° Elasticsearch for record in data: embedding = generate_embedding(record[\u0026#34;title\u0026#34;]) # ç”ŸæˆåµŒå…¥å‘é‡ record[\u0026#34;embedding\u0026#34;] = embedding # åŠ å…¥åµŒå…¥ es.index(index=index_name, body=record) # åŒ¯å…¥åˆ° Elasticsearch print(\u0026#34;è³‡æ–™åŒ¯å…¥å®Œæˆ\u0026#34;) å‘é‡æŸ¥è©¢ # # æŸ¥è©¢æ¨™é¡Œ query_title = \u0026#34;Timeout during login\u0026#34; # ç”ŸæˆæŸ¥è©¢å‘é‡ query_vector = generate_embedding(query_title) # kNN æœå°‹ knn_query = { \u0026#34;size\u0026#34;: 5, # è¿”å›æœ€ç›¸ä¼¼çš„ 5 ç­†çµæœ \u0026#34;knn\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;embedding\u0026#34;, \u0026#34;query_vector\u0026#34;: query_vector, \u0026#34;k\u0026#34;: 10, \u0026#34;num_candidates\u0026#34;: 100 }, \u0026#34;_source\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;] # æŒ‡å®šè¿”å›çš„æ¬„ä½ } # åŸ·è¡ŒæŸ¥è©¢ response = es.search(index=index_name, body=knn_query) # é¡¯ç¤ºçµæœ for hit in response[\u0026#34;hits\u0026#34;][\u0026#34;hits\u0026#34;]: print(f\u0026#34;Title: {hit[\u0026#39;_source\u0026#39;][\u0026#39;title\u0026#39;]}, Score: {hit[\u0026#39;_score\u0026#39;]}\u0026#34;) Hybrid æŸ¥è©¢ # # æ§‹å»º Hybrid æŸ¥è©¢ query_text = \u0026#34;Troubleshooting login issues\u0026#34; query_vector = generate_embedding(query_text) # ç”ŸæˆæŸ¥è©¢å‘é‡ hybrid_query = { \u0026#34;size\u0026#34;: 5, \u0026#34;_source\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: query_title, \u0026#34;boost\u0026#34;: 1.5 # å¯é¸ï¼šæé«˜æ¨™é¡ŒåŒ¹é…çš„æ¬Šé‡ } } }, { \u0026#34;match\u0026#34;: { \u0026#34;description\u0026#34;: { \u0026#34;query\u0026#34;: query_title, \u0026#34;boost\u0026#34;: 1.0 } } }, { \u0026#34;script_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;exists\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;embedding\u0026#34; # ç¢ºä¿æ–‡æª”æœ‰ embedding æ¬„ä½ } }, \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;cosineSimilarity(params.query_vector, \u0026#39;embedding\u0026#39;) + 1.0\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;query_vector\u0026#34;: query_vector } }, \u0026#34;boost\u0026#34;: 0.5 # å‘é‡ç›¸ä¼¼æ€§çš„æ¬Šé‡ } } ], \u0026#34;minimum_should_match\u0026#34;: 1 } } } è£œå……ï¼š å¦‚æœæ˜¯è¦å°å…¨æ–‡ä»¶å‘é‡æœå°‹ script_score å¯ä»¥æ”¹æˆä»¥ä¸‹\n# åŒ¹é…æ‰€æœ‰æ–‡æª”çš„æŸ¥è©¢ \u0026#34;script_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, ç¸½çµï¼š\næ™®é€šæœå°‹ï¼š Elastic å…ˆæŠŠå¥å­æŠŠä½ çš„å­—è©è¨˜ä¸‹åœ°ç†ä½ç½®ï¼Œä¹‹å¾Œæœå°‹æ™‚ä¾ç…§ä½ è¼¸å…¥çš„è©å½™å»å°æ‡‰åœ°å€å»æœå°‹å¤§è‡´ç›¸å°æ‡‰åœ°ç†ä½ç½®çš„DBä¸­çš„å¥å­ï¼Œä¸¦ä½¿ç”¨ BM25 æ–¹å¼å€å°ä½ çš„å¥å­å»æœå°‹ï¼Œä¾ç…§å‡ºç¾çš„é »ç‡å»è¨ˆç®—å¹³å‡å‡ºç¾æ©Ÿç‡ã€‚ å‘é‡æœå°‹ï¼š æ˜¯ä¾ç…§å¥å­è½‰æ›æˆå‘é‡ä¹‹å¾Œå»ä½¿ç”¨ æ­æ°è·é›¢ èˆ‡ é¤˜å¼¦ç›¸ä¼¼åº¦ å»æœå°‹ç›¸ä¼¼åº¦ã€‚ æ··åˆæœå°‹ï¼š é€éä½ è¨­å®šæ™®é€šæœå°‹æœƒæœ‰åˆ†æ•¸ï¼Œå‘é‡æœå°‹ä¹Ÿæœƒæœ‰åˆ†æ•¸ï¼Œä¹‹å¾Œé€é script_score çš„è¨ˆç®—æ–¹å¼å»è¨ˆç®—å‡ºä½ çš„æ··åˆåˆ†æ•¸ã€‚ Reference # å¯†é›†å‘é‡æ¬„ä½é¡å‹ - elastic ä¸­æ–‡\n","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/hybrid-search/","section":"Posts","summary":"\u003cp\u003eæƒ³èªªéƒ½å»ºç«‹ Elastic ä¸è©¦è©¦çœ‹é€™ DB çš„æœå°‹æ•ˆæœå°±ä¸å¤ æ„æ€äº†å§ï¼Œå°±æœ‰äº†é€™ç¯‡ Elastic æœå°‹ç¯‡\u003c/p\u003e","title":"Hybrid Search","type":"posts"},{"content":"","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/rag/","section":"Tags","summary":"","title":"RAG","type":"tags"},{"content":"","date":"2024å¹´12æœˆ05æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/vectordb/","section":"Tags","summary":"","title":"VectorDB","type":"tags"},{"content":"","date":"2024å¹´11æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/environment/","section":"Categories","summary":"","title":"Environment","type":"categories"},{"content":"","date":"2024å¹´11æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/gpu/","section":"Tags","summary":"","title":"GPU","type":"tags"},{"content":"","date":"2024å¹´11æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/nvdia/","section":"Tags","summary":"","title":"NVDIA","type":"tags"},{"content":"å› ç‚ºNvidiaé©…å‹•æ¯æ¬¡éƒ½æœƒè«åå…¶å¦™ä¸è¦‹ï¼Œç„¶å¾Œåˆè¦é‡è£å¥—ä»¶ï¼Œç´€éŒ„ä¸€ä¸‹å¦‚ä½•å®Œæ•´çš„ç§»é™¤é©…å‹•èˆ‡å¥—ä»¶ã€‚\næŸ¥çœ‹æ˜¯å¦æœ‰ nvidia é©…å‹•ï¼š dpkg -l | grep -i nvidia ç§»é™¤nvidia-cuda-toolkité©…å‹•ï¼š åªç§»é™¤nvidia-cuda-toolkité©…å‹• sudo apt-get remove nvidia-cuda-toolkit ç§»é™¤nvidia-cuda-toolkitåŠå…¶ä¾è³´å¥—ä»¶ sudo apt-get remove --auto-remove nvidia-cuda-toolkit ç§»é™¤ nvidia-cuda-toolkitèˆ‡å…¶ä¾è³´å¥—ä»¶è·Ÿç’°å¢ƒé…ç½®ï¼š sudo apt-get purge --auto-remove nvidia-cuda-toolkit ç§»é™¤æ‰€æœ‰é—œæ–¼cudaçš„å†…å®¹ï¼š sudo apt-get --purge -y remove \u0026#39;cuda*\u0026#39; # cuda10.1åŠä»¥ä¸Šçš„å¸è½½ cd /usr/local/cuda-xx.x/bin/ sudo ./cuda-uninstaller sudo rm -rf /usr/local/cuda-xx.x ç§»é™¤æ‰€æœ‰é—œæ–¼nvidiaçš„å†…å®¹ï¼š sudo apt-get --purge -y remove \u0026#39;nvidia*\u0026#39; æª¢æŸ¥cudaçš„æ–‡ä»¶å¤¾æ˜¯å¦é‚„å­˜åœ¨ï¼š ls /usr/local/ | grep cuda Rebootï¼š sudo reboot æŸ¥çœ‹æ˜¯å¦æœ‰ cudnn é©…å‹•ï¼š dpkg -l | grep cudnn ç§»é™¤ cudnn é©…å‹•ï¼š ç§»é™¤å‰›å‰›æŸ¥è©¢åˆ°ç³»ç»Ÿä¸­å­˜åœ¨çš„cudnnå¥—ä»¶, command ä»¥ cudnn8 ç‚ºä¾‹ sudo dpkg --remove libcudnn8 libcudnn8-dev libcudnn9-samples Reference # Ubuntuä¸‹å®Œå…¨ç§»é™¤cudaå’Œnvidiaé©±åŠ¨å¹¶é‡æ–°å®‰è£…æ–°ç‰ˆæœ¬cuda_ubuntuå¸è½½cuda toolkit-CSDNåšå®¢\n","date":"2024å¹´11æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/nvdriver-rm/","section":"Posts","summary":"\u003cp\u003eå› ç‚ºNvidiaé©…å‹•æ¯æ¬¡éƒ½æœƒè«åå…¶å¦™ä¸è¦‹ï¼Œç„¶å¾Œåˆè¦é‡è£å¥—ä»¶ï¼Œç´€éŒ„ä¸€ä¸‹å¦‚ä½•å®Œæ•´çš„ç§»é™¤é©…å‹•èˆ‡å¥—ä»¶ã€‚\u003c/p\u003e","title":"ç§»é™¤ Nvidia é©…å‹•èˆ‡ CUDA å¥—ä»¶","type":"posts"},{"content":"æœ€è¿‘åœ¨å¯« Python æƒ³èªªæŠŠä¸€äº› Model åŒ¯èšæˆä¸€å€‹ Package ä½¿ç”¨æ™‚ï¼Œçªç„¶ç™¼ç¾å¥½åƒæ²’æœ‰ä¸€å€‹åƒ Next.js é‚£ç¨®å»ºç«‹ä¸€å€‹åˆå§‹åŒ– Templates çš„å·¥å…·ï¼Œç„¶å¾Œæˆ‘å°±æ‰¾åˆ°äº†é€™å€‹ã€‚\nCookiecutter # GitHubï¼šCookiecutter - GitHub\nInstallationï¼š\npip install cookiecutter ä¹‹å¾Œå°±æ˜¯æ‰¾åˆ°ä½ éœ€è¦ç”¨çš„ Templateï¼š cookiecutter.io\nCookiecutter: æ›´å¥½çš„é¡¹ç›®æ¨¡æ¿å·¥å…· ç®€ä»‹åŠå¯ç”¨èµ„æºæ±‡æ€» - åšå®¢åœ’\næ‰¾åˆ°ä¹‹å¾Œä¸‹è¼‰ä¸¦ä½¿ç”¨ï¼Œä¾‹å¦‚æˆ‘æ‰¾åˆ°çš„é€™å€‹ cookiecutter-pypackageï¼š\ncookiecutter https://github.com/audreyfeldroy/cookiecutter-pypackage.git Reference # Cookiecutter - GitHub\ncookiecutter.io\nCookiecutter: æ›´å¥½çš„é¡¹ç›®æ¨¡æ¿å·¥å…· ç®€ä»‹åŠå¯ç”¨èµ„æºæ±‡æ€» - åšå®¢åœ’\n","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/cookiecutter/","section":"Posts","summary":"\u003cp\u003eæœ€è¿‘åœ¨å¯« Python æƒ³èªªæŠŠä¸€äº› Model åŒ¯èšæˆä¸€å€‹ Package ä½¿ç”¨æ™‚ï¼Œçªç„¶ç™¼ç¾å¥½åƒæ²’æœ‰ä¸€å€‹åƒ Next.js é‚£ç¨®å»ºç«‹ä¸€å€‹åˆå§‹åŒ– Templates çš„å·¥å…·ï¼Œç„¶å¾Œæˆ‘å°±æ‰¾åˆ°äº†é€™å€‹ã€‚\u003c/p\u003e","title":"Cookiecutter","type":"posts"},{"content":"","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/python/","section":"Categories","summary":"","title":"Python","type":"categories"},{"content":"","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/conda/","section":"Tags","summary":"","title":"Conda","type":"tags"},{"content":"æŸæ¬¡å›  Server ä¸Šéœ€å…ˆæ› Proxy å¾Œæ‰èƒ½ä¸Šç¶²å°è‡´ Python å®‰è£å¥—ä»¶éç¨‹ä¸­éœ€è¦è¨­å®š Proxy æ‰èƒ½ä¸‹è¼‰å¥—ä»¶ç´€éŒ„ã€‚\nConda and Pip Proxy Setting # Conda Proxy Setting # conda config --set proxy_servers.http http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; conda config --set proxy_servers.https http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; Pip Proxy Setting # pip config set global.proxy http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; Writing to /root/.config/pip/pip ","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/pypi_proxy/","section":"Posts","summary":"\u003cp\u003eæŸæ¬¡å›  Server ä¸Šéœ€å…ˆæ› Proxy å¾Œæ‰èƒ½ä¸Šç¶²å°è‡´ Python å®‰è£å¥—ä»¶éç¨‹ä¸­éœ€è¦è¨­å®š Proxy æ‰èƒ½ä¸‹è¼‰å¥—ä»¶ç´€éŒ„ã€‚\u003c/p\u003e","title":"Conda \u0026 Pip Proxy è¨­å®š","type":"posts"},{"content":"","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/pip/","section":"Tags","summary":"","title":"Pip","type":"tags"},{"content":"","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/proxy/","section":"Tags","summary":"","title":"Proxy","type":"tags"},{"content":"","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/testlink/","section":"Tags","summary":"","title":"TestLink","type":"tags"},{"content":"æœ¬æ–‡è¬›è¿°ç•¶åˆå‰›ä½¿ç”¨ TestLink æ™‚æƒ³é€é TestLink çš„ API å»äº’å‹•æ™‚é‡åˆ°çš„å•é¡Œä¸¦è§£æ±ºçš„ç´€éŒ„ï¼ï¼\nç•¶åˆåœ¨ä½¿ç”¨ TestLink API æ™‚æœ‰å ± xmlrpc çš„éŒ¯èª¤æ‰€ä»¥ä¾†è¨˜éŒ„ä¸€ä¸‹è§£æ±ºæ–¹æ³• ä½¿ç”¨ Docker æˆ–æ˜¯ ä½¿ç”¨ Local å®‰è£ TestLink è¦ä½¿ç”¨ TestLink æœ¬èº«çš„ API æ™‚éœ€è¦é–‹å•Ÿå¹¾å€‹è¨­å®š! ç”¨ Local å®‰è£ TestLink åœ¨å®‰è£çš„åœ°æ–¹ä¸‹å› è©²ä¹Ÿèƒ½æ‰¾åˆ°é€™å…©å€‹æª”æ¡ˆ ä¸‹é¢æ˜¯ä»¥ Docker ä¾†ç¤ºç¯„ï¸°\nä¿®æ”¹ config.inc.php æª”æ¡ˆä½ç½®ï¸°/opt/bitnami/testlink ä¿®æ”¹æª”æ¡ˆè£¡çš„ config $tlCfg-\u0026gt;exec_cfg-\u0026gt;enable_test_automation = ENABLED; $tlCfg-\u0026gt;api-\u0026gt;enabled = TRUE; ä¿®æ”¹ xmlrpc.php æª”æ¡ˆä½ç½®ï¸°/opt/bitnami/testlink/lib/api/xmlrpc/v1 ä¿®æ”¹ä¸¦æ·»åŠ åˆ°æª”æ¡ˆåº•ä¸‹ require_once(\u0026#34;xmlrpc.class.php\u0026#34;); define(\u0026#39;XMLRPC_REQUEST\u0026#39;, true); // Some browser-embedded clients send cookies. We don\u0026#39;t want them.`Â `$_COOKIE = array(); $GLOBALS[\u0026#39;HTTP_RAW_POST_DATA\u0026#39;] = file_get_contents(\u0026#34;php://input\u0026#34;);` $XMLRPCServer = new TestlinkXMLRPCServer(); é€™æ¨£è¨­å®šå®Œä¹‹å¾Œå°±èƒ½ä½¿ç”¨ TestLink çš„ API é€²è¡Œå° TestLink æ“ä½œäº†!!\nReference # java - TestLink XML-RPC The call to the xml-rpc client failed - Stack Overflow\nTestLink 1.8.5: How to configure TestLink to enable XMLRPC - TestLink\ntestlink-code/lib/api/xmlrpc/v1/xmlrpc.class.php at testlink_1_9 Â· TestLinkOpenSourceTRMS/testlink-code Â· GitHub\n","date":"2024å¹´09æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/testlink-api-enabled/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡è¬›è¿°ç•¶åˆå‰›ä½¿ç”¨ TestLink æ™‚æƒ³é€é TestLink çš„ API å»äº’å‹•æ™‚é‡åˆ°çš„å•é¡Œä¸¦è§£æ±ºçš„ç´€éŒ„ï¼ï¼\u003c/p\u003e","title":"Testlink Api Enabled","type":"posts"},{"content":"","date":"2024å¹´09æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/a100/","section":"Tags","summary":"","title":"A100","type":"tags"},{"content":"å‰›å¥½æœ‰å¹¸ç”¨åˆ° 8 Core 80G GPU çš„ A100 æ©Ÿå°ï¼Œä½†ä»¥ç‚ºè¨­å®šè·Ÿä¹‹å‰ä¸€æ¨£å»è¦ç”¨ CUDA è·‘ LLM æ™‚é‡åˆ°å•é¡Œä¸¦ç´€éŒ„è§£æ±ºæ–¹æ³•ã€‚\nç•¶ä½ ä»Šå¤©æ˜¯ä½¿ç”¨ ( V100 / A100 / A30 \u0026hellip;ç­‰ç­‰ ) æ™‚å› ç‚ºæ˜¯ä½¿ç”¨ NVSwitch é€£é€šæ‰€ä»¥éœ€è¦å®‰è£ 3 ä»¥å¾Œçš„æ­¥é©Ÿæ‰èƒ½æ­£å¸¸ä½¿ç”¨ NVIDA GPU çš„åŠŸèƒ½\nInstall CUDA\nFollow: CUDA Toolkit 12.6 Downloads | NVIDIA Developer\nBase Installer:\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda-repo-ubuntu2204-12-6-local_12.6.0-560.28.03-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-6-local_12.6.0-560.28.03-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-6 Driver Installer:\nsudo apt-get install -y nvidia-open Setting NVCC: Command ä¸­çš„ cuda-12 è«‹ä¾ç…§ä½ å®‰è£çš„ç‰ˆæœ¬å»æ›¿æ› sudo vim ~/.bashrc export PATH=/usr/local/cuda-12/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-12/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} Install cuDNN\nFollow: cuDNN 9.3.0 Downloads | NVIDIA Developer\nBase Installer:\nwget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2204-9.3.0/cudnn-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cudnn If install specific CUDA version package:\nsudo apt-get -y install cudnn-cuda-\u0026lt;CUDA-Version\u0026gt; Install libfreeimage:\nsudo apt install libfreeimage-dev Test cuDNN:\ngit clone https://github.com/NVIDIA/cuda-samples.git cd cuda-samples/Samples/bandwidthTest make ./bandwidthTest å¦‚æœå¤±æ•—è«‹å®‰è£æ¥ä¸‹ä¾†çš„æ­¥é©Ÿ\nInstall DCGM\nFollow: NVIDIA DCGM | NVIDIA Developer\nsudo apt-get update sudo apt-get install -y datacenter-gpu-manager Install nvidia-fabricmanager\nFollow: fabric-manager-user-guide.pdf (nvidia.com) - Chapter 2.6\nversion=\u0026lt;your-gpu-Driver Version\u0026gt; main_version=$(echo $version | awk -F \u0026#39;.\u0026#39; \u0026#39;{print $1}\u0026#39;) apt-get update apt-get -y install nvidia-fabricmanager-${main_version}=${version}-* Nvidia-smi: +-----------------------------------------------------------------------------------------+ | NVIDIA-SMI 560.35.03 Driver Version: 560.35.03 CUDA Version: 12.6 | |-----------------------------------------+------------------------+----------------------+ ä»¥æ­¤ç‚ºä¾‹ version = 560.35.03 Disabel nv-hostengine\nsudo nv-hostengine -t Start the fabricmanager\nsudo service nvidia-fabricmanager start Test cuDNN again\ngit clone https://github.com/NVIDIA/cuda-samples.git cd cuda-samples/Samples/bandwidthTest make ./bandwidthT root@test-ORACLE-SERVER-E4-2c:~/cudnn_samples_v9/mnistCUDNN# ./mnistCUDNN Executing: mnistCUDNN cudnnGetVersion() : 90400 , CUDNN_VERSION from cudnn.h : 90400 (9.4.0) Host compiler version : GCC 11.4.0 There are 8 CUDA capable devices on your machine : device 0 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=0 device 1 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=1 device 2 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=2 device 3 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=3 device 4 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=4 device 5 : sms 108 Capabilities 8.0, SmClok 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=5 device 6 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=6 device 7 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=7 Using device 0 Testing single precision Loading binary file data/conv1.bin Loading binary file data/conv1.bias.bin Loading binary file data/conv2.bin Loading binary file data/conv2.bias.bin Loading binary file data/ip1.bin Loading binary file data/ip1.bias.bin Loading binary file data/ip2.bin Loading binary file data/ip2.bias.bin Loading image data/one_28x28.pgm Performing forward propagation ... Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.027648 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.036864 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.062464 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.070656 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.091136 time requiring 2057744 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.092160 time requiring 184784 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 129072 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.055296 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.064512 time requiring 1433120 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.090112 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.093184 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.098304 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.189440 time requiring 129072 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Resulting weights from Softmax: 0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 Loading image data/three_28x28.pgm Performing forward propagation ... Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.023552 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.026624 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.028672 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.057344 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.057344 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.064512 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 129072 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.053248 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.055296 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.063488 time requiring 1433120 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.064512 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.092160 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.102400 time requiring 129072 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Resulting weights from Softmax: 0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 Loading image data/five_28x28.pgm Performing forward propagation ... Resulting weights from Softmax: 0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5 Test passed! çœ‹åˆ° Test passed æ­å–œä½ æˆåŠŸå¯ä»¥æ­£å¸¸ä½¿ç”¨ GPU äº†!!\nè£œå……ï¼š # NVLink Topology Commandï¼š\nnvidia-smi topo -m NVLink Status Commandï¼š\nnvidia-smi nvlink --status æ›´å¤šç›¸é—œ Nvidia-smi æŸ¥çœ‹ Nvlink Commandï¼š nvidia-smi å·¥å…·æ£€æŸ¥NVIDIA NVLink - Docs\nReference # cuda runtime error (802) : system not yet initialized \u0026hellip;/THCGeneral.cpp:50 Â· Issue #35710 Â· pytorch/pytorch Â· GitHub\nHow to Configure NVLink on Machines - digitalocean\n","date":"2024å¹´09æœˆ11æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/nvidia-a100_env/","section":"Posts","summary":"\u003cp\u003eå‰›å¥½æœ‰å¹¸ç”¨åˆ° 8 Core 80G GPU çš„ A100 æ©Ÿå°ï¼Œä½†ä»¥ç‚ºè¨­å®šè·Ÿä¹‹å‰ä¸€æ¨£å»è¦ç”¨ CUDA è·‘ LLM æ™‚é‡åˆ°å•é¡Œä¸¦ç´€éŒ„è§£æ±ºæ–¹æ³•ã€‚\u003c/p\u003e","title":"Nvidia A100 ç’°å¢ƒè¨­å®š","type":"posts"},{"content":"","date":"2024å¹´06æœˆ09æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/chroma/","section":"Tags","summary":"","title":"Chroma","type":"tags"},{"content":"","date":"2024å¹´06æœˆ09æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/langchain/","section":"Tags","summary":"","title":"LangChain","type":"tags"},{"content":"","date":"2024å¹´06æœˆ09æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/llama.cpp/","section":"Tags","summary":"","title":"Llama.cpp","type":"tags"},{"content":"æ­¤æ–‡ç´€éŒ„ä½¿ç”¨ LLama3 + Langchain + llamacpp + Chroma çµ„åˆæˆä¸€å€‹ç°¡å–®çš„ RAG !\næ•´é«” RAG æ¶æ§‹åœ–ï¼š å…ˆè®€å…¥æˆ‘å€‘è£œå……çš„è³‡æ–™ åˆ©ç”¨èªè¨€æ¨¡å‹å¹«æˆ‘å€‘åš Embedding å¹«æˆ‘å€‘çš„å­—ä¸²åˆ†æä¸¦è½‰æˆå‘é‡ æŠŠè½‰æ›å¾Œçš„å‘é‡å­˜å»å‘é‡è³‡æ–™åº« åˆ©ç”¨ LangChain çš„ Library å…§çš„ LLamaCpp å•Ÿå‹•æˆ‘å€‘çš„ LLama3 æ¨¡å‹ æˆ‘å€‘å°±èƒ½è¼¸å…¥å•é¡Œ æ‹¿åˆ°å•é¡Œå¾Œä»–æœƒå˜—è©¦å»è³‡æ–™åº«æ‰¾ç›¸ä¼¼çš„ç­”æ¡ˆ ç¶“ç”± LLama3 å›ç­”å•é¡Œ Codeï¼š\nimport os import sys import time import chromadb from dotenv import load_dotenv from langchain.chains import ConversationalRetrievalChain from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter from langchain_community.document_loaders import PyPDFLoader from langchain_community.document_loaders import Docx2txtLoader from langchain_community.document_loaders import TextLoader from langchain_community.vectorstores import Chroma from langchain.embeddings import HuggingFaceEmbeddings from langchain.callbacks.manager import CallbackManager from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler from langchain_community.llms import LlamaCpp from langchain.chains import RetrievalQA from langchain.chains import LLMChain from langchain.prompts import PromptTemplate # è®€å–è³‡æ–™ pdf, docs, docx, txt ... documents = [] # Create a List of Documents from all of our files in the ./docs folder for file in os.listdir(\u0026#34;docs\u0026#34;): print(f\u0026#39;Now Loadï¼š{file}\u0026#39;) if file.endswith(\u0026#34;.pdf\u0026#34;): pdf_path = \u0026#34;./docs/\u0026#34; + file loader = PyPDFLoader(pdf_path) documents.extend(loader.load()) elif file.endswith(\u0026#39;.docx\u0026#39;) or file.endswith(\u0026#39;.doc\u0026#39;): doc_path = \u0026#34;./docs/\u0026#34; + file loader = Docx2txtLoader(doc_path) documents.extend(loader.load()) elif file.endswith(\u0026#39;.txt\u0026#39;): text_path = \u0026#34;./docs/\u0026#34; + file loader = TextLoader(text_path) documents.extend(loader.load()) # è®€å–ä¸¦åˆ‡å‰²å­—ä¸² (RecursiveCharacterTextSplitter é€™ä¸€æ®µæœ‰3ç¨®ä¸åŒçš„åˆ‡å‰²æ–¹å¼æœ‰èˆˆè¶£çš„åŒå­¸å¯ä»¥è‡ªå·±å»çœ‹ä¸€ä¸‹ Langchain çš„ library) start_time = time.time() # Split the documents into smaller chunks text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50) documents = text_splitter.split_documents(documents) end_time = time.time() splitter_time = end_time-start_time # æŠŠå‰›å‰›åˆ‡å‰²çš„å­—ä¸²ä½¿ç”¨ ntfloat/multilingual-e5-large-instruct æ¨¡å‹å»ä½œ Embedding ,æˆ‘é€™é‚Šæ˜¯é¸æ“‡ç”¨ CPU å¯ä»¥ç”¨ GPU æœƒæ¯”è¼ƒå¿« start_time = time.time() # Embedding Sentence-transformer Model model_name = \u0026#39;intfloat/multilingual-e5-large-instruct\u0026#39; model_kwargs = {\u0026#39;device\u0026#39;: \u0026#39;cpu\u0026#39;} embedding = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs) end_time = time.time() embedding_time = end_time-start_time # æŠŠè½‰å¥½çš„è³‡æ–™æ”¾åˆ° Chroma DB è£¡,é€™é‚Šæ˜¯ä½¿ç”¨ç°¡æ˜“ç‰ˆç›´æ¥æ”¾åˆ° memory ä¸­ start_time = time.time() # setup Chroma in-memory, for easy prototyping. Can add persistence easily! client = chromadb.Client() # Create collection. get_collection, get_or_create_collection, delete_collection also available! collection = client.create_collection(\u0026#34;all-my-documents\u0026#34;) persist_directory = Chroma(client=client, collection_name=\u0026#34;all-my-documents\u0026#34;) # Convert the document chunks to embedding and save them to the vector store vectordb = Chroma.from_documents(documents, embedding=embedding, persist_directory=persist_directory) vectordb.persist() end_time = time.time() vectordb_time = end_time-start_time # å•Ÿç”¨ LLama3 ä¸¦ä½¿ç”¨ LLamaCpp ä¸€æ¨£å¯ä»¥è¨­å®šåƒæ•¸ # Main LLM llm = LlamaCpp( model_path=\u0026#34;/root/LLM-models/Llama3-8B-Chinese-Chat-q8_0-v2_1.gguf\u0026#34;, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=False, n_gpu_layers=100, n_batch=1600, n_ctx=8000, f16_kv=False, temperature=0.7, use_mlock=True, use_mmap=True, vocab_only=False, ) # è¨­å®š æ¨¡ç‰ˆ ç­‰ç­‰... ä¸¦è¨­å®šæœƒå» DB æ‰¾å†å›å‚³çµ¦ LLama3 å›ç­” # With Langchain Model # This controls how the standalone question is generated. # Should take `chat_history` and `question` as input variables. template = ( \u0026#34;Combine the chat history and follow up question into \u0026#34; \u0026#34;a standalone question. Chat History: {chat_history}\u0026#34; \u0026#34;Follow up question: {question}\u0026#34; ) prompt = PromptTemplate.from_template(template) # create our Q\u0026amp;A chain pdf_qa = ConversationalRetrievalChain.from_llm( llm=llm, condense_question_prompt=prompt, retriever=vectordb.as_retriever(search_kwargs={\u0026#39;k\u0026#39;: 6}), return_source_documents=True, verbose=False, ) # åŸç‰ˆæ¨¡å‹ç”¨ä¾†è·Ÿæœ‰ LangChain ä¾†æ¯”å°å›ç­” # Original Model template = \u0026#34;\u0026#34;\u0026#34; Question: {question} Answer: \u0026#34;\u0026#34;\u0026#34; prompt = PromptTemplate(template=template, input_variables=[\u0026#34;question\u0026#34;]) # Create an LLMChain to manage interactions with the prompt and model Ollm = LLMChain(prompt=prompt, llm=llm) yellow = \u0026#34;\\033[0;33m\u0026#34; green = \u0026#34;\\033[0;32m\u0026#34; white = \u0026#34;\\033[0;39m\u0026#34; chat_history = [] print(f\u0026#34;{yellow}---------------------------------------------------------------------------------\u0026#34;) print(f\u0026#39;Init Timeï¼š\u0026#39;) print(f\u0026#39;Splitter_Timeï¼š{splitter_time} seconds\u0026#39;) print(f\u0026#39;Embedding_Timeï¼š{embedding_time} seconds\u0026#39;) print(f\u0026#39;Vectordb_Timeï¼š{vectordb_time} seconds\u0026#39;) print(\u0026#39;Welcome to the DocBot. You are now ready to start interacting with your documents\u0026#39;) print(\u0026#39;---------------------------------------------------------------------------------\u0026#39;) while True: query = input(f\u0026#34;{green}Prompt: \u0026#34;) if query == \u0026#34;exit\u0026#34; or query == \u0026#34;quit\u0026#34; or query == \u0026#34;q\u0026#34; or query == \u0026#34;f\u0026#34;: print(\u0026#39;Exiting\u0026#39;) sys.exit() if query == \u0026#39;\u0026#39;: continue # æœ‰æ­é…æ‰¾å°‹ chroma DB åœ¨å›ç­”çš„ LLama3 å›ç­” result = pdf_qa.invoke( {\u0026#34;question\u0026#34;: query, \u0026#34;chat_history\u0026#34;: chat_history}) print(f\u0026#34;{white}Answer: \u0026#34; + result[\u0026#34;answer\u0026#34;]) print(\u0026#34;=====================================================\u0026#34;) # åŸç‰ˆ LLama3 å›ç­” Ollm_answer = Ollm.invoke(query) print(Ollm_answer, \u0026#39;\\n\u0026#39;) print(\u0026#34;=====================================================\u0026#34;) # ç´€éŒ„åŠŸèƒ½ #chat_history.append((query, result[\u0026#34;answer\u0026#34;])) æœ€å¾Œå°±èƒ½å¯¦ä½œå‡ºç°¡å–®çš„ RAG äº†ç°¡å–®å§ï¼ï¼ æœ‰èˆˆè¶£çš„åŒå­¸é‚„èƒ½ä¸²æ¥ç¶²é æœå°‹çš„ API ä¸éæˆ‘çœ‹éƒ½è¦éŒ¢æ‰€ä»¥æˆ‘å°±æ²’æ¥äº†QQ\nReference # RAGå¯¦ä½œæ•™å­¸ï¼ŒLangChain + Llama2 |å‰µé€ ä½ çš„å€‹äººLLM\nç”¨ç­†é›»å°±èƒ½è·‘ LLaMA ! llama.cpp æ•™å­¸\n","date":"2024å¹´06æœˆ09æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/langchain2rag/","section":"Posts","summary":"\u003cp\u003eæ­¤æ–‡ç´€éŒ„ä½¿ç”¨ LLama3 + Langchain + llamacpp + Chroma çµ„åˆæˆä¸€å€‹ç°¡å–®çš„ RAG !\u003c/p\u003e","title":"ç”¨ LangChain å¯¦ä½œå‡ºç°¡æ˜“ç‰ˆ RAG","type":"posts"},{"content":"","date":"2024å¹´06æœˆ08æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/ollama/","section":"Tags","summary":"","title":"Ollama","type":"tags"},{"content":"é€™é‚Šç´€éŒ„å¾ Ollama github ä¸Šçš„ Modefile ç´€éŒ„æœ‰å“ªäº›å¯ä»¥ä¿®æ”¹çš„åƒæ•¸ã€‚\nOllama Modelfileï¼š # Modelfile å…§æŒ‡ä»¤åƒæ•¸ï¼š\nFROM : (å¿…å¡«) å®šä¹‰è¦ä½¿ç”¨çš„åŸºæœ¬æ¨¡å‹ã€‚ PARAMETER\t: è®¾ç½® Ollama å¦‚ä½•è¿è¡Œæ¨¡å‹çš„å‚æ•°ã€‚ TEMPLATE\t: è¦å‘é€åˆ°æ¨¡å‹çš„å®Œæ•´æç¤ºæ¨¡æ¿ã€‚ SYSTEM\t: æŒ‡å®šå°†åœ¨æ¨¡æ¿ä¸­è®¾ç½®çš„ç³»ç»Ÿæ¶ˆæ¯ã€‚ ADAPTER\t: å®šä¹‰è¦åº”ç”¨äºæ¨¡å‹çš„ ï¼ˆQï¼‰LoRA é€‚é…å™¨ã€‚ LICENSE\t: æŒ‡å®šåˆæ³•è®¸å¯è¯ã€‚ MESSAGE\t: æŒ‡å®šæ¶ˆæ¯å†å²è®°å½•ã€‚ Base model specification # FROMï¼š Defines the base model to use for creating your customized model. å®šç¾©ä¸€å€‹ model , å»æ‰€å»ºç«‹å®¢è£½åŒ– model\nModel parameters # PARAMETER mirostat [0/1/2]ï¼š Enable Mirostat sampling for perplexity control. 0=disabled, 1=Mirostat, 2=Mirostat 2.0. Mirostatå€¼ï¼šå¯ä»¥æœ‰æ•ˆé¿å…å‡ºç¾éåº¦é‡è¤‡æˆ–ä¸é€£è²«çš„å†…å®¹ é è¨­:0 , 0 æ˜¯ä¸ä½¿ç”¨ , 1æ˜¯Mirostat , 2æ˜¯Mirostat2.0\nPARAMETER mirostat_eta [float]ï¼š Learning rate for Mirostat. Default=0.1. Adjusts algorithm responsiveness. mirostat_etaå€¼ï¼šå½±éŸ¿ç®—æ³•å°ç”Ÿæˆæ–‡æœ¬åæ‡‰çš„éŸ¿æ‡‰é€Ÿåº¦ï¼Œå¾è€Œå½±éŸ¿ç”Ÿæˆæ–‡æœ¬çš„è³ªé‡å’Œç‰¹å¾µã€‚ è¼ƒä½çš„å€¼èª¿æ•´é€Ÿåº¦è¼ƒæ…¢ï¼Œè¼ƒé«˜çš„å€¼ä½¿ç®—æ³•æ›´å…·å½±éŸ¿æ€§ï¼Œå°æ–¼éœ€è¦å¿«é€Ÿè¿­ä»£æˆ–èª¿æ•´æ¨¡å‹è¼¸å‡ºçš„å ´æ™¯éå¸¸æœ‰ç”¨ã€‚ ; é è¨­:0.1\nPARAMETER mirostat_tau [float]ï¼š Balance between coherence and diversity. Default=5.0. Lower values = more focused text. mirostat_tauï¼šå¯ä»¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„é€£è²«æ€§å’Œå¤šæ¨£æ€§ä¹‹é–“çš„å¹³è¡¡,å¾è€Œå½±éŸ¿æ–‡æœ¬çš„é‡è¤‡æ€§å’Œé€£è²«æ€§ç­‰é‡è¦å±æ€§ã€‚ è¼ƒä½çš„å€¼å¯ä»¥æ›´åŠ é›†ä¸­å’Œé€£è²«ï¼Œè¼ƒé«˜çš„å€¼å‰‡æœƒå¢åŠ è¼¸å‡ºçš„å¤šæ¨£æ€§ã€‚é è¨­:5.0\nPARAMETER num_ctx [int]ï¼š Context window size. Default=2048. Controls tokens used for generating the next token. num_ctxï¼šé€™å€‹åƒæ•¸ç”¨æ–¼è¨­ç½®ä¸Šä¸‹æ–‡ token çš„æ•¸é‡ã€‚å®ƒå†³å®šäº†æ¨¡å‹åœ¨ç”ŸæˆéŸ¿æ‡‰æ™‚å¯ä»¥è€ƒæ…®çš„ä¸Šä¸‹æ–‡é•·åº¦ã€‚é è¨­:2048\nPARAMETER num_gqa [int]ï¼š Number of GQA groups in the transformer layer. Required for some models, e.g., 8 for llama2:70b. num_gqaï¼šå¯ä»¥æ§åˆ¶æ¨¡å‹åŒæ™‚è™•ç†çš„ä»»å‹™æ•¸é‡ï¼Œå¾è€Œæœ€ä½³åŒ–æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œè¨­å®š Transformer å±¤ä¸­ GQA ç»„çš„æ•¸é‡ã€‚æŸäº›æ¨¡å‹éœ€è¦ï¼Œä¾‹å¦‚ llama2:70b ç‚º 8\nPARAMETER num_gpu [int]ï¼š Number of layers to send to the GPU(s). macOS defaultï¼š1 for metal support. num_gpuï¼šè¨­ç½®æ¨¡å‹åœ¨æ¨ç†æ™‚ä½¿ç”¨çš„ GPU layers æ•¸é‡ã€‚é è¨­ï¼š1ï¼Œç¦ç”¨ï¼š0\nPARAMETER num_thread [int]ï¼š Number of threads for computation. Recommended: number of physical CPU cores. num_threadï¼šè¨­ç½®æ¨¡å‹åœ¨æ¨ç†æ™‚ä½¿ç”¨çš„ CPU ç·šç¨‹æ•¸é‡ã€‚ Ollama å°‡æª¢æ¸¬åˆ°é€™ä¸€é»ä»¥ç²å¾—æœ€ä½³æ€§èƒ½ã€‚å»ºè­°å°‡æ­¤å€¼è¨­ç½®ç‚ºç³»çµ±å…·æœ‰çš„ç‰©ç† CPU æ ¸å¿ƒæ•¸ï¼ˆè€Œä¸æ˜¯é‚è¼¯æ ¸å¿ƒæ•¸ï¼‰ã€‚\nPARAMETER repeat_last_n [int]ï¼š Lookback distance to prevent repetition. Default=64, 0=disabled, -1=num_ctx. repeat_last_nï¼šæ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚æª¢æ¸¬å’Œæ‡²ç½°é‡è¤‡ n-gram çš„\u0026quot;æ•¸é‡\u0026quot;ã€‚å‘Šè¨´æ¨¡å‹åœ¨å˜—è©¦ä¸é‡è¤‡æœ€åä¸€éƒ¨åˆ†å°è©±æ™‚æ‡‰è©²è€ƒæ…®çš„ token æ•¸é‡ã€‚ ç°¡å–®ä¾†èªªå°±æ˜¯ æ§åˆ¶æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚é¿å…é‡è¤‡å‰ n-gram çš„ token å‡ºç¾,å¾è€Œæé«˜æ–‡æœ¬çš„å¤šæ¨£æ€§å’Œè³ªé‡ã€‚ é è¨­ï¼š64ï¼Œç¦ç”¨ï¼š0ï¼Œ-1=num_ctx\nPARAMETER repeat_penalty [float]ï¼š Penalty for repetitions. Higher values penalize more. Default: 1.1. repeat_penaltyï¼šè¨­ç½®æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚å°é‡è¤‡ n-gram çš„æ‡²ç½°\u0026quot;ç¨‹åº¦\u0026quot;ã€‚ å¯ä»¥æ§åˆ¶æ¨¡å‹å°é‡è¤‡ n-gram çš„æ‡²ç½°åŠ›åº¦,å¾è€Œå½±éŸ¿ç”Ÿæˆæ–‡æœ¬çš„æµæš¢æ€§å’Œé€£è²«æ€§ã€‚ è¼ƒé«˜çš„å€¼ï¼ˆä¾‹å¦‚ï¼Œ1.5ï¼‰å°‡æ›´å¼·çƒˆçš„æ‡²ç½°é‡è¤‡ï¼Œè€Œè¼ƒä½çš„å€¼ï¼ˆä¾‹å¦‚ï¼Œ0.9ï¼‰å°‡æ›´å¯¬é¬†ã€‚é è¨­:1.1\nPARAMETER temperature [float]ï¼š Model creativity vs coherence. Higher values = more creative. Default=0.8. temperatureï¼šåƒæ•¸å¯ä»¥å½±éŸ¿ç”Ÿæˆæ–‡æœ¬çš„å¤šæ¨£æ€§,å€¼è¶Š\u0026quot;é«˜\u0026quot;ç”Ÿæˆçš„æ–‡æœ¬è¶Šå…·æœ‰å‰µé€ æ€§å’Œè®ŠåŒ–æ€§,å€¼è¶Š\u0026quot;ä½\u0026quot;ç”Ÿæˆçš„æ–‡æœ¬è¶Šè¶¨å‘æ–¼ä¿å®ˆå’Œç©©å®šã€‚é è¨­:0.8\nPARAMETER seed [int]ï¼š Random seed for generation consistency. Default=0. seedï¼šé€šéè¨­å®šå›ºå®šçš„ç¨®å­å€¼ï¼Œå¯ä»¥ç¢ºä¿æ¯æ¬¡é‹è¡Œç›¸åŒçš„æ¨¡å‹å’Œç›¸åŒçš„è¼¸å…¥æ™‚ï¼Œå¾—åˆ°çš„è¼¸å‡ºæ˜¯ä¸€è‡´çš„ã€‚ é è¨­ï¼š0\nPARAMETER stop \u0026ldquo;[string]\u0026quot;ï¼š Stop sequences for generation end. Multiple stops possible with separate parameters. stopï¼šè¨­ç½®è¦ä½¿ç”¨çš„åœæ­¢æ–‡å­—ã€‚ç•¶é‡åˆ°é€™ç¨®æ¨¡å¼æ™‚ï¼ŒLLM å°‡åœæ­¢ç”Ÿæˆæ–‡æœ¬ä¸¦è¿”å›ã€‚ å¯ä»¥é€šé stop åœ¨æ¨¡å‹æ–‡ä»¶ä¸­æŒ‡å®š\u0026quot;å¤šå€‹\u0026quot;å–®ç¨çš„åƒæ•¸æ¥è¨­ç½®å¤šå€‹åœæ­¢æ¨¡å¼ã€‚\nPARAMETER tfs_z [float]ï¼š Tail free sampling for reducing less probable tokens\u0026rsquo; impact. Default=1, \u0026gt;1 reduces impact more. tfs_zï¼šé€šéèª¿æ•´ tfs_z(å°¾è‡ªç”±æ¡æ¨£) çš„å½±éŸ¿åŠ›åº¦æ¥å½±éŸ¿æ¨¡å‹è¼¸å‡ºçš„å¤šæ¨£æ€§å’Œé€£è²«æ€§ã€‚ ç•¶ tfs_z å€¼è¼ƒé«˜ï¼ˆä¾‹å¦‚ï¼Œ2.0ï¼‰æ™‚ï¼Œå®ƒæœƒæ¸›å°‘ä¸å¤ªå¯èƒ½çš„ token çš„å½±éŸ¿åŠ›ï¼Œå¾è€Œä½¿è¼¸å‡ºæ›´åŠ å¤šæ¨£åŒ–ã€‚ ç›¸åï¼Œç•¶ tfs_z å€¼ç‚º 1.0 æ™‚ï¼Œé€™å€‹è¨­ç½®è¢«ç¦ç”¨ï¼Œæ„å‘³è‘—å°¾è‡ªç”±é‡‡æ ·çš„å½±éŸ¿åŠ›åº¦ç‚ºæœ€ä½ï¼Œæ¨¡å‹è¼¸å‡ºçš„å¤šæ¨£æ€§å’Œé€£è²«æ€§å¯èƒ½æœƒå—åˆ°å½±éŸ¿ã€‚ é è¨­:1.0\nPARAMETER num_predict [int]ï¼š Max tokens to predict. Default=128, -1=infinite generation, -2=fill context. num_predictï¼šåƒæ•¸ä»£è¡¨äº†åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶æ¨¡å‹é æ¸¬çš„æœ€å¤§ token æ•¸é‡ã€‚é€™å€‹åƒæ•¸çš„åŠŸèƒ½ä¸»è¦æ˜¯æ§åˆ¶æ–‡æœ¬ç”Ÿæˆçš„éç¨‹ä¸­æ¨¡å‹çš„è¼¸å‡ºé•·åº¦ã€‚ è¼ƒå°çš„ num_predict å€¼å¯ä»¥æé«˜ç”Ÿæˆæ•ˆç‡,ä½†å¯èƒ½æœƒé™åˆ¶æ¨¡å‹ç”Ÿæˆæ›´è±å¯Œçš„æ–‡æœ¬ã€‚è¼ƒå¤§çš„ num_predict å€¼å‰‡å¯ä»¥è®“æ¨¡å‹ç”Ÿæˆæ›´é•·æ›´è¤‡é›œçš„æ–‡æœ¬,ä½†å¯èƒ½æœƒé™ä½ç”Ÿæˆé€Ÿåº¦ã€‚é è¨­:128, ç„¡é™åˆ¶ï¼š-1 (æ¨¡å‹ç„¡é™åˆ¶åœ°ç”Ÿæˆæ–‡æœ¬,ç›´åˆ°é‡åˆ°åœæ­¢æ¨™è¨˜), å¡«å……ä¸Šä¸‹æ–‡ï¼š-2 (æœƒæ ¹æ“šçµ¦å®šçš„ä¸Šä¸‹æ–‡ç”Ÿæˆæ–‡æœ¬ï¼Œè€Œä¸æœƒç”Ÿæˆæ–°çš„ä»¤ç‰Œ)\nPARAMETER top_k [int]ï¼š Limits nonsense generation. Higher values = more diverse answers. Default=40. top_k: åƒæ•¸ç”¨æ–¼æ§åˆ¶æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚è€ƒæ…®çš„å€™é¸ token æ•¸é‡ã€‚ è¼ƒé«˜çš„å€¼ï¼ˆä¾‹å¦‚ 100ï¼‰å°‡çµ¦å‡ºæ›´å¤šæ¨£åŒ–çš„ç­”æ¡ˆï¼Œè€Œè¼ƒä½çš„å€¼ï¼ˆä¾‹å¦‚ 10ï¼‰å°‡æ›´åŠ ä¿å®ˆã€‚é è¨­:40 (å–å‰40å€‹)\nPARAMETER top_p [float]ï¼š Works with top-k for output diversity. Higher values = more diversity. Default=0.9. top_p: å€¼æœƒè®“æ¨¡å‹è€ƒæ…®ç´¯è¨ˆæ¦‚ç‡è¼ƒé«˜çš„ token ã€‚ è¼ƒé«˜çš„å€¼ï¼ˆä¾‹å¦‚ï¼Œ0.95ï¼‰å°‡å°è‡´æ›´åŠ å¤šæ¨£åŒ–çš„æ–‡æœ¬ï¼Œè€Œè¼ƒä½çš„å€¼ï¼ˆä¾‹å¦‚ï¼Œ0.5ï¼‰å°‡ç”Ÿæˆæ›´åŠ é›†ä¸­å’Œä¿å®ˆçš„æ–‡æœ¬ã€‚é è¨­ï¼š0.9 (ä»£è¡¨å–æ¬Šé‡å‰90%çš„)\nPrompt template # TEMPLATE \u0026quot;\u0026rdquo;\u0026quot; \u0026hellip; \u0026ldquo;\u0026quot;\u0026quot;ï¼š Full prompt template including optional system message, user\u0026rsquo;s message, and the model\u0026rsquo;s response. TEMPLATEï¼šè©²åƒæ•¸ç”¨æ–¼å®šç¾©æ¨¡å‹çš„æ¨¡æ¿æˆ–ç³»ç»Ÿæç¤ºï¼Œæ§åˆ¶æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚çš„è¼¸å‡ºçµæ§‹å’Œé¢¨æ ¼ã€‚ ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ TEMPLATE åƒæ•¸æ¥æŒ‡å®šæ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ™‚æ˜¯å¦åŒ…å«ç³»ç»Ÿæç¤ºã€ç”¨æˆ·æç¤ºã€æ¨¡å‹éŸ¿æ‡‰ç­‰ä¿¡æ¯ã€‚ æ§åˆ¶æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ•´é«”çµæ§‹å’Œæ ¼å¼ã€‚ (ä½¿ç”¨ Go èªæ³•æ ¼å¼) Example:\n| Variable | Description | | {{ .System }} | The system message used to specify custom behavior. ç”¨æ–¼è¨­å®šè‡ªè¨‚ç¾©è¡Œç‚º| | {{ .Prompt }} | The user prompt message. ä½¿ç”¨è€…æç¤ºæ¶ˆæ¯| | {{ .Response }} | The response from the model. When generating a response, text after this variable is omitted. æ¨¡å‹ç”Ÿæˆçš„å›å¤ã€‚åœ¨ç”Ÿæˆå›å¤æ—¶ï¼Œæ­¤å˜é‡åçš„æ–‡æœ¬å°†è¢«çœç•¥ã€‚| TEMPLATE \u0026#34;\u0026#34;\u0026#34;{{ if .System }}system {{ .System }} {{ end }}{{ if .Prompt }}user {{ .Prompt }} {{ end }}assistant \u0026#34;\u0026#34;\u0026#34; System message # SYSTEM \u0026ldquo;\u0026rdquo;\u0026quot;[system message]\u0026rdquo;\u0026quot;\u0026quot;ï¼š Custom system message specifying chat assistant behavior. SYSTEMï¼šåƒæ•¸çš„ä¸»è¦åŠŸèƒ½æ˜¯ç‚ºæ¨¡å‹æä¾›ä¸€å€‹åˆå§‹çš„å°è©±ä¸Šä¸‹æ–‡ã€‚ é€šéè¨­ç½® SYSTEM åƒæ•¸ï¼Œé–‹ç™¼è€…å¯ä»¥æ§åˆ¶æ¨¡å‹åœ¨é–‹å§‹ç”Ÿæˆæ–‡æœ¬ä¹‹å‰ï¼Œç³»ç»Ÿæ¶ˆæ¯çš„å†…å®¹ã€‚ ç°¡å–®ä¾†èªªå°±æ˜¯é–‹å§‹å›ç­”å‰å…ˆè·Ÿå®ƒè¬›æ˜¯ç¾åœ¨æ˜¯å“ªç¨®èº«åˆ†èˆ‡è¨­å®šï¼Œå½±éŸ¿æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„é¢¨æ ¼å’Œå†…å®¹ã€‚\nExampleï¼š\nSYSTEM \u0026#34;\u0026#34;\u0026#34;You are a helpful medicine assistant.\u0026#34;\u0026#34;\u0026#34; LoRA adapter # ADAPTERï¼š Specifies the LoRA adapter to apply. Path relative to the Modelfile or absolute. ADAPTER: æŒ‡å®šè¦æ‡‰ç”¨æ–¼åŸºç¤æ¨¡å‹çš„ (Q)LoRA æª”æ¡ˆã€‚ å¿…é ˆé‡‡ç”¨ GGML æ–‡ä»¶æ ¼å¼ã€‚ Exampleï¼š\nADAPTER ./ollama-lora.bin License # LICENSEï¼š Legal license under which the model is shared or distributed. LICENSEï¼šæ­¤æ¨¡å‹åˆ†äº«èˆ‡åˆæ³•æˆæ¬Šéµå®ˆçš„ License è¦å‰‡ã€‚ Exampleï¼š\nLICENSE \u0026#34;\u0026#34;\u0026#34; \u0026lt;license text\u0026gt; \u0026#34;\u0026#34;\u0026#34; Message # MESSAGE [role] [message]ï¼š Sets up a predefined message history for the model to consider when generating responses, helping to provide context or guide the model\u0026rsquo;s outputs. MESSAGEï¼šæŒ‡ä»¤å…è¨±æ‚¨ç‚ºæ¨¡å‹æŒ‡å®šæ¶ˆæ¯æ­·å²ç´€éŒ„ï¼Œä»¥ä¾¿åœ¨éŸ¿æ‡‰æ™‚ä½¿ç”¨ã€‚ä½¿ç”¨å¤šå€‹ MESSAGE å‘½ä»¤çš„è¿­ä»£æ¥å»ºæ§‹å°è©±ï¼Œé€™å°‡å¼•å°æ¨¡å‹ä»¥é¡ä¼¼çš„æ–¹å¼å›ç­”ã€‚ Example:\n| Variable | Description | | system | Alternate way of providing the SYSTEM message for the model. ä¸ºæ¨¡å‹æä¾›ç³»ç»Ÿæ¶ˆæ¯çš„æ›¿ä»£æ–¹å¼ã€‚| | user | An example message of what the user could have asked. ç”¨æˆ·å¯èƒ½ä¼šæå‡ºçš„ç¤ºä¾‹æ¶ˆæ¯ã€‚| | assistant | An example message of how the model should respond. æ¨¡å‹åº”è¯¥å¦‚ä½•å›åº”çš„ç¤ºä¾‹æ¶ˆæ¯ã€‚| MESSAGE user Is Toronto in Canada? MESSAGE assistant yes ... ç­†è¨˜ï¼š # temperature, top_k, top_p 3è€…ç›¸é—œæ€§ï¼š\ntemperatureï¼šæ“·å– prompt ä¸­çš„ tokenã€‚ top_kï¼šå¾ tokens é‡Œé¸æ“‡ k å€‹ä½œç‚ºå€™é¸ï¼Œç„¶åæ ¹æ®å®ƒå€‘çš„ likelihood scores æ¥æ¡æ¨£ã€‚ top_pï¼šå¾ tokens é‡ŒæŒ‰ç™¾åˆ†æ¯”é¸æ“‡å€™é¸è©ã€‚ é †åºï¼štemperature æ•´é«”åƒæ•¸å–æ¨£ =\u0026gt; top_k å–æ¨£å‰nå€‹é‡æ–°è³¦äºˆæ¬Šé‡æ’å =\u0026gt; top_p å–å‰ n% ä¾†ä½¿ç”¨ Reference # ç¿»è­¯èˆ‡æ‰¾è³‡æ–™ï¼šperplexity.ai and phind.ai\nåŸºäºOllamaå®šåˆ¶è‡ªå·±çš„å¤§è¯­è¨€æ¨¡å‹ - 53ai\nä¸Šç™¾å¤§è¯­è¨€æ¨¡å‹å¿«é€Ÿéƒ¨ç½²è°ƒç”¨å·¥å…· Ollamaä½¿ç”¨æŒ‡å—\nOllama GitHub - Modefile\nOllama GitHub - Modefile\nOllama GitHub - import è‡ªå®šä¹‰å¤§å‹è¯­è¨€æ¨¡å‹-ä½¿ç”¨OLLAMAå’ŒModelfileå®šåˆ¶ã€è¿è¡Œå’Œä¿å­˜LLM - çŸ¥ä¹\né–±è®€æ–‡ç« ï¼š\npromptingguide.ai\nlearnprompting.org\nGitHubï¼š\nOllama - GitHub\n","date":"2024å¹´06æœˆ08æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/ollama-modefile/","section":"Posts","summary":"\u003cp\u003eé€™é‚Šç´€éŒ„å¾ Ollama github ä¸Šçš„ Modefile ç´€éŒ„æœ‰å“ªäº›å¯ä»¥ä¿®æ”¹çš„åƒæ•¸ã€‚\u003c/p\u003e","title":"Ollama Modefile å¯èª¿åƒæ•¸ç´€éŒ„","type":"posts"},{"content":"æ­¤æ–‡ç« ä»‹ç´¹å¦‚ä½•å¾å®‰è£ Nvidia é©…å‹•åˆ°å¾ HuggingFace ä¸‹è¼‰çš„ LLM Model ä½¿ç”¨ Ollama å•Ÿå‹• LLM ä¸¦ä½¿ç”¨ OpenWeb ui é€²è¡Œæºé€šçš„éƒ¨ç½²éç¨‹ç´€éŒ„ã€‚\næ•´é«”æµç¨‹ï¼š\nLLM Model(HugingFace) =\u0026gt; Download .gguf model =\u0026gt; Ollama (backend run) =\u0026gt; OpenWeb ui (forten Web) ç’°å¢ƒå®‰è£ï¼š\nç¦ç”¨ nouveau é©…å‹•\n# åœ¨ /etc/modprobe.d/blacklist-nouveau.conf æª”æ¡ˆä¸­åŠ å…¥ä¸‹æ–¹å…©è¡Œå­— # blacklist nouveau # options nouveau modeset=0 echo \u0026#34;blacklist nouveau\u0026#34; | sudo tee /etc/modprobe.d/blacklist-nouveau.conf \u0026amp;\u0026amp; echo \u0026#34;options nouveau modeset=0\u0026#34; | sudo tee -a /etc/modprobe.d/blacklist-nouveau.conf # æ›´æ–° kernel initramfs sudo update-initramfs -u # é‡é–‹æ©Ÿ reboot # åŸ·è¡Œå¾Œï¼Œæ²’æœ‰å‡ºç¾ä»»ä½•è¨Šæ¯ï¼Œå°±è¡¨ç¤ºæˆåŠŸç¦ç”¨ nouveau é©…å‹• lsmod | grep nouveau # ä¹Ÿå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æª¢æŸ¥ä¸€ä¸‹ configuration æ˜¯å¦é‚„æœ‰ nouveau æ–‡å­— sudo lshw -numeric -C display Ref: How to disable Nouveau kernel driver - askubuntu\napt-install tool\nsudo apt-get update sudo apt-get install libc-dev -y sudo apt-get install linux-headers-$(uname -r) -y sudo apt-get install ubuntu-drivers-common install nvidia-CUDA-Toolkit\nè§£å®‰è£èˆŠ NVIDIA é©…å‹•ï¼š sudo apt-get --purge remove nvidia* sudo apt-get --purge remove libnvidia* Base Installerï¼š wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-4 Driver Installerï¼š sudo apt-get install -y cuda-drivers Followerï¼šNvidia cuda å®˜æ–¹å®‰è£ç¶²é \nè£œå……ï¼š\nCheck Nvidia Version: modinfo nvidia|grep version setting nvcc env bashrc and check nvcc\nsudo nano ~/.bashrc # åŠ åœ¨æœ€ä¸‹é¢ export PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/lib64:$LD_LIBRARY_PATH\u0026#34; source ~/.bashrc nvcc --version install cuDNN\nwget https://developer.download.nvidia.com/compute/cudnn/9.1.0/local_installers/cudnn-local-repo-ubuntu2204-9.1.0_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2204-9.1.0_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2204-9.1.0/cudnn-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cudnn Get:1 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-cuda-12 9.1.0.70-1 [439 MB] Get:2 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-dev-cuda-12 9.1.0.70-1 [34.1 kB] Get:3 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-static-cuda-12 9.1.0.70-1 [436 MB] Get:4 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9-cuda-12-4 9.1.0.70-1 [12.3 kB] Get:5 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9-cuda-12 9.1.0.70-1 [12.3 kB] Get:6 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-samples 9.1.0.70-1 [1670 kB] Get:7 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9 9.1.0-1 [2442 B] Get:8 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn 9.1.0-1 [2414 B] Selecting previously unselected package libcudnn9-cuda-12. (Reading database ... 216732 files and directories currently installed.) Preparing to unpack .../0-libcudnn9-cuda-12_9.1.0.70-1_amd64.deb ... Unpacking libcudnn9-cuda-12 (9.1.0.70-1) ... Follower: Nvidia cuDNN å®˜æ–¹å®‰è£ç¶²é \nCheck cuDNN:\nsee version:\ncat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 # or cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 check can use cuDNN:\nsudo apt install libfreeimage3 libfreeimage-dev cp -r /usr/src/cudnn_samples_v9/ /home/cuDNN-test/ cd /home/cuDNN-test/cudnn_samples_v9/mnistCUDNN make clean \u0026amp;\u0026amp; make ./mnistCUDNN Resulting weights from Softmax: 0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5 Test passed! install miniconda\nmkdir -p ~/miniconda3 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 rm -rf ~/miniconda3/miniconda.sh ~/miniconda3/bin/conda init bash conda create --name llama_py python=3.10 Follower: miniconda å®˜æ–¹ç¶²é \ninstall pytorch\npip3 install torch torchvision torchaudio Ref: pytorch å®˜æ–¹ç¶²é \nTry run LLama2\ngit clone https://github.com/meta-llama/llama.git pip install -e . download the model (Ex:llama-2-7b-chat) torchrun --nproc_per_node 1 example_chat_completion.py --ckpt_dir llama-2-7b-chat/ --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 6 Refï¼šLLama GitHub Page\nDocker run Ollama \u0026amp; openWeb ui\nRun in LLM folder create docker-compose.yaml docker-compose.yamlï¼š\nversion: \u0026#39;3.8\u0026#39; services: ollama: image: ollama/ollama:latest ports: - 11434:11434 runtime: nvidia environment: NVIDIA_VISIBLE_DEVICES: all volumes: - .:/code - ./ollama/ollama:/root/.ollama container_name: ollama pull_policy: always tty: true restart: always open-webui: image: ghcr.io/open-webui/open-webui:main container_name: open-webui volumes: - ./ollama/open-webui:/app/backend/data depends_on: - ollama ports: - 8080:8080 environment: - \u0026#39;/ollama/api=http://ollama:11434/api\u0026#39; extra_hosts: - host.docker.internal:host-gateway restart: unless-stopped Create Ollama Modelfile to Ollama use Model\ncreate ./Makefile Makefileï¼š (é‚„æœ‰å…¶ä»– LLM è©³ç´°è¨­å®šå¯ä»¥åˆ° Ollama çš„ github ä¸Šçœ‹)\nFROM ./\u0026lt;model_name\u0026gt;.gguf docker compose up -d docker exec -it ollama /bin/bash cd code ollama create \u0026lt;Ollama_Show_Model_Name\u0026gt; -f Modelfile root@454866b8147a:/code# ollama create llama3-8B-chat -f ./Modelfile transferring model data creating model layer using already created layer sha256:ce22d8a49a949089fd2b50a4c19fd043b8480da951d9ace3aa50446d64d4468c writing layer sha256:6e8dc213cf73dab521788f5a7e506d202db50b73d104d7d1bbc343089dfd1e8a writing manifest success root@454866b8147a:/code# ls Ref: Ollama GitHub Page - import\nGo to Web use\nè£œå……ï¼š # Docker install:\nuninstall old docekr\nfor pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done install docker source\n# Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update install docker\nLast version: sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Specific version: # List the available versions: apt-cache madison docker-ce | awk \u0026#39;{ print $3 }\u0026#39; 5:26.1.0-1~ubuntu.24.04~noble 5:26.0.2-1~ubuntu.24.04~noble ... VERSION_STRING=5:26.1.0-1~ubuntu.24.04~noble sudo apt-get install docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-buildx-plugin docker-compose-plugin Verify Docker\nsudo docker run hello-world Refï¼šdocker å®˜æ–¹ç¶²é \nNvidia container toolkitï¼š\ninstall Nvidia container toolkit curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list sudo apt-get update sudo apt-get install -y nvidia-container-toolkit # Configure NVIDIA Container Toolkit sudo nvidia-ctk runtime configure --runtime=docker sudo systemctl restart docker # Test GPU integration docker run --gpus all nvidia/cuda:11.5.2-base-ubuntu20.04 nvidia-smi Reference # Nvidia container-toolkit\nå‚»ç“œ LLM æ¶è¨­ - Ollama + Open WebUI ä¹‹ Docker Compose æ‡¶äººåŒ…\n","date":"2024å¹´05æœˆ02æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/ollama-deploy/","section":"Posts","summary":"\u003cp\u003eæ­¤æ–‡ç« ä»‹ç´¹å¦‚ä½•å¾å®‰è£ Nvidia é©…å‹•åˆ°å¾ HuggingFace ä¸‹è¼‰çš„ LLM Model ä½¿ç”¨ Ollama å•Ÿå‹• LLM ä¸¦ä½¿ç”¨ OpenWeb ui é€²è¡Œæºé€šçš„éƒ¨ç½²éç¨‹ç´€éŒ„ã€‚\u003c/p\u003e","title":"Ollama Deploy LLM","type":"posts"},{"content":"","date":"2024å¹´02æœˆ28æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/devops/","section":"Categories","summary":"","title":"DevOps","type":"categories"},{"content":"","date":"2024å¹´02æœˆ28æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"2024å¹´02æœˆ28æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/k8s/","section":"Tags","summary":"","title":"K8s","type":"tags"},{"content":"","date":"2024å¹´02æœˆ28æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/nvidia/","section":"Tags","summary":"","title":"NVIDIA","type":"tags"},{"content":"æœ¬æ–‡ä»‹ç´¹åœ¨ Ubuntu Server 22.04 ä¸Šå®‰è£ Docker èˆ‡ Kubernetes ä¸¦åœ¨ Container ä¸Šä½¿ç”¨ GPU çš„ç´€éŒ„\nç’°å¢ƒä»‹ç´¹ # K8s-Controllerï¼ˆV100 GPUï¼‰\nOSï¼šUbuntu Server 22.04 IPï¼š192.168.137.154 Hostnameï¼šk8s-controller.com K8s-Node1ï¼ˆT4 GPUï¼‰\nOSï¼šUbuntu Server 22.04 IPï¼š192.168.137.168 Hostnameï¼šk8s-node1.com K8s-Node2ï¼ˆT4 GPUï¼‰\nOSï¼šUbuntu Server 22.04 IPï¼š192.168.137.249 Hostnameï¼šk8s-node2.com å¦‚æœä¸å¤ªæ‡‚ K8s ä¸Šè©²ä½¿ç”¨ GPU æ•´é«”æ¶æ§‹å¯ä»¥å…ˆçœ‹é€™ç¯‡æ–‡ç« ï¼Œå¯ä»¥å¤§è‡´ä¸Šå…ˆäº†è§£ç­‰ç­‰æœƒç”¨åˆ°çš„å¥—ä»¶ K8s GPU æ•´é«”æ¶æ§‹ä»‹ç´¹ï¼šhttps://zhuanlan.zhihu.com/p/670798727\nGPU è¨­å®š åŠ å®‰è£ (æ¯å°éƒ½éœ€è¦è¨­å®š) # ç’°å¢ƒè¨­å®š # Disable nouveau é–‹æºç‰ˆæœ¬çš„ GPU é©…å‹• ç•¶ç³»çµ±å®‰è£å®Œæˆä¹‹å¾Œï¼Œæœƒå®‰è£ç³»çµ±é–‹æºçš„ NVIDIA é©…å‹•ç‰ˆæœ¬ï¼Œåç¨±ç‚º nouveau å‰µå»º /etc/modprobe.d/blacklist-nouveau.conf æ–‡ä»¶ sudo vim /etc/modprobe.d/blacklist-nouveau.conf å°‡ä¸‹é¢å†…å®¹æ·»åŠ é€²å»ï¼š blacklist nouveau blacklist lbm-nouveau options nouveau modeset=0 alias nouveau off alias lbm-nouveau off å‰µå»º /etc/modprobe.d/nouveau-kms.conf æ–‡ä»¶ï¼Œä¸¦å°‡ options nouveau mdeset=0 æ·»åŠ é€²å»ï¼š echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf æ›´æ–°ä¸€ä¸‹ initramfsï¼š sudo update-initramfs -u é‡å•Ÿä¼ºæœå™¨ï¼š sudo reboot æŸ¥çœ‹ nouveau æ˜¯å¦åŠ è¼‰ï¼Œæ²’é¡¯ç¤ºçš„è©±å°±è¡¨ç¤ºå·²ç¶“ç¦ç”¨ï¼š sudo lsmod | grep nouveau å¥—ä»¶å®‰è£ # æœ‰åˆ† \u0026ldquo;ä¸€æ¬¡å…¨éƒ¨å®‰è£å¥½(CUDA Toolkit)\u0026rdquo; è·Ÿ \u0026ldquo;å„å€‹å°å¥—ä»¶åˆ†åˆ¥å®‰è£\u0026rdquo; çš„æ–¹æ³•,é€™é‚Šæ¨è–¦ç›´æ¥è£ä¸€æ¬¡å…¨éƒ¨è£å¥½çš„ç‰ˆæœ¬\nå®‰è£ Nvidia CUDA Toolkit å¥—ä»¶ (ä¸€æ¬¡å…¨è£ç‰ˆæœ¬) # å¯ä»¥å»å®˜ç¶²é¸æ“‡ä½ çš„ OS èˆ‡ç‰ˆæœ¬å»å®‰è£åˆé©å¥—ä»¶èˆ‡æ­¥é©Ÿï¼š Nvidia CUDA Toolkitï¼šhttps://developer.nvidia.com/cuda-downloads é€™é‚Šæ˜¯ä½¿ç”¨ Local deb å®‰è£, å®‰è£ Ubuntu 22.04 local deb ç‰ˆæœ¬\nç§»é™¤èˆŠ NVIDIA é©…å‹• sudo apt-get --purge remove nvidia* sudo apt-get --purge remove libnvidia* å®‰è£… CUDA Toolkit (è£¡é¢åŒ…å« Driver Cuda NVCC ç­‰ç­‰\u0026hellip;) Base Installer: wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.3.2/local_installers/cuda-repo-ubuntu2204-12-3-local_12.3.2-545.23.08-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-3-local_12.3.2-545.23.08-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-3 Driver Installerï¼šäºŒæ“‡ä¸€å³å¯æˆ‘æ˜¯è£ä¸Šé¢å°±è¡Œäº† To install the legacy kernel module flavor: sudo apt-get install -y cuda-drivers To install the open kernel module flavor: sudo apt-get install -y nvidia-kernel-open-545 sudo apt-get install -y cuda-drivers-545 å–®ç´”å®‰è£ Nvidia GPU Drive (ä¹‹å¾Œé‚„è¦è£ Cuda): # å¯¦ä½œä¸­ç™¼ç¾æœ‰ error è¦æ§åˆ¶ OS core ç‰ˆæœ¬æ‰€ä»¥æ²’ç‰¹åˆ¥å»è§£!! æ‰€ä»¥è¦å˜—è©¦å–®å€‹å¥—ä»¶å®‰è£çš„è«‹è‡ªè¡Œ Debugï¼Œæˆ–å“ªå¤©æˆ‘æ‰¾åˆ°æ­£ç¢ºæ–¹æ³•æˆ‘åœ¨è£œä¸Šï¼ wget NVIDIA GPU Driver\næ‰¾è‡ªå·±å‹è™Ÿçš„ Driver ä¸¦è¤‡è£½ä¸‹è¼‰é€£çµï¼š https://www.nvidia.com/Download/index.aspx?lang=en-us ä¸‹è¼‰ Driver åˆ°æ©Ÿå°ä¸Š wget \u0026#34;Driver-Url\u0026#34; install GPU Driver\nchmod 777 \u0026#34;GPU-Driver\u0026#34; ./\u0026#34;GPU-Driver\u0026#34; å®‰è£å¾Œå°±é¡¯ç¤ºé€™å€‹éŒ¯èª¤\nERROR: An error occurred while performing the step: \u0026#34;Building kernel modules\u0026#34;. See /var/log/nvidia-installer.log for details. ERROR: An error occurred while performing the step: \u0026#34;Checking to see whether the nvidia kernel module was successfully built\u0026#34;. See /var/log/nvidia-installer.log for details. èª¿æ•´åˆ°è·Ÿ uname -r ä¸€æ¨£çš„ç‰ˆæœ¬æˆ–æ˜¯èª¿ä½ uname åˆ°ä¸€æ¨£çš„ç‰ˆæœ¬ install linux-kernel-headers kernel-package:\nsudo apt-get install linux-kernel-headers kernel-package è§£æ±ºæ–¹æ³•ï¼šhttps://www.linuxprobe.com/ubuntu-nvidia-v100-gpu.html\nè£œå……ï¼š # è£å®Œä¹‹å¾Œè¦ä½¿ç”¨ nvccï¼š # sudo nano ~/.bashrc\n# åŠ åœ¨æœ€ä¸‹é¢ export PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/lib64:$LD_LIBRARY_PATH\u0026#34; # æˆ–è€…ç”¨é€™å€‹ä¹Ÿå¯ export PATH=\u0026#34;/usr/local/cuda/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/cuda/lib64:$LD_LIBRARY_PATH\u0026#34; # æˆ–è€…ç”¨é€™å€‹ä¹Ÿå¯ (æˆ‘æ˜¯ç”¨é€™å€‹) # ref : https://blog.csdn.net/qq_41094058/article/details/116207333 if [ $LD_LIBRARY_PATH ]; then export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:\u0026#39;/usr/local/cuda/lib64\u0026#39; else export LD_LIBRARY_PATH=\u0026#39;/usr/local/cuda/lib64\u0026#39; fi if [ $PATH ]; then export PATH=$PATH:\u0026#39;/usr/local/cuda/bin\u0026#39; else export PATH=\u0026#39;/usr/local/cuda/bin\u0026#39; fi if [ $CUDA_HOME ]; then export CUDA_HOME=$CUDA_HOME:\u0026#39;/usr/local/cuda\u0026#39; else export CUDA_HOME=\u0026#39;/usr/local/cuda\u0026#39; fi source ~/.bashrc\nnvcc --version å°æ–¼å¤šç‰ˆæœ¬ cuda çš„åˆ‡æ›ï¼Œä¹Ÿå¯ä»¥é€šéå»ºç«‹é€£çµçš„æ–¹æ³•ï¼š\nsudo rm -rf cuda sudo ln -s /usr/local/cuda-11.1/ /usr/local/cuda Check Driver, CUDA, NVCC\nnvidia-smi nvcc -V åƒè€ƒè³‡æ–™ï¼šhttps://zhuanlan.zhihu.com/p/338507526\nGPU ç›¸é—œè³‡æºï¼š # Nvidia Download Website: https://developer.nvidia.com/downloads Nvidia CUDA Toolkit : https://developer.nvidia.com/cuda-downloads Nvidia Driver : https://www.nvidia.com.tw/Download/index.aspx?lang=tw GPU Check Command: # nvidia-smi nvcc -V GPU è£œå……: # æ­é…æ€§ : GPU é©…å‹• å»è·Ÿ CUDA åŒ¹é…ï¼Œ CUDA å¯ä»¥è£ä½ä¸€é»ç‰ˆæœ¬çš„åªè¦ GPU é©…å‹•æœ‰å…¼å®¹åˆ°å³å¯ nvidia-smi é¡¯ç¤ºçš„æ˜¯ç•¶å‰é©…å‹•æ”¯æŒçš„æœ€é«˜ç‰ˆæœ¬çš„ cudaã€‚ ä¸æ˜¯å·²ç¶“å®‰è£çš„ cuda ç‰ˆæœ¬ã€‚ Cuda Toolkit ç‰ˆæœ¬å…§è£çš„å„å¥—ä»¶ç‰ˆæœ¬ https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html CUDA : ç‚º GPU é€šç”¨è¨ˆç®—å»ºæ§‹çš„é‹ç®—å¹³å° cudnn : ç‚ºæ·±åº¦å­¸ç¿’è¨ˆç®—è¨­è¨ˆçš„å¥—ä»¶ CUDA Toolkit (nvidia) : CUDA å®Œæ•´çš„å·¥å…·å®‰è£åŒ…ï¼Œå…¶ä¸­æä¾› Nvidia é©…å‹•ã€é–‹ç™¼ CUDA ç¨‹å¼ç›¸é—œé–‹ç™¼å·¥å…·ç­‰å¯ä¾›å®‰è£çš„é¸é …ã€‚åŒ…æ‹¬ CUDA ç·¨è­¯å™¨ã€IDEã€èª¿é©å™¨ç­‰ï¼ŒCUDA ç¨‹å¼æ‰€å°æ‡‰çš„å•ä»¶ä»¥åŠä»–å€‘çš„é ­æ–‡ä»¶ CUDA Toolkit (Pytorch): CUDA ä¸å®Œæ•´çš„å·¥å…·å®‰è£åŒ…ï¼Œå…¶ä¸»è¦åŒ…å«åœ¨ä½¿ç”¨ CUDA ç›¸é—œåŠŸèƒ½æ™‚æ‰€ä¾è³´çš„å‹•æ…‹é€£æ¥åº«ã€‚ä¸æœƒå®‰è£é©…å‹•ç¨‹å¼!! NVCC æ˜¯ CUDA çš„ç·¨è­¯å™¨ï¼Œåªæ˜¯ CUDA Toolkit çš„ä¸€éƒ¨åˆ† K8så®‰è£ (æœƒå¯«èªªåœ¨å“ªå€‹ Node ä¸Šå®‰è£ï¼Œæ²’ç‰¹åˆ¥å¯«å°±æ˜¯æ¯å°éƒ½è¦è£) # set hostname (All nodes) ä¾ç…§ä½ è¦è¨­å®šçš„ Hostname å»è¨­å®š\nsudo hostnamectl set-hostname \u0026lt;k8smaster.example.net\u0026gt; exec bash set /etc/hosts (All nodes)\n// IP Hostname ServerName 192.168.137.154 k8sc.net k8sc 192.168.137.168 k8sn1.net k8sn1 192.168.137.249 k8sn2.net k8sn2 disable swap , selinux, firewall\nswap:\nswapon --show sudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab sudo swapoff -a selinux:\nsudo selinux-config-enforcing # or sudo vim /etc/selinux/config Modify =\u0026gt; SELINUX=disabled Reboot system firewall:\nsudo ufw status sudo ufw disabl åƒè€ƒè³‡æ–™ï¼šhttps://www.zhihu.com/question/374752553/answer/1052244227\nmodify core\nsudo tee /etc/modules-load.d/containerd.conf \u0026lt;\u0026lt;EOF overlay br_netfilter EOF reload mod\nsudo modprobe overlay sudo modprobe br_netfilter modify core\nsudo tee /etc/sysctl.d/kubernetes.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF reload system\nsudo sysctl --system install CRI suite\nsudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates add docker apt repository\nAdd Docker\u0026rsquo;s official GPG key:\nsudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg Add the repository to Apt sources:\necho \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null install Docker\nsudo apt-get update # å®‰è£ docker ç›¸é—œå¥—ä»¶ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # æ–°å¢ docker ç¾¤çµ„ sudo groupadd docker # æŠŠç¾åœ¨çš„ $USER åŠ åˆ° docker ä¸­ sudo usermod -aG docker $USER # åˆ‡æ›åˆ° docker ç¾¤çµ„ newgrp docker è¨­ç½® docker ä½¿ç”¨ cgroupdriver=systemd å› ç‚ºè¦é…åˆ k8s ä½¿ç”¨ systemd æ‰€ä»¥è¦è¨­å®š docker daemon\nmkdir -p /etc/docker vim /etc/docker/daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } systemctl enable docker \u0026amp;\u0026amp; systemctl systemctl status docker install cri-docker\nV0.3.9ï¼š wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.9/cri-dockerd_0.3.9.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.9.3-0.ubuntu-jammy_amd64.deb systemctl daemon-reload systemctl enable cri-docker \u0026amp;\u0026amp; systemctl start cri-docker \u0026amp;\u0026amp; systemctl status cri-docker V0.3.10ï¼š wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.10/cri-dockerd_0.3.10.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.10.3-0.ubuntu-jammy_amd64.deb systemctl daemon-reload systemctl enable cri-docker \u0026amp;\u0026amp; systemctl start cri-docker \u0026amp;\u0026amp; systemctl status cri-docker Docker è©¦è·‘: Run container =\u0026gt; docker run --name hello-world hello-world çœ‹è³‡æº =\u0026gt; docker ps -a åˆªé™¤ container =\u0026gt; docker rm hello-world Add Kubernetes apt repositoryï¼š\n# (æ¨è–¦)å®˜æ–¹ä½¿ç”¨åŸç”ŸåŒ…ç®¡ç†å·¥å…·å®‰è£… sudo apt-get update # apt-transport-https å¯ä»¥æ˜¯ä¸€ä¸ªè™šæ‹ŸåŒ…ï¼›å¦‚æœæ˜¯è¿™æ ·ï¼Œä½ å¯ä»¥è·³è¿‡è¿™ä¸ªåŒ… sudo apt-get install -y apt-transport-https ca-certificates curl # å¦‚æœ `/etc/apt/keyrings` ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åº”åœ¨ curl å‘½ä»¤ä¹‹å‰åˆ›å»ºå®ƒï¼Œè¯·é˜…è¯»ä¸‹é¢çš„æ³¨é‡Šã€‚ sudo mkdir -p -m 755 /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list !!è¨»è§£: æƒ³è¦åˆ¥çš„ç‰ˆæœ¬è«‹æ”¹ V?.?? è¦å‡çº§ kubectl åˆ°åˆ«çš„æ¬¡è¦ç‰ˆæœ¬ï¼Œä½ éœ€è¦å…ˆå‡çº§ /etc/apt/sources.list.d/kubernetes.list ä¸­çš„ç‰ˆæœ¬ï¼Œ å†è¿è¡Œ apt-get update å’Œ apt-get upgradeã€‚ ref: https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/ install Kubernetes suite for Kubectl, kubeadm, kubelet\nsudo apt update sudo apt install -y kubelet kubeadm kubectl (option) sudo apt-mark hold kubelet kubeadm kubectl Kubeadm init (Controller Node) ç‰¹åˆ¥æ³¨æ„ï¼ï¼ åƒæ•¸åŸºæœ¬ä¸Šéƒ½æ˜¯ä¾ç…§ä½ çš„ç’°å¢ƒç‹€æ…‹å»æ–°å¢æˆ–ä¿®æ”¹ï¼ï¼ \u0026ndash;pod-network-cidr \u0026lt;cidr_ip\u0026gt; è«‹ä¾ç…§ä½ å¾Œä¾†è¦ä½¿ç”¨çš„ cidr_ip éœ€æ±‚å»ä¿®æ”¹ Normal command: sudo kubeadm init --control-plane-endpoint=k8sc.net --pod-network-cidr=172.168.0.0/16 Docekr cri-dockerd command: sudo kubeadm init --control-plane-endpoint=k8sc.net --pod-network-cidr=172.168.0.0/16 --cri-socket unix:///run/cri-dockerd.sock åˆå§‹åŒ–å¥½æœƒé¡¯ç¤º Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 \\ --control-plane Then you can join any number of worker nodes by running the following on each as root: kubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 Work Node Join cluster (WorkNode) è«‹ä¾ç…§ä½ å‰›å‰›å»ºç«‹å¥½çš„ k8s å»ä¿®æ”¹è¦è¼¸å…¥çš„ kubeadm join code Normal command:\nkubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 Docekr cri-dockerd command:\nkubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 --cri-socket unix:///run/cri-dockerd.sock Check all node join (MasterNode) - kubectl get nodes\ninstall Calico Pod network suite (MasterNode)\næ­¤ç‰ˆæœ¬ç‚º V3.27.0 å› ç‚ºé€™æ¬¡ä½¿ç”¨çš„æ˜¯ --pod-network-cidr=172.168.0.0/16 æ‰€ä»¥éœ€è¦æ”¹æ–‡ä»¶\n# å»ºç«‹å®ƒæ‰€éœ€è¦çš„å¥—ä»¶ kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml # ä¸‹è¼‰è¨­å®šæª” wget https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml ä¿®æ”¹è¨­å®šæª”ï¼š\n# å› ç‚ºé è¨­æ˜¯ 192.168.0.0 è·Ÿæˆ‘å€‘ IP æ’åˆ°,ä¿®æ”¹æˆ 172.168.0.0 nano custom-resources.yaml # This section includes base Calico installation configuration. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation apiVersion: operator.tigera.io/v1 kind: Installation metadata: name: default spec: # Configures Calico networking. calicoNetwork: # Note: The ipPools section cannot be modified post-install. ipPools: - blockSize: 26 cidr: 172.168.0.0/16 \u0026lt;= ä¿®æ”¹é€™ encapsulation: VXLANCrossSubnet natOutgoing: Enabled nodeSelector: all() --- éƒ¨å±¬ CNIï¼š\nkubectl create -f custom-resources.yaml Waite all pods Runningï¼š\nwatch kubectl get pods -n calico-system # or watch kubectl get pods --all-namespaces # ç§»é™¤åœ¨ control-plane ä¸Šçš„ æ±™é»(taint) kubectl taint nodes --all node-role.kubernetes.io/control-plane- # ç§»é™¤åœ¨ master ä¸Šçš„ æ±™é»(taint) kubectl taint nodes --all node-role.kubernetes.io/master- åƒè€ƒè³‡æ–™ï¼š https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart https://www.cnblogs.com/khtt/p/16563088.html Check All Cluster Node STATUS\nkubectl get nodes -o wide æœƒéƒ½ç›¸ä¸‹é¢ä¸€æ¨£é¡¯ç¤º Ready ä»£è¡¨ k8s ä»¥å¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼ï¼\nNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8smaster.net Ready control-plane 52m v1.29.1 192.8.1.66 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 k8snode1.net Ready \u0026lt;none\u0026gt; 23m v1.29.1 192.8.1.65 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 k8snode2.net Ready \u0026lt;none\u0026gt; 23m v1.29.1 192.8.1.69 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 Trouble Shooting: # \u0026ldquo;åˆå§‹éŒ¯èª¤\u0026quot;è¦é‡å»º k8sï¼š\n# å¦‚æœ kubeadm reset (ä½¿ç”¨ containerd.io) kubeadm reset (ä½¿ç”¨ cri-dockerd) kubeadm reset --cri-socket unix:///run/cri-dockerd.sock # æ¸…é™¤ k8s æ–‡ä»¶ rm -rf $HOME/.kube # é‡å•Ÿ k8s æœå‹™ systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart kubelet # ä¹‹å¾Œè«‹å›åˆ° step.15 \u0026ldquo;å»ºç«‹ CNI ä¹‹å¾Œ\u0026quot;é‡å»º k8sï¼š\n# å¦‚æœ kubeadm reset (ä½¿ç”¨ containerd.io) kubeadm reset (ä½¿ç”¨ cri-dockerd) kubeadm reset --cri-socket unix:///run/cri-dockerd.sock # åˆªé™¤ CNI æ–‡ä»¶ rm -rf /etc/cni/net.d # åˆªé™¤ä¹‹å‰ CNI æ‰€å»ºç«‹çš„ iptable sudo iptables -F \u0026amp;\u0026amp; sudo iptables -t nat -F \u0026amp;\u0026amp; sudo iptables -t mangle -F \u0026amp;\u0026amp; sudo iptables -X # åˆªé™¤ k8s æ–‡ä»¶ sudo rm -f $HOME/.kube/config kubectl get nodes å¦‚æœå‡ºç¾\nroot@k8sc:~/K8s# kubectl get node E0201 16:03:23.299872 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.300534 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.302286 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.302901 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.304646 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused The connection to the server localhost:8080 was refused - did you specify the right host or port? è§£æ±ºæ–¹æ³•: =\u0026gt; mkdir ~/.kube =\u0026gt; cp /etc/kubernetes/admin.conf ~/.kube/config åƒè€ƒè³‡æ–™ï¼š rfe: https://www.gbase8.cn/12320 Docker use GPU # æœ‰ GPU çš„ host éƒ½éœ€è¦è£\ninstall nvidia-container-toolkit\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/libnvidia-container.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y nvidia-container-toolkit Setting /etc/docker/daemon.json\nnano /etc/docker/daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;default-runtime\u0026#34;: \u0026#34;nvidia\u0026#34;, \u0026#34;runtimes\u0026#34;: { \u0026#34;nvidia\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/usr/bin/nvidia-container-runtime\u0026#34;, \u0026#34;runtimeArgs\u0026#34;: [] } } } sudo systemctl restart docker check container can use GPU\ndocker run --rm -it nvcr.io/nvidia/cuda:10.2-base nvidia-smi å¦‚æœå¯ä»¥çœ‹åˆ°ä¸‹é¢é€™æ¨£ Nvidia-smi ç•«é¢å°±ä»£è¡¨ä½ çš„ docker container è£¡å¯ä»¥ä½¿ç”¨ GPU äº†!!\nThu Feb 1 09:55:47 2024 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 545.23.08 Driver Version: 545.23.08 CUDA Version: 12.3 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 Tesla T4 On | 00000000:18:00.0 Off | 0 | | N/A 28C P8 9W / 70W | 7MiB / 15360MiB | 0% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ åƒè€ƒè³‡æ–™ï¼š https://github.com/NVIDIA/k8s-device-plugin?tab=readme-ov-file#enabling-gpu-support-in-kubernetes Install NGC # ç‚ºäº†å¯ä»¥è®“ k8s å¯ä»¥æ‰¾åˆ° GPU è³‡æºéœ€è¦ Nvidia NGC ä¸­çš„ images\nInstall NGC Command Line\nwget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.37.0/files/ngccli_linux.zip -O ngccli_linux.zip \u0026amp;\u0026amp; unzip ngccli_linux.zip find ngc-cli/ -type f -exec md5sum {} + | LC_ALL=C sort | md5sum -c ngc-cli.md5 chmod u+x ngc-cli/ngc echo \u0026#34;export PATH=\\\u0026#34;\\$PATH:$(pwd)/ngc-cli\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/.bash_profile \u0026amp;\u0026amp; source ~/.bash_profile # rfe: https://ngc.nvidia.com/setup/installers/cli set NGC config set\nngc.nvidia.com è¾¦ä¸€å€‹æœƒå“¡ å³ä¸Šè§’é ­åƒ SetUp -\u0026gt; API Key Generate API Key ngc config set è¼¸å…¥ api key è·Ÿä¸€äº›è³‡æ–™ docker login nvcr.io Username: è¼¸å…¥ =\u0026gt; $oauthtoken Password: è¼¸å…¥ä½ çš„ token å®Œæˆå°±æœƒåƒé€™æ¨£ root@k8sc:~/NVD# docker login nvcr.io Username: $oauthtoken Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded ç¢ºèªæ˜¯å¦å¯é€£ä¸Šä¸¦ä¸‹è¼‰å›ä¾† images docker pull nvcr.io/nvidia/k8s-device-plugin:v0.14.4 Check Pods Ruing\nroot@k8sc:~/NVD/test# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE ........ ........ ...... kube-system nvidia-device-plugin-daemonset-g7pn5 1/1 Running 0 11m kube-system nvidia-device-plugin-daemonset-j5t79 1/1 Running 0 11m kube-system nvidia-device-plugin-daemonset-pjjr9 1/1 Running 0 11m ........ ........ ...... Check kubectl describe nodes ç¢ºèªæœ‰ nvidia.com/gpu å°±ä»£è¡¨æˆåŠŸäº†\nAddresses: InternalIP: 192.168.137.249 Hostname: k8sn2.net Capacity: cpu: 96 ephemeral-storage: 3843514416Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 395820888Ki nvidia.com/gpu: 5 pods: 110 Allocatable: cpu: 96 ephemeral-storage: 3542182879921 hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 395718488Ki nvidia.com/gpu: 5 pods: 110 System Info: Machine ID: 99a1ca0433d9443aafba35201ede1a9b System UUID: d8c50c1b-e0ef-2445-bc45-140d4f639386 Boot ID: 5a8a1c1f-f155-44af-9e70-105e821bd24c Kernel Version: 6.5.0-15-generic OS Image: Ubuntu 22.04.3 LTS Operating System: linux Architecture: amd64 Container Runtime Version: docker://25.0.2 Kubelet Version: v1.29.1 Kube-Proxy Version: v1.29.1 PodCIDR: 172.168.2.0/24 PodCIDRs: 172.168.2.0/24 Non-terminated Pods: (5 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age --------- ---- ------------ ---------- --------------- ------------- --- calico-system calico-node-rvhj8 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h calico-system calico-typha-5f87879b7d-tjwld 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h calico-system csi-node-driver-b58b7 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h kube-system kube-proxy-xcf67 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h kube-system nvidia-device-plugin-daemonset-pjjr9 0 (0%) 0 (0%) 0 (0%) 0 (0%) 14m Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 0 (0%) 0 (0%) memory 0 (0%) 0 (0%) ephemeral-storage 0 (0%) 0 (0%) hugepages-1Gi 0 (0%) 0 (0%) hugepages-2Mi 0 (0%) 0 (0%) nvidia.com/gpu 0 0 Events: \u0026lt;none\u0026gt; åƒè€ƒè³‡æ–™ï¼š https://github.com/NVIDIA/k8s-device-plugin https://bluesmilery.github.io/blogs/afcb1072/ Trouble Shooting: # reboot ä¹‹å¾Œ nvidia-smi æœƒå ±éŒ¯: sudo ubuntu-drivers devices # å®‰è£å¸¶æœ‰ recommended ç‰ˆæœ¬çš„ Driver sudo apt-get install nvidia-driver-\u0026lt;*\u0026gt; # ref: # https://zhuanlan.zhihu.com/p/337013545 # https://www.zhihu.com/question/474222642 create -f k8s device plugin ä¹‹å¾Œç™¼ç¾ control-plane æ²’æœ‰è¢«æ´¾ç™¼ä»»å‹™ï¼Œ step.19 æ²’åšåˆ°æ­¤å‹•ä½œï¼Œè¼¸å…¥å®Œå³å¯ # ç§»é™¤åœ¨ control-plane ä¸Šçš„ æ±™é»(taint) kubectl taint nodes --all node-role.kubernetes.io/control-plane- # ç§»é™¤åœ¨ master ä¸Šçš„ æ±™é»(taint) kubectl taint nodes --all node-role.kubernetes.io/master- GPU Burn # ä½¿ç”¨ wilicc/gpu-burn ä½œç‚º GPU Burn ç¨‹å¼ä¸¦ä¸”æ‰“åŒ…æˆ images ä½¿ç”¨\nwilicc/gpu-burn to image git clone https://github.com/wilicc/gpu-burn cd gpu-burn nano Dockerfile # æŠŠå®ƒä¿®æ”¹ç‰ˆæœ¬åŠåŸ·è¡Œæ–¹å¼æˆæˆ‘å€‘è¦çš„æ¨£å­æ–¹ä¾¿å¾Œé¢ k8s ä½¿ç”¨ ARG CUDA_VERSION=12.3.1 ARG IMAGE_DISTRO=ubuntu22.04 FROM nvidia/cuda:${CUDA_VERSION}-devel-${IMAGE_DISTRO} AS builder WORKDIR /build COPY . /build/ RUN make FROM nvidia/cuda:${CUDA_VERSION}-runtime-${IMAGE_DISTRO} COPY --from=builder /build/gpu_burn /app/ COPY --from=builder /build/compare.ptx /app/ WORKDIR /app # Create a /app/result directory and link it to the local ./result directory RUN mkdir /app/result \u0026amp;\u0026amp; ln -s /app/result /result # æ‰“åŒ…æˆ Images docker build -t gpu_burn . # ç¢ºèªæ˜¯å¦æœ‰æ‰“åŒ…å¥½çš„ images docker images Private Docker Registry Server # å› ç‚ºéœ€è¦ä¸‹åœ¨è‡ªå·±æ‰“åŒ…çš„ image çµ¦å…¶ä»– node ä½¿ç”¨åˆä¸æƒ³ä¸Šå‚³åˆ° dockerhub æ‰€ä»¥è‡ªå·±å»ºä¸€å€‹ Private Docker Registry\n# ç”¨ docker æ¶èµ· Registry docker run -d --restart always -p 5000:5000 -v /root/K8s/registry:/var/lib/registry --name registry registry:2 # æŠŠæˆ‘å€‘å‰›å‰›æ‰“åŒ…å¥½çš„ image æ‰“ä¸Š tag docker tag \u0026lt;images_name\u0026gt; \u0026lt;registries_ip\u0026gt;:5000/\u0026lt;images_name\u0026gt; # åœ¨æ‰€æœ‰è¦ä¸‹è¼‰çš„ server ä¿®æ”¹ docker è¨­å®šæª”æ–°å¢ä»¥ä¸‹ code nano /etc/docker/daemon.json (all node) \u0026#34;live-restore\u0026#34;: true, \u0026#34;group\u0026#34;: \u0026#34;dockerroot\u0026#34;, \u0026#34;insecure-registries\u0026#34;: [\u0026#34;\u0026lt;registries_ip\u0026gt;:5000\u0026#34;] # é‡å•Ÿ docker è®“ä»–è®€å–æ–°è¨­å®šæª” (all node) systemctl restart docker # ä¸Šå‚³å‰›å‰›æ‰“ä¸Š tag çš„ images docker push \u0026lt;registries_IP\u0026gt;:5000/\u0026lt;images_name\u0026gt; K8s exec GPU-Burn # gpu-burn-CN5c.yaml:\napiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-controller labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sc.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # è¨­ç½®æ¯å€‹ Pod ä½¿ç”¨çš„ GPU æ•¸é‡ volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory --- apiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-node1 labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sn1.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # è¨­ç½®æ¯å€‹ Pod ä½¿ç”¨çš„ GPU æ•¸é‡ volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory --- apiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-node2 labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sn2.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # è¨­ç½®æ¯å€‹ Pod ä½¿ç”¨çš„ GPU æ•¸é‡ volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory gpu-burn-R4c-3pod.yaml:\napiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-random labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 completions: 3 # å®Œæˆå¹¾å€‹ parallelism: 3 # åŒæ™‚åŸ·è¡Œå¹¾å€‹ template: metadata: labels: app: gpu-burn spec: restartPolicy: Never containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 4 # è¨­ç½®æ¯å€‹ Pod ä½¿ç”¨çš„ GPU æ•¸é‡ volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory å»ºç«‹ä»»å‹™: =\u0026gt; kubectl create -f \u0026lt;yaml\u0026gt; åˆªé™¤ä»»å‹™: =\u0026gt; kubectl delete -f \u0026lt;yaml\u0026gt; æŸ¥çœ‹ job : =\u0026gt; kubectl get pods æŸ¥çœ‹ job è©³ç´°è³‡è¨Š : =\u0026gt; kubectl describe pods or =\u0026gt; kubectl describe pod \u0026lt;pod_name\u0026gt; æŸ¥çœ‹åŸ·è¡Œ Logs : =\u0026gt; kubectl Logs \u0026lt;pod_name\u0026gt; ","date":"2024å¹´02æœˆ28æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/k8sgpu/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡ä»‹ç´¹åœ¨ Ubuntu Server 22.04 ä¸Šå®‰è£ Docker èˆ‡ Kubernetes ä¸¦åœ¨ Container ä¸Šä½¿ç”¨ GPU çš„ç´€éŒ„\u003c/p\u003e","title":"å¦‚ä½•æ­£ç¢ºåœ¨ Docker èˆ‡ K8s ä½¿ç”¨ GPU","type":"posts"},{"content":"","date":"2024å¹´02æœˆ08æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/s2d/","section":"Tags","summary":"","title":"S2D","type":"tags"},{"content":"æœ¬æ–‡ç´€éŒ„ Windows Server 2019 ä¸Šå»ºç«‹ S2D çš„éç¨‹ï¼ï¼\nå…ˆä»‹ç´¹å®‰è£ç’°å¢ƒï¼Œæ­¤æ¬¡æ˜¯ä¸å« ADDS ä¸¦ä½¿ç”¨å¤–æ¥ USB ç•¶ä½œä»²è£é©—è­‰æ–¹å¼éƒ¨å±¬ S2Dã€‚\næˆ‘å€‘ç¸½å…±æœ‰ 2 å°æ©Ÿå°åˆ†åˆ¥æ˜¯ Node1 è·Ÿ Node2ï¼Œæˆ‘å€‘é€™é‚ŠæŠŠ Node1 ç•¶ä¸»è¦éƒ¨ç½²åŠå¾ŒçºŒæ“ä½œæ©Ÿå°ã€‚\né‚£ç”±æ–¼æˆ‘å€‘æ²’æœ‰ ADDS è·Ÿ DHCP æ‰€ä»¥æˆ‘å€‘å°±å…ˆæŠŠ Node1 è·Ÿ Node2 è¨­å®šç‚ºéœæ…‹ IPã€‚\nNode1 IP : 192.8.1.42 Node2 IP : 192.8.1.43 # é€™é‚Šå…ˆæ“¬å®šä¸€å€‹çµ¦ Cluster å»ºç«‹ç”¨çš„ IP Cluster IP : 192.8.1.57 Quorum ä»²è£æ©Ÿåˆ¶ : \u0026lt;Host IP\u0026gt;/Q:\\\\ å»ºç«‹ S2D æ­¥é©Ÿ # è¨­å®š hosts (æ¯å€‹ Node éƒ½éœ€è¦è¨­å®š) ç”±æ–¼æˆ‘å€‘æ˜¯æ²’æœ‰ DHCPã€ADDS æƒ…æ³ä¸‹éƒ¨å±¬æˆ‘å€‘è¦è®“æ©Ÿå°äº’ç›¸å¯ä»¥èƒ½æºé€šåˆ°æ‰€ä»¥è¦è¨­å®šæœ¬æ©Ÿä¸Šçš„ hosts ç·¨è¼¯ C:\\Windows\\System32\\drivers\\etc\\hosts\nEx: IP hostname 192.8.1.43 Node2 192.8.1.42 Node1 192.8.1.57 S2D-Cluster è¨­å®š TrustedHosts (æ¯å€‹ Node éƒ½éœ€è¦è¨­å®š)\næ–°å¢ TrustedHosts Set-Item WSMan:\\localhost\\Client\\TrustedHosts -Concatenate -Value \u0026#34;S2D-Controller , Node1 , Node2â€œ ç¢ºèª TrustedHosts Get-Item WSMAN:\\Localhost\\Client\\TrustedHosts å®‰è£éœ€è¦ç”¨åˆ°çš„æœå‹™ (æ¯å€‹ Node éƒ½éœ€è¦è¨­å®š)\nå®‰è£å¥—ä»¶ Windows è…³è‰²å’ŒåŠŸèƒ½ Install-WindowsFeature -Name \u0026#34;Hyper-V\u0026#34;, \u0026#34;Failover-Clustering\u0026#34;, \u0026#34;Data-Center-Bridging\u0026#34;, \u0026#34;RSAT-Clustering-PowerShell\u0026#34;, \u0026#34;Hyper-V-PowerShell\u0026#34;, \u0026#34;FS-FileServer\u0026#34; -IncludeManagementTools æ¸…ç©º S2D ç£ç¢Ÿ (æ¯å€‹ Node éƒ½éœ€è¦è¨­å®š)\nåˆå§‹åŒ– S2D ç¡¬ç¢Ÿ (ç¢ºä¿ç¡¬ç¢Ÿéƒ½æ˜¯æ²’æœ‰è¢« Claimed çš„ç‹€æ…‹ )\nå¦‚æœç¡¬ç¢Ÿæ²’è¨­å®šéå°±ä¸éœ€è¦è©²æ­¥é©Ÿ(é ˆé¿é–‹ä½œæ¥­ç³»çµ±ç¡¬ç¢Ÿ)\nè«‹å…ˆä»¥ Diskpart æŒ‡ä»¤ç¢ºèªç¡¬ç¢Ÿç·¨è™Ÿï¼Œç„¶å¾Œå°±å¯ä»¥ä½¿ç”¨ Clear-Disk çš„ PowerShell ä¾†æ¸…æƒç¡¬ç¢Ÿä¸­æ‰€æœ‰çš„å…§å®¹ã€‚\n(è«‹æ³¨æ„!! ç¡¬ç¢Ÿå¿…é ˆç‚º Online ç‹€æ…‹ä¸‹ï¼Œé‚£éº¼ Clear-Disk æŒ‡ä»¤æ‰èƒ½é †åˆ©æ¸…æƒç¡¬ç¢Ÿå…§å®¹ã€‚)\n#è™•ç†å–®é¡†ç¡¬ç¢Ÿï¼š Clear-Disk â€“Number 1 -RemoveData -RemoveOEM #ä¸€æ¬¡è™•ç†å¤šé¡†ç¡¬ç¢Ÿï¼š Clear-Disk â€“Number 1,2,3,4 -RemoveData -RemoveOEM åŸ·è¡Œå®Œ Clear-Disk å‹•ä½œå¾Œï¼Œç¡¬ç¢Ÿçš„ç‹€æ…‹æ‡‰æ¢å¾©åˆ°ã€ŒUnknownã€Not Initializedã€Unallocatedã€æ‰æ˜¯æ­£ç¢ºç‹€æ…‹\nè«‹æ³¨æ„ !! è‹¥ç¡¬ç¢Ÿæœªå‘ˆç¾æ­£ç¢ºç‹€æ…‹çš„è©±ï¼Œç¨å¾Œå•Ÿå‹•ã€ŒSoftware Storage Busã€æ©Ÿåˆ¶æ™‚ï¼Œå°‡ç„¡æ³•é †åˆ©æŠŠç¯€é»ä¸»æ©Ÿçš„æœ¬æ©Ÿç¡¬ç¢ŸåŠ å…¥è‡³å„²å­˜è³‡æºæ± ä¸­ã€‚\næ¸¬è©¦å»ºç«‹ Cluster ç’°å¢ƒ (Node1)\næ¸¬è©¦ Node1 Node2 æ˜¯å¦ç¬¦åˆå»ºç«‹ Cluster çš„ç’°å¢ƒ\nTest-Cluster Node1 , Node2 æ¸¬è©¦å®Œæœƒé¡¯ç¤ºç›®å‰å•é¡Œèˆ‡å ±å‘Šç”¢ç”Ÿçš„åœ°æ–¹ï¼Œæœ‰å•é¡Œå»ºè­°å»çœ‹å ±å‘Šæœƒæœ‰è©³ç´°çš„å•é¡Œèªªæ˜ å»ºç«‹ Cluster (Node1)\nå»ºç«‹ Cluster New-Cluster â€“Name S2DCluster -Node Node1,Node2 -AdministrativeAccessPoint DNS -StaticAddress 192.8.1.57 Quorum USB è¨­å®š (Node2)\nå…ˆåˆ° USB Propertiesï¼Œä¹‹å¾Œé–‹å•Ÿ Shareâ€¦ Advanced Shareingâ€¦ \u0026gt; Permissions \u0026gt; Everyone é»é¸ Full Control è¨­å®š Cluster çš„ä»²è£æ©Ÿåˆ¶ (Node1)\nè¨­å®š ä»²è£æ©Ÿåˆ¶ç‚ºå¤–æ¥ USB Set-ClusterQuorum -FileShareWitness \\\\192.8.1.43\\q -Credential $(Get-Credential) ä¹‹å¾Œæœƒå‡ºç¾ç™»å…¥ç•«é¢è«‹è¼¸å…¥ç›¸å°æ‡‰æ©Ÿå°çš„å¸³è™Ÿèˆ‡å¯†ç¢¼ é–‹å•Ÿ Storage Spaces Direct æœå‹™ (Node1)\nEnable-ClusterStorageSpacesDirect è·‘å®Œä¸€å°æ®µä¹‹å¾Œå®ƒæœƒå•ä½ æ˜¯ä¸æ˜¯è¦ä½¿ç”¨ä½ å‰›å‰›å‰µçš„ Cluster è¼¸å…¥ Y é–‹å§‹å»ºç«‹ æŸ¥çœ‹ Failover Cluster Manager (Node1 or Node2)\nServer Manager \u0026gt; Tool \u0026gt; Failover Cluster Manager é»æ“Š Failover Cluster Manager å³éµ \u0026gt; Connect to Cluster \u0026gt; é»æ“Š OK å®ƒæœƒè‡ªå·±æ‰¾åˆ°ç›®å‰æ©Ÿå°æœ‰é€£æ¥çš„ Cluster ä½ å¯ä»¥åœ¨ Disks, Pools ä¸‹æ‰¾åˆ°å‰›å‰›å»ºç«‹å¥½çš„ Disks, Pools å»ºç«‹ Share Disk æ­¥é©Ÿ # å»ºç«‹å¥½ Cluster å¾Œæƒ³è¦åˆ‡å‡ºä¸€å€‹ç©ºé–“çµ¦æŸå€‹åŠŸèƒ½ç”¨å¯ä»¥ä¾ç…§ä»¥ä¸‹æ–¹æ³•åŸ·è¡Œ å…ˆåœ¨ Pool ä¸­é»æ“Šå³éµï¼Œé»é¸ New Virtual Disk ä¹‹å¾Œåˆ‡å‡ºä½ è¦çš„ç©ºé–“ åˆ‡å®Œä¹‹å¾Œåˆ°å¦ä¸€å° Node ä¸‹ Disk Management å¯ä»¥çœ‹åˆ°æ­¤ç¡¬ç¢Ÿ åˆå§‹åŒ–å®ƒ(å¯ä»¥ç”¨ ReFS æˆ–æ˜¯ NTFS æ ¼å¼åŒ–)ä¸¦è¨­å®š æ§½å€ å›åˆ°åŸæœ¬ Node ä¸‹åˆ° Failover Cluster Manager \u0026gt; Disks ä¸‹æŠŠç¡¬ç¢ŸåŠ å…¥åˆ° Cluster Share Volumes å¾ Pool ä¸­å»ºç«‹æ–°çš„è™›æ“¬ç£ç¢Ÿ (Node1)\nå¾ Pool ä¸­åˆ‡å‡ºä¸€å€‹è¦ä½¿ç”¨çš„ç©ºé–“ ç›¡é‡ä¸è¦é¸ Max å› ç‚ºæˆ‘å€‘æ¶æ§‹æ²’æœ‰ç©ºé–“çµ¦å®ƒå¿«å–æœ‰å¯èƒ½åœ¨å»ºæ§‹çš„æ™‚å€™æœƒé€ æˆ Fail åˆ‡å¥½ä¹‹å¾Œçš„å½ˆå‡ºè¦–çª—æ˜¯å¯ä»¥å¹«ä½ å»ºç«‹æ§½å€ä½†ç¾åœ¨çš„æ¶æ§‹ä¸æ˜¯å–®ç´”çš„ä¸€å€‹æ©Ÿå°æˆ–æœ‰ADçš„æƒ…å¢ƒä¸‹æ‰€ä»¥ä¸é©ç”¨ ä¹‹å¾Œæˆ‘å€‘è‡ªå·±æ‰‹å‹•åˆ‡æ§½å€ åˆ‡å®Œä¹‹å¾Œæˆ‘å€‘å¯ä»¥çœ‹åˆ°ä¸‹é¢æœƒé•·å‡ºä¸€å€‹æ–°çš„ Virtual Disk ç¢ºèªæœ‰åˆ‡å‡ºè™›æ“¬ç£ç¢Ÿ (Node2)\nè·³åˆ° Node2 çš„ Disk Management æˆ‘å€‘å¯ä»¥çœ‹åˆ°æœƒæœ‰ä¸€å€‹æ–°çš„æœªå•Ÿç”¨çš„ Disk æ‰‹å‹•åˆ‡å‰²ç£å€ (Node2)\næˆ‘å€‘æ‰‹å‹•å…ˆæ‰‹å‹•å»ºç«‹è·Ÿæ ¼å¼åŒ–(ReFS or NTFS éƒ½å¯ä»¥) ä¹‹å¾ŒæŒ‰å³éµ Change Drive Letter and Paths â€¦ å¹«å®ƒä¸Šæ§½å€ ç¢ºèª Cluster çš„ Pool ä¸Šæ˜¯å¦æœ‰å»ºç«‹å‡ºä¸€å€‹ç£ç¢Ÿ (Node1)\nå›åˆ° Node1 çš„ Failover Cluster Manager \u0026gt; Pool ä¸‹å¯ä»¥çœ‹åˆ°æœ‰äº†æ§½å€ä¸¦ä¸”æ˜¯ ReFS æ ¼å¼è·Ÿæˆ‘å€‘å‰›å‰›åšçš„ç¬¦åˆ ç¢ºèª Cluster çš„ Disk ä¸Šçš„è³‡è¨Š (Node1)\næˆ‘å€‘åˆ° Disks ç¢ºèªå¯ä»¥çœ‹åˆ°é¡ä¼¼çš„å…§å®¹ï¼Œä¸¦ä¸”å¯ä»¥æ³¨æ„åˆ°å®ƒç›®å‰ç‹€æ…‹æ˜¯ Avalable Storage æ–°å¢åˆ° Cluster Share Volumes (Node1)\næˆ‘å€‘å³éµå‰›å‰›å‰µå»ºçš„ Virtual Disk æŒ‰ä¸‹ Add to Cluster Share Volumes æŠŠæˆ‘å€‘çš„ç¡¬ç¢ŸåŠ åˆ° Cluster Share Volumes è®“å…©å€‹ node éƒ½èƒ½ç”¨åˆ° ç¢ºèª Cluster Share Volume ç‹€æ…‹ (Node1)\nåŠ å®Œä¹‹å¾Œæˆ‘å€‘å°±å¯ä»¥çœ‹è¦‹ä¸Šé¢çš„ç‹€æ…‹è®Šæˆ Cluster Share Volume ä¸‹é¢è®Šæˆ CSVFS çš„æ ¼å¼äº† æœƒæ›è¼‰åˆ°æ¯å€‹ Node çš„ C:\\ClusterStorage ä¸‹ ç¢ºèªæ˜¯å¦éƒ½æœ‰æ›è¼‰åˆ°æ¯å€‹ Node ä¸Š (Node1 and Node2)\nåˆ°æ¯å€‹ Node ä¸‹å»é©—è­‰ C:\\ClusterStorage ä¸‹æ˜¯å¦æœ‰ç©ºé–“ è£œå……ï¼š # æ›´æ›ä»²è£æ©Ÿåˆ¶ï¼š # Failover Cluster Manager \u0026gt; å³éµ Cluster \u0026gt; MoreAction \u0026gt; Configure ClusterQuorum Settingsâ€¦ æˆ–æ˜¯ä¾ç…§å‰é¢ Setting USB enable share folder æ–¹å¼ä½¿ç”¨ Command Line ä¾†è¨­å®šæ–°çš„ Quorum ç¢ºèª S2D æå£ç¡¬ç¢Ÿï¼š # ç¢ºèªç¡¬ç¢Ÿç‹€æ…‹ï¼š Get-StoragePool *S2D* | Get-PhysicalDisk æœ‰å•é¡Œçš„ç¡¬ç¢Ÿç‹€æ…‹æœƒå‡ºç¾é¡ä¼¼è¨Šæ¯ OperationalStatusï¼šLost Communicationï¼Œ HealthStatusï¼šWarning æŸ¥çœ‹å—å½±éŸ¿çš„ VirtualDiskï¼š Get-VirtualDisk æœ‰å•é¡Œçš„ VirtualDisk ç‹€æ…‹æœƒå‡ºç¾é¡ä¼¼è¨Šæ¯ HealthStatusï¼šWarning æ’é™¤ S2D æ•…éšœç¡¬ç¢Ÿï¼š # å¾ç¡¬ç¢Ÿå€å°‡æ•…éšœç¡¬ç¢Ÿéæ¿¾å‡ºä¾†ä¸¦å­˜æˆ $FailDisk è®Šæ•¸ $FailDisk = Get-PhysicalDisk |? OperationalStatus -Notlike OK è¨­å®šæ•…éšœç¡¬ç¢Ÿçš„ä½¿ç”¨ç‹€æ…‹ç‚º Retired Set-PhysicalDisk -InputObject $FailDisk -Usage Retired å°‡æ•…éšœç¡¬ç¢Ÿå¾ S2D Pool ä¸­ç§»é™¤ Get-StoragePool *S2D* | Remove-PhysicalDisk -PhysicalDisks $FailDisk ç¢ºèª S2D Pool ä»¥ç„¡æ•…éšœç¡¬ç¢Ÿ Get-StoragePool *S2D* | Get-PhysicalDisk æ–°ç¡¬ç¢ŸåŠ å…¥ Storage Poolï¼š # å°‹æ‰¾å¯ä»¥åŠ å…¥ Storage Pool çš„æ–°ç¡¬ç¢Ÿä¸¦å­˜æˆ $NewDisk è®Šæ•¸ $NewDisk = Get-PhysicalDisk |? CanPool -eq True å°‡æ–°ç¡¬ç¢ŸåŠ å…¥ Storage Pool ä¸­ (è«‹ç¢ºä¿æ–°ç¡¬ç¢Ÿå°šæœªåˆå§‹åŒ–ã€æ ¼å¼åŒ–ï¼Œå¦å‰‡å±†æ™‚ S2D å°‡ç„¡æ³•é †åˆ©å®£å‘ŠåŠä½¿ç”¨æ­¤é¡†æ–°ç¡¬ç¢Ÿ!!) Get-StoragePool *S2D* | Add-PhysicalDisk -PhysicalDisks $NewDisk â€“Verbose ç¢ºèªæ–°ç¡¬ç¢Ÿæ˜¯å¦å·²åŠ å…¥ Storage Pool Get-StoragePool *S2D* | Get-PhysicalDisk æ‰‹å‹•é‡æ–°å¹³å‡å¯«å…¥ Slab è³‡æ–™ # æ­£å¸¸æƒ…æ³ä¸‹ S2D æœƒè‡ªå·±è‡ªå‹•åŸ·è¡Œ S2D Storage Pool Rebalance çš„å‹•ä½œæŠŠè³‡æ–™å¹³å‡å„²å­˜åœ¨æ¯å€‹ç¡¬ç¢Ÿä¸Š æ‰‹å‹•åŸ·è¡Œ S2D Storage Pool Rebalance Get-StoragePool *S2D* | Optimize-StoragePool é€é Show-PrettyPool.ps1 é€™éš»è…³æœ¬å¯ä»¥çœ‹åˆ°ç¡¬ç¢Ÿä¸Šå·²ç¶“å¯«å› Slab è³‡æ–™ æŸ¥çœ‹å¹³è¡¡é€²åº¦ Get-StorageJob Reference # 117 æœŸ - å¾®è»Ÿæœ€æ–° S2D å„²å­˜æŠ€è¡“ï¼Œè·¨ä¼ºæœå™¨ç¡¬ç¢Ÿçµ„æˆè³‡æºæ±  (weithenn blog)\nåœ¨ Windows Server ä¸Šéƒ¨ç½²å„²å­˜ç©ºé–“ç›´æ¥å­˜å– (microsoft.com)\næ·±å…¥å‰–æ S2D Storage Pool (weithenn blog)\nå„²å­˜ç©ºé–“ç›´æ¥å­˜å–çš„å·¢ç‹€å¾©åŸ - Azure Stack HCI (microsoft.com)\nS2D (Storage Spaces Direct) æ›´æ›æ•…éšœç¡¬ç¢Ÿ (weithenn blog)\n","date":"2024å¹´02æœˆ08æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/builds2d/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡ç´€éŒ„ Windows Server 2019 ä¸Šå»ºç«‹ S2D çš„éç¨‹ï¼ï¼\u003c/p\u003e","title":"Windows Server S2D","type":"posts"},{"content":"æœ¬æ–‡ä»‹ç´¹åŸºç¤çš„ Docker Swarm è©²å¦‚ä½•ä½¿ç”¨\nå»ºç«‹æ¸¬è©¦æ©Ÿä¸¦å»ºç«‹æ¸¬è©¦ç’°å¢ƒ # æˆ‘å€‘é€™é‚Šç”¨ Docker-Machine å»ºç«‹æ¸¬è©¦ç’°å¢ƒä¹Ÿå¯ä»¥ç”¨ä¸€èˆ¬çš„VM å»ºç«‹æ¸¬è©¦ç’°å¢ƒéƒ½OKï¼Œåªè¦ç¢ºä¿ç’°å¢ƒä¸Šç¶²è·¯èƒ½é€£é€š Docker èƒ½ç”¨å³å¯ï¼\nDocker-Machine (ç”¨ä¾†å»ºç«‹è™›æ“¬æ©Ÿ for virtualbox)ï¼š\ndocker/machine (github.com) â‡’ æ”¹åç‚º docker-machine.exe\nWindowsï¼šæ”¾åœ¨ C:\\Windows\\System32\nLinuxï¼šæ”¾åœ¨ /usr/bin â‡’ chmod 755 docker-machine\nDocker Swarm è…³è‰²ï¼š # Manager å¢é›†ç®¡ç† ç›®çš„å°±æ˜¯è² è²¬ä¾†ç®¡ç†å¢é›†çš„å®¿ä¸»æ©Ÿï¼Œä¸¦èª¿ç”¨å®‰æ’æ¯å€‹éœ€è¦çš„æœå‹™å®¹å™¨æ‡‰è©²è¦è¢«æ”¾åœ¨å“ªä¸€å°ä¾†åšå•Ÿå‹•ï¼Œç•¶æœå‹™åœæ­¢æ™‚ä¹Ÿè¦è² è²¬å•Ÿå‹•æœå‹™å®¹å™¨ä½¿ä¹‹æ­£å¸¸ä¾†åšæœå‹™çš„æä¾›ã€‚\nWorker Nodes å·¥ä½œç¯€é» Nodeç¿»è­¯æˆç¯€é»ï¼Œç°¡å–®èªªå°±æ˜¯ä»£è¡¨ä¸€å°å°çš„å®¿ä¸»æ©Ÿï¼Œè€ŒåŸ·è¡ŒServiceçš„åœ°æ–¹å°±æ˜¯åœ¨ä»»æ„çš„Nodeç¯€é»ä¸Šã€‚\nDocker Swarm å„ªé»ï¼š # Scaling è‡ªå‹•æ“´å±• Scalingæœ¬èº«æ¦‚å¿µç°¡å–®ï¼Œä¹Ÿæ˜¯é›²ç«¯èƒ½å¸¶ä¾†çš„å…¶ä¸­ä¸€é …åƒ¹å€¼æ‰€éœ€ï¼Œç•¶å›æ‡‰éœ€æ±‚æœå‹™æ•¸é‡æˆ–é€£ç·šæµé‡éå¤§æ™‚ï¼Œèƒ½é€éè‡ªå‹•æ“´å±•æ©Ÿåˆ¶ä¸€æ¬¡å•Ÿå‹•å¤šå€‹ç›¸æ‡‰çš„æœå‹™åŒæ™‚è™•ç†éœ€æ±‚å›æ‡‰èˆ‡å› æ‡‰æµé‡ï¼Œç›´åˆ°æµé‡æˆ–éœ€æ±‚æ¢å¾©æ­£å¸¸ï¼Œå°±å¯ä»¥é€éç¸®å®¹ä¾†æ¸›å°‘æœå‹™æ•¸é‡ï¼Œä»¥ç¯€çœä¸»æ©Ÿæˆæœ¬ã€‚\nLoad Balacning è² è¼‰å¹³è¡¡ ç•¶æµé‡é€²åˆ°Docker Swarmçš„æœå‹™ä¸­ï¼Œæœƒé€éåƒè¼ªè©¢(Round Robin)çš„æ©Ÿåˆ¶å»æŠŠé€²ä¾†çš„æµé‡åšåˆ†æµï¼Œä¹Ÿå°±æ˜¯è¼ªæµæŠŠæµé‡é€åˆ°å„æœå‹™å»ï¼Œèˆ‰ä¾‹ç¬¬ä¸€å€‹é€²ä¾†çµ¦Aå®¹å™¨ï¼Œç¬¬äºŒå€‹é€²ä¾†çµ¦Bå®¹å™¨ï¼Œç¬¬ä¸‰å€‹é€²ä¾†å†çµ¦Aï¼Œä»¥æ­¤é¡æ¨\u0026hellip;\nService Discovery æœå‹™æ¢ç´¢ åœ¨ Docker swarm ä¸­æ¯å€‹æœå‹™éƒ½å¯ä»¥å®šç¾©è‡ªå·±æœå‹™ç¨æœ‰çš„DNSï¼Œè€Œæ¥ä¸‹ä¾†å°±å¯ä»¥è®“å…¶ä»–å®¹å™¨é€éè‡ªè¨‚çš„DNSä¾†ä½¿ç”¨æœå‹™ã€‚\nDocker Swarm æ•´é«”æ¶æ§‹åœ–ï¼š # Docker Swarm ç¶²è·¯æ¶æ§‹åœ–ï¼š # Docker Swarm Commandï¼š # æŸ¥çœ‹ cluster å…§çš„ serverï¼šdocker node ls\nå»ºç«‹æœå‹™ï¼šdocker service create --replicas \u0026lt;æ•¸é‡\u0026gt; --name=\u0026lt;service_name\u0026gt; -p \u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt; \u0026lt;image\u0026gt;\nåˆªé™¤æœå‹™ï¼šdocker service rm \u0026lt;service_name\u0026gt;\næŸ¥çœ‹æœå‹™ï¼šdocker service ps \u0026lt;service_name\u0026gt;\næŸ¥çœ‹æœå‹™ Logï¼šdocker service logs \u0026lt;service_name\u0026gt; -f\næ›´æ–°æœå‹™åƒæ•¸ï¼šdocker service update \u0026lt;option\u0026gt; \u0026lt;service_name\u0026gt;\næŸ¥çœ‹æœå‹™è©³ç´°åƒæ•¸ï¼šdocker service inspect \u0026lt;service_name\u0026gt;\nDocker Swarm æ­å»ºåŸºç¤å¯¦ä½œï¼š # init docker swarm (in master)\ndocker swarm init # æ©Ÿå°ä¸Šæœ‰å¤šå€‹ ip è«‹ä½¿ç”¨ä¸‹é¢çš„ docker swarm init --advertise-addr \u0026lt;äº’pingçš„åˆ°çš„ip\u0026gt; IP å¤ªå¤šçš„ Error messageï¼š init æˆåŠŸï¼š docker swarm join (in node) è¤‡è£½ä¸Šé¢çš„ Join Command\ndocker swarm join --token \u0026lt;docker_swarm_token\u0026gt; \u0026lt;IP\u0026gt;:2377 é€£çµæˆåŠŸï¼š æŸ¥çœ‹ node æ˜¯å¦æ­£ç¢º\ndocker node ls å»ºç«‹æœå‹™\ndocker service create æŸ¥çœ‹æœå‹™æ˜¯å¦å»ºç«‹\ndocker service ps \u0026#34;gyhello\u0026#34; æŸ¥çœ‹æœå‹™æ˜¯å¦æ­£å¸¸å•Ÿç”¨ æŸ¥çœ‹æœå‹™ Logs\ndocker service logs gyhello -f Docker Swarm Load Balancer å¯¦ä½œï¼š # é€™é‚Šæ˜¯ç¤ºç¯„å¾Œç«¯è¨­å®š , å‰ç«¯é‚„éœ€è¦æ›è¼‰ä¸€å€‹ nginx å»åš Load Balancer , é€£åˆ°å‰ç«¯ nginx å¾Œæœƒè‡ªå‹•å°å…¥å¾Œç«¯å…©å°å…¶ä¸­ä¸€å€‹ ip å»ä½¿ç”¨æœå‹™\næ“´å¢(scaling up)ï¼š # docker service scale \u0026lt;service_name\u0026gt;=\u0026lt;æ•¸é‡\u0026gt; # Ex: docker service scale gyhello=5 ç¸®å®¹(scaling down)ï¼š # docker service scale \u0026lt;service_name\u0026gt;=\u0026lt;æ•¸é‡\u0026gt; # Ex: docker service scale gyhello=2 è² è¼‰å¹³è¡¡é©—è­‰ï¼š # # Linux Command: iptables -L -t nat # filter : æ˜¯æµé‡é€²åˆ°å®¿ä¸»æ©Ÿæœ¬èº«ä¾†æ±ºå®šæ˜¯å¦ Accept or Drop or Forwardçš„æ–¹å¼ã€‚ # NAT : æµé‡æœ¬èº«è·Ÿæ­¤å°å®¿ä¸»æ©Ÿä¸¦ç„¡ç›´æ¥é—œä¿‚ï¼Œä¸»è¦ä½œç‚ºä¾†æºèˆ‡ç›®çš„ IP \u0026amp; Porté–“è½‰è‡³å¾Œç«¯å®¹å™¨ä¸»æ©Ÿã€‚ # Mangle : å±¬ç‰¹æ®Šè¡¨æ ¼ï¼Œæœƒå»æ¨™è¨˜æŸäº›è¦æ ¼ä¸¦æ”¹å¯«å°åŒ…ã€‚ é©—è­‰æœƒè¢«å°å…¥åˆ° 172.18.0.2:8080\nifconfig ç¢ºèª docker_gwbridge ç¶²è·¯ä»‹é¢ç›¸é—œè¯ï¼Œé€é ï¼®odeå»ºç«‹Container å¾Œåœ¨èˆ‡å®¹å™¨å»ºç«‹é€£ç·šï¼Œæ•…ç¯€é»ä¸­æ¶µè“‹ä¸€çµ„å®¹å™¨ IPï¼š172.18.0.2\næª¢è¦– Docker ç¶²è·¯çš„è©³ç´°è³‡è¨Šï¼š\ndocker network inspect docker_gwbridge é€™è£¡æœ‰ä¸€å€‹è¢«éš±è—çš„ Container å« ingress-sboxï¼Œçœ‹èµ·ä¾†æµé‡æ˜¯å…ˆé€²å…¥æ­¤ Container å¾Œå†æŠŠæµé‡åˆ†é…åˆ°çœŸæ­£çš„ Service\nIngressï¼š # docker swarm è·Ÿ k8s ä¾æ¨£æ˜¯é€éåœ¨ Masterç«¯ å»ºç«‹ç¶²æ®µå¯ä»¥èˆ‡å¤–ç¶²æºé€šä¸¦åˆ©ç”¨ ipvs æ–¹å¼æŠŠ iptables åŠ åœ¨æ¯å€‹ node ä¸­ä¸¦å°å‡ºæœå‹™çš„ port , é”åˆ°å¤–ç¶²åªè¦é€£ç·šåˆ° masterç«¯ip:port å°±èƒ½ä½¿ç”¨æœå‹™\nReference # æ·±å…¥æµ…å‡ºSwarm(Blog DaoCloud)\nã€äº‘åŸç”Ÿã€‘ä¸€æ–‡ç†è§£Swarmè§£å†³docker serverçš„é›†ç¾¤åŒ–ç®¡ç†å’Œéƒ¨ç½²(çŸ¥ä¹)\nDocker Swarm ç¶²è·¯æ¶æ§‹ä»‹ç´¹ - load balancing traffic path ","date":"2023å¹´11æœˆ26æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/docker-swarm/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡ä»‹ç´¹åŸºç¤çš„ Docker Swarm è©²å¦‚ä½•ä½¿ç”¨\u003c/p\u003e","title":"Docker Swarm å…¥é–€æ•™å­¸","type":"posts"},{"content":"æœ¬æ–‡è¬›è¿° Docker èˆ‡ VM çš„ä¸åŒ èˆ‡ Docker æŒ‡ä»¤\né‡è¦è§€å¿µ Docker != Container # Docker æ¶æ§‹ï¼š # VMï¼š # ç”¨ä¾†å»ºç«‹è™›æ“¬åŒ–é‹ç®—ç’°å¢ƒçš„æŠ€è¡“(OSå±¤ç´šè™›æ“¬åŒ–)\nå„ªé»:\nå®‰å…¨æ€§è¼ƒé«˜ï¼Œå› ç‚ºç¡¬é«”å±¤ä»¥ä¸Šéƒ½è™›æ“¬åŒ– å¯ä»¥é¸æ“‡å„ç¨®ä¸åŒçš„ OS ç¼ºé»:\nImageå¤§å°é€šå¸¸ç‚ºGB å•Ÿå‹•é€Ÿåº¦é€šå¸¸è¦èŠ±å€‹å¹¾åˆ†é˜ è³‡æºä½¿ç”¨è¼ƒå¤šï¼Œå› ç‚ºè¦å°‡ä¸€éƒ¨åˆ†è³‡æºåˆ†çµ¦ VM çš„ä½œæ¥­ç³»çµ± Containerï¼š # Docker æ˜¯å€‹ç®¡ç†å®¹å™¨çš„æœå‹™ï¼Œæä¾›æ‡‰ç”¨å±¤ç´šè™›æ“¬åŒ–æŠ€è¡“ã€‚å®¹å™¨ä¸åƒè™›æ“¬æ©Ÿè¦åœ¨ Host OS ä¸Šå†å®‰è£ Guest OSï¼Œè€Œå¯ä»¥ç›´æ¥å…±ç”¨åº•å±¤ Host OS çš„è³‡æºï¼ŒåŒæ™‚å…·å‚™å…¶æ‡‰ç”¨ç¨‹å¼æ²™ç›’çš„éš”é›¢æ€§ã€‚\nå„ªé»:\nImageå¤§å°é€šå¸¸ç‚ºMB å•Ÿå‹•é€Ÿåº¦è¼ƒå¿« èƒ½å°‡æ›´å¤šè³‡æºé‹ç”¨åœ¨è·‘æœå‹™ä¸Š æ›´æ–°è¼ƒç‚ºå®¹æ˜“ ç¼ºé»:\nå®‰å…¨æ€§è¼ƒå·® åŒä¸€å°æ©Ÿå™¨ä¸­ï¼Œæ¯å€‹ Container çš„ OS éƒ½æ˜¯ç›¸åŒ Docker åƒæ•¸ï¼š # å»ºç«‹ç¶²è·¯é€£æ¥ï¼Œè®“å¤–éƒ¨å¯ä»¥é€éä¸»æ©Ÿç«¯å£å­˜å–å®¹å™¨å…§çš„æœå‹™ docker run -p \u0026lt;hostç«¯port:containerç«¯port\u0026gt; å°‡ä¸»æ©Ÿ (host) çš„ç›®éŒ„æˆ–æª”æ¡ˆæ›è¼‰åˆ°å®¹å™¨å…§çš„æŒ‡å®šè·¯å¾‘ docker run -v \u0026lt;hostç«¯path:containerç«¯path\u0026gt; Docker Commandï¼š # æŠŠ docker image ä¸‹è¼‰ä¸‹ä¾†ï¼š docker pull \u0026lt;image_name:version_Tag\u0026gt;\nå»ºç«‹ç•¶å‰è³‡æ–™å¤¾ä¸‹çš„ docker-compose.yml æª”å»ºç«‹ç›¸å°æ‡‰çš„ containerï¼š docker compose up -d\næŸ¥çœ‹ç›®å‰æœ‰åœ¨è·‘çš„ container å’Œ è©³ç´°è³‡æ–™ï¼š docker compose ps -a\næŸ¥çœ‹ container ç›®å‰æœ‰ä»€éº¼åœ¨è·‘ï¼š docker container ls\næŸ¥çœ‹ container ID and åŸ·è¡Œä½”ç”¨ CPU or Memory â€¦ï¼š docker stats\nåŸ·è¡Œ containerï¼š docker run \u0026lt;container_ID or Container_name\u0026gt;\nåœæ­¢ containerï¼š docker stop \u0026lt;container_ID or Container_name\u0026gt;\nç§»é™¤ containerï¼š docker rm \u0026lt;container_ID or Container_name\u0026gt;\nåœæ­¢ containerï¼š docker compose stop \u0026lt;container_ID or compose_name\u0026gt;\né–‹å§‹ containerï¼š docker compose run \u0026lt;container_ID or compose_name\u0026gt;\né‡å•Ÿ containerï¼š docker compose restart \u0026lt;container_ID or compose_name\u0026gt;\næŸ¥çœ‹æ‰€æœ‰ docker ä¸Š network ç¨®é¡ï¼š docker network ls\næŸ¥è©¢æ¥ä¸Šæ­¤ network çš„è³‡è¨Šï¼š docker network inspect \u0026lt;network_name\u0026gt;\ndocker è·Ÿ container æºé€šï¼š docker exec -it \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt;\nä»¥ rootæ¬Šé™ è·Ÿ container æºé€šï¼š docker exec -it â€”user=root \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt; or docker exec -it â€”u 0 \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt;\næŠŠdocker file æ–‡ä»¶æ‰“åŒ…æˆä¸€å€‹imagï¼šdocker compose build\nçœ‹container ipï¼š\ndocker inspect -f \u0026#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; \u0026lt;container_id or container_name\u0026gt; æ‰¾è³‡æ–™ä½ç½®ï¼š\n# åˆ—å‡ºæ‰€æœ‰ volumes docker volume ls # æª¢è¦–æŒ‡å®šå®¹å™¨çš„æ‰€æœ‰æ›è¼‰é» (mount points) è³‡è¨Š docker inspect -f \u0026#39;{{.Mounts}}\u0026#39; \u0026lt;Container_ID\u0026gt; åˆªé™¤ docker ç”¢ç‰© ï¼šdocker \u0026lt;*\u0026gt; prune imageï¼š\ndocker image prune docker image prune -a containerï¼š\ndocker container prune volumesï¼š\ndocker volume prune networkï¼š\ndocker network prune everythingï¼š\ndocker system prune WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all dangling images - all build cache docker system prune --volumes WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all volumes not used by at least one container - all dangling images - all build cache Reference # ã€ŠDocker â€”â€” å¾å…¥é–€åˆ°å¯¦è¸Â­ã€‹æ­£é«”ä¸­æ–‡ç‰ˆ (Git book)\nDocker Tips (Git book)\nå°ˆé¡Œç­†è¨˜: VM èˆ‡ Docker (Hackmd) by.@wei06097\nPrune unused Docker objects | Docker Docs\n","date":"2023å¹´11æœˆ19æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/docker-vm-df/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡è¬›è¿° Docker èˆ‡ VM çš„ä¸åŒ èˆ‡ Docker æŒ‡ä»¤\u003c/p\u003e","title":"Docker èˆ‡ VM çš„ä¸åŒ èˆ‡ Docker æŒ‡ä»¤","type":"posts"},{"content":"","date":"2023å¹´06æœˆ17æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/ci/cd/","section":"Tags","summary":"","title":"CI/CD","type":"tags"},{"content":"","date":"2023å¹´06æœˆ17æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/gitlab/","section":"Tags","summary":"","title":"Gitlab","type":"tags"},{"content":"æœ¬æ–‡è¬›è¿° Gitlab Runner çš„å„ç¨®é¡åˆ¥èˆ‡å»ºç«‹ä½¿ç”¨æ–¹æ³•!!\nGitLab CI/CD çš„ Runner æ˜¯è—‰ç”±å¦ä¸€å°é›»è…¦å»åŸ·è¡Œ CI/CD å‹•ä½œå®Œå¾Œå†å›å‚³çµ¦ GitLab è³‡è¨Š è‡ªæ¶ Gitlab è¦ä½¿ç”¨åˆ° Gitlab CI/CD åŠŸèƒ½éœ€å®‰è£ Git-runner åˆ°ä¸€å° Server or Container ä¸‹å»åšä½¿ç”¨ Install GitLab Runner | GitLab Gitlab Runner æœ‰ä¸‰ç¨®ä¸åŒçš„æ¬Šé™ :\nShared runnersï¼šå¯ç”¨æ–¼ GitLab å¯¦ä¾‹ä¸­çš„æ‰€æœ‰çµ„å’Œé …ç›®ã€‚ Group runnersï¼šå¯ç”¨æ–¼å°çµ„ä¸­çš„æ‰€æœ‰é …ç›®å’Œå­å°çµ„ã€‚ Specific runnersï¼šèˆ‡ç‰¹å®šçš„é …ç›®ç›¸é—œè¯ã€‚é€šå¸¸ï¼Œç‰¹å®šçš„é‹è¡Œå™¨ä¸€æ¬¡ç”¨æ–¼ä¸€å€‹é …ç›®ã€‚ ç•¶ä½ æ²’æœ‰ç®¡ç† runner çš„æ¬Šé™æ™‚ï¼Œå¯ä»¥ç”¨é€™å€‹ä¾†å»ºç«‹å±¬æ–¼è‡ªå·±çš„ gitlab runner Shared runners (é©ç”¨ç¯„åœ GitLab ä¸Šå…¨éƒ¨çš„ Groups èˆ‡ Projects ) å› ç‚ºæ˜¯å…¨åŸŸ Runner æ‰€ä»¥éœ€è¦ admin å¸³æˆ¶ä¾†å‰µå»º Runner Admin Area -\u0026gt; CI/CD -\u0026gt; Runner -\u0026gt; Register an instance runner -\u0026gt; Show runner installation and registration instuctions åˆ°ä½ å®‰è£ GitLab runner çš„åœ°æ–¹ç…§è‘— Command to register runner åŸ·è¡Œ \\\n# Windows åŸ·è¡Œ .\\gitlab-runner.exe register --url \u0026lt;GitLab_Url\u0026gt; --registration-token \u0026lt;admin_registration_token\u0026gt; æœ‰çœ‹åˆ°ä»¥ä¸‹ä»£è¡¨æˆåŠŸ ç¾åœ¨ä½ å‰µæ–°çš„å°ˆæ¡ˆéƒ½å¯ä»¥çœ‹åˆ°é€™å€‹ Runner Group runners (é€™é‚Šå»ºç«‹çš„æ˜¯ Group ä¸‹æ‰€æœ‰çš„ Projects çš†å¯ä½¿ç”¨é€™å€‹ runner) Select your group -\u0026gt; CI/CD -\u0026gt; Runners -\u0026gt; Register an instance runner -\u0026gt; Show runner installation and registration instuctions åˆ°ä½ å®‰è£ GitLab runner çš„åœ°æ–¹ç…§è‘— Command to register runner åŸ·è¡Œ \\\n# Windows åŸ·è¡Œ .\\gitlab-runner.exe register --url \u0026lt;GitLab_Url\u0026gt; --registration-token \u0026lt;admin_registration_token\u0026gt; æœ‰çœ‹åˆ°ä»¥ä¸‹ä»£è¡¨æˆåŠŸ ç¾åœ¨ä½ å‰µæ–°çš„å°ˆæ¡ˆéƒ½å¯ä»¥çœ‹åˆ°é€™å€‹ Runner Specific runners (å°ˆé–€çµ¦æŸå€‹ Project å»åšä½¿ç”¨) å…ˆåˆ° project ä¸‹ CI/CD -\u0026gt; Jobs -\u0026gt; Creata CI/CD configuration file ä¹‹å¾Œä½ å°±èƒ½åœ¨ä½ çš„ Project ä¸‹çœ‹åˆ°å¤šäº†ä¸€å€‹ .gitlab-ci.yml é€™å€‹å°±æ˜¯ç”¨ä¾†è·Ÿ GitLab Runner ä½ é€™å°ˆæ¡ˆä»€éº¼æ™‚å€™æœƒè§¸ç™¼ CI/CD ä¸¦ä¸”è©²åšä»€éº¼å‹•ä½œç­‰ç­‰\u0026hellip; åœ¨ Server ä¸­å®‰è£å®Œ GitLab ä¹‹å¾Œåˆ° Project -\u0026gt; settings -\u0026gt; CI/CD -\u0026gt; Runners è·Ÿè‘—æŒ‡ä»¤ä¸‹å°±å¯ä»¥é€£çµèµ· Gitlab Runner è·Ÿ GitLab å…©è€…äº† é€£æ¥å¥½ä¹‹å¾Œå°±èƒ½çœ‹åˆ°ä¸‹é¢æœƒæœ‰å¤šä¸€å€‹ Assigned project runners é€™æ¨£å°±ä»£è¡¨æœ‰é€£çµæˆåŠŸäº† register é€£æ¥èªªæ˜ : # Enter the GitLab instance URL ( for example, https://gitlab.com/ )ï¼šè¼¸å…¥ GitLab-Url\nEnter the registration tokenï¼šè¼¸å…¥ admin-registration-token\nEnter tags for the runner (comma-separated)ï¼šä½  CI/CD æ˜¯å“ªå€‹ Tag æ‰èƒ½ä½¿ç”¨å®ƒ\nEnter optional maintenance note for the runnerï¼šrunner èªªæ˜\nEnter an executor: virtualbox, docker-autoscaler, instance, kubernetes, custom, docker-windows, shell, ssh, docker, parallels, docker+machineï¼šè¼¸å…¥ä½ è¦ä½¿ç”¨çš„é¡å‹\né‡åˆ°å•é¡Œ: # ç„¡æ³•åŸ·è¡Œæ²’æœ‰ Tag çš„ CI/CD å…ˆé€²åˆ° Runner è¨­å®š Run untagged jobs æ‰“å‹¾ Runner æ¶åœ¨ Windows ç„¡æ³•é †åˆ©åŸ·è¡Œ Runner éœ€ä¿®æ”¹ GitLab-Runner è³‡å¤¾ä¸‹çš„ config.toml æª” \u0026ldquo;pwsh\u0026rdquo; -\u0026gt; \u0026ldquo;powershell\u0026rdquo; Reference # Day04 - GitLab CI è¨­è¨ˆå‡ºè‡ªå·±çš„å·¥ä½œæµç¨‹ - æµæ°´ç·šåˆ†æå»ºç«‹ .gitlab-ci.yml æ¦‚è¿°\nè‡ªæ¶GitLab - ç‚ºGitLabæ·»åŠ Runner\nGitlab CI/CD ä»‹ç´¹èˆ‡ Runner çš„æ¶è¨­\ngitlab runner çš„ä¸‰ç§ç±»å‹ï¼Œåˆ›å»ºä»¥åŠä½¿ç”¨\nDay 28 GitLab Runner - å®‰è£èµ·ä¾†åˆ†é…å·¥ä½œå§ï¼\ngitlab-runner: prepare environment failed to start process pwsh in windows - Stack Overflow\n","date":"2023å¹´06æœˆ17æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/gitlab-runner/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡è¬›è¿° Gitlab Runner çš„å„ç¨®é¡åˆ¥èˆ‡å»ºç«‹ä½¿ç”¨æ–¹æ³•!!\u003c/p\u003e","title":"Gitlab Runner","type":"posts"},{"content":"","date":"2023å¹´05æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/giscus/","section":"Tags","summary":"","title":"Giscus","type":"tags"},{"content":"","date":"2023å¹´05æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/hugo/","section":"Categories","summary":"","title":"Hugo","type":"categories"},{"content":"æœ¬ç¯‡æ–‡ç« æ˜¯è‡ªå·±è¨˜éŒ„ä¸‹ä¾†å¦‚ä½•è‡ªå·±ä¿®æ”¹ hugo-tranquilpeak-theme æ·»åŠ è‡ªå·±éœ€è¦çš„ Giscus ç•™è¨€æ¿ï¼\nç•¶åˆç¶²ç«™å»ºå¥½ç•™è¨€æ¿å¾—éƒ¨åˆ†æˆ‘è€ƒæ…®äº†å¾ˆä¹…è¦ç”¨å“ªå€‹ï¼Œå¾ˆå¤šäººèªª Disqus æœƒè„«æ…¢ç¶²ç«™é€Ÿåº¦ï¼Œå¾Œä¾†å°±çœ‹åˆ° Gitalk å’Œ Utterancesï¼Œä¸éæŸ¥äº†è€åŠå¤©çªç„¶çœ‹åˆ°ä¸€å€‹å¦æˆ‘å¿ƒå‹•çš„ç•™è¨€æ¿å¯ä»¥ç”¨ emoji åæ‡‰åœ¨ç•™è¨€æ¿ä¸Šï¼Œè¦ºå¾—è¶…é…·è¶…æœ‰è¶£è€Œä¸”é‚„æ˜¯æ¥åœ¨ Github ä¸Šå°±ç›´æ¥é¸ç”¨é€™å€‹äº†XD\nå»ºç«‹å€‹äººç¶²ç«™ç•™è¨€çš„å„²å­˜åº« ä¸¦ å•Ÿç”¨giscus # å…ˆåœ¨ Github ä¸Šæ–°å»ºä¸€å€‹ repositoryï¼Œåå­—å–ä½ æƒ³è¦çš„ï¼Œä¸¦å°‡å„²å­˜åº«è¨­å®šç‚º Public å¦å‰‡è¨ªå®¢å°‡ç„¡æ³•æŸ¥çœ‹ discussionã€‚ å®‰è£ giscus æ‡‰ç”¨ç¨‹å¼ï¼Œå¦å‰‡è¨ªå®¢å°‡ç„¡æ³•ç•™è¨€æˆ–å›æ‡‰ã€‚ æ¥ä¸‹ä¾†æœƒçœ‹åˆ°é¸æ“‡ä½ æ˜¯è¦çµ¦ giscus æ¬Šé™æ˜¯ å…¨éƒ¨çš„å°ˆæ¡ˆ é‚„æ˜¯ é¸æ“‡çš„å°ˆæ¡ˆï¼Œæˆ‘è‡ªå·±æ˜¯é¸æ“‡è‡ªå·±å‰›å‰›å»ºçš„é‚£å€‹æ–°çš„ repositoryã€‚\nå¦‚æœé¸éŒ¯å¯ä»¥åˆ° é ­åƒ -\u0026gt; Integrations -\u0026gt; Applications -\u0026gt; giscus -\u0026gt; configure å»èª¿æ•´ åˆ°å‰›å‰›æ–°å»ºçš„ repository ä¸‹çš„ Setting -\u0026gt; Features å‹¾é¸ Discussions å•Ÿç”¨å®ƒã€‚\nä¹‹å¾Œåˆ° giscus.app è¼¸å…¥ä¸¦å‹¾é¸ä¸€äº›è³‡è¨Šï¼Œå‹¾é¸å®Œè¼¸å…¥å®Œä¹‹å¾Œå°±å¯ä»¥åœ¨ä¸‹é¢å•Ÿç”¨ giscuséƒ¨åˆ†çœ‹åˆ°å¯ä»¥åµŒå…¥ç•™è¨€æ¿çš„code ä¸‹é¢çš„å¯ä»¥ä¸ç”¨ç…§è‘—æˆ‘çš„å‹¾é¸ï¼Œå¯ä»¥ä¾ç…§ä½ çš„éœ€æ±‚èˆ‡å–œå¥½å»åšé¸æ“‡ ä¿®æ”¹ Hugo theme # é€™é‚Šè¦å…ˆèªªä¸€ä¸‹æ¯å€‹ Hugo theme è£¡é¢çš„config.tomalè·Ÿä¸€äº›æ“ºæ”¾è³‡æ–™çš„ä½ç½®æˆ–æ–¹æ³•æœƒæœ‰äº›è¨±ä¸ä¸€æ¨£\nhugo-tranquilpeak-theme çš„æ”¹æ³•ï¼š\nä¹‹å¾Œåˆ° hugo web çš„è³‡æ–™å¤¾ä¸‹æ‰¾åˆ° config.tomal æ·»åŠ ä¸‹é¢çš„ Code [params.comment.giscus] enable = true ä¹‹å¾Œåˆ° layouts/partials/post æ‰¾åˆ° comment.htmlï¼Œåˆ°æœ€ä¸‹é¢{{END}}ä¸Šé¢æ·»åŠ ä»¥ä¸‹çš„Code {{ else if .Site.Params.comment.giscus.enable }} å‰›å‰›åœ¨ giscus.app å•Ÿç”¨ giscus çš„ code è²¼éä¾† nunocoracao/blowfish çš„æ”¹æ³•ï¼š\nåœ¨ layouts/partials ä¸‹ï¼Œå»ºä¸€ä»½æ–‡ä»¶ comments.html\nè²¼ä¸Šå‰›å‰›åœ¨ giscus.app å•Ÿç”¨ giscus çš„ code\nå°±å®Œæˆæ‹‰ï¼ç¾åœ¨æ‹‰åˆ°ä½ çš„å€‹äººç¶²é ä¸‹å› è©²å°±æœƒæœ‰é€™å€‹æ¨£å­çš„ç•™è¨€æ¿äº† Reference # å®‰è£Giscusä½œç‚ºHugoç¶²ç«™çš„ç•™è¨€æ¿ï¼Œæ”¯æ´è½‰æ›Gitalk/Utterancesçš„ç•™è¨€ Giscuså®˜æ–¹å”åŠ©å®‰è£ç¶²é \n","date":"2023å¹´05æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/hugo-giscus/","section":"Posts","summary":"\u003cp\u003eæœ¬ç¯‡æ–‡ç« æ˜¯è‡ªå·±è¨˜éŒ„ä¸‹ä¾†å¦‚ä½•è‡ªå·±ä¿®æ”¹ hugo-tranquilpeak-theme æ·»åŠ è‡ªå·±éœ€è¦çš„ Giscus ç•™è¨€æ¿ï¼\u003c/p\u003e","title":"Hugo åŠ è£ Giscus ç•™è¨€æ¿","type":"posts"},{"content":"","date":"2023å¹´05æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/jenkins/","section":"Tags","summary":"","title":"Jenkins","type":"tags"},{"content":"æœ¬æ–‡è¬›è¿°å¦‚ä½•ä½¿ç”¨ Docker ç°¡å–®æ­å»º Jenkins æœå‹™ï¼Œä¸¦ç´€éŒ„éç¨‹ï¼\næˆ‘å€‘çš„ç’°å¢ƒæ˜¯ä½¿ç”¨ Docker ä¾†æ­å»ºï¼Œä½¿ç”¨ä¸‹é¢å‘½ä»¤ä¾†ä¸‹è¼‰ image ä¸¦è·‘èµ·ä¾†æœå‹™ï¼\nDocker :\ndocker run --name jenkins -d -p 8080:8080 -p 50000:50000 -v ${HOME}/docker/jenkins:/var/jenkins_home jenkins/jenkins æœå‹™å•Ÿå‹•å¥½ä¹‹å¾Œæˆ‘å€‘éœ€è¦äº†è§£ä¸€ä¸‹ Docker ç›¸é—œæ“ä½œä¸ç„¶ç­‰ç­‰æœƒå¡é—œ\ndocker æ“ä½œ command : æŸ¥çœ‹ç›®å‰æœ‰åœ¨å•Ÿå‹•çš„ container. =\u0026gt; docker ps æŸ¥çœ‹å…¨éƒ¨ container. =\u0026gt; docker ps -a é€²container bash =\u0026gt; docker exec -it \u0026lt;container_id or name\u0026gt; /bin/bash é€²container rootèº«åˆ†é€² bash =\u0026gt; docker exec -u 0 -it \u0026lt;container_id or name\u0026gt; /bin/bash æœå‹™å•Ÿå‹•å¥½ä¹‹å¾Œæˆ‘å€‘é–‹å•Ÿç¶²é è¼¸å…¥ http://localhost:8080 å°±èƒ½çœ‹åˆ° Jenkins äº†ï¼ å…ˆåˆå§‹åŒ–æˆ‘å€‘çš„å¯†ç¢¼ åˆ©ç”¨ä¸Šé¢å‰›å‰›èªªçš„ command å°±èƒ½é€²åˆ°container åº•ä¸‹ä¹‹å¾Œè¼¸å…¥ä¸‹é¢çš„ command å°±å¯ä»¥çœ‹åˆ°åˆå§‹åŒ–å¯†ç¢¼äº†\ncat /var/jenkins_home/secrets/initialAdminPassword ä¹‹å¾Œæˆ‘å€‘å°±èƒ½å®‰è£æƒ³å®‰è£çš„ pluging , ä¸¦è¨­ç½®æˆ‘å€‘çš„å¸³è™Ÿå¯†ç¢¼\nå¦‚æœå¾Œä¾†å¿˜è¨˜å¯†ç¢¼QQ # åœ¨ä½¿ç”¨ jenkins çš„æ™‚å€™ä¸å°å¿ƒæŠŠ admin å¯†ç¢¼å¿˜è¨˜äº†ï¼Œä¸‹é¢ä¾†ä¿®æ”¹æ‰¾å› admin å¯†ç¢¼ Jenkins å°ˆç”¨çš„ user è³‡æ–™å­˜æ”¾åœ¨ JENKINS_HOME/users ç›®éŒ„ã€‚æ¯å€‹userè³‡æ–™åˆ†åˆ¥æ”¾åœ¨ users/xxx(å„ç¨®ç”¨æˆ¶å) ï¼Œå¯ä»¥ç”¨ find å‘½ä»¤æŸ¥æ‰¾å°æ‡‰ç”¨æˆ¶çš„è·¯å¾‘ï¼š\n# find / -name config.xml /var/jenkins_home/jobs/peter_Test/config.xml /var/jenkins_home/config.xml /var/jenkins_home/users/admin_17608091780692632075/config.xml /var/jenkins_home/users/ziyu_13869244322503421338/config.xml /var/jenkins_home/users/frank_5101403968758794797/config.xml /var/jenkins_home/users/alan_10846704603041450940/config.xml /var/jenkins_home/users/peter_17697102942534321614/config.xml æ‰“é–‹å¿˜è¨˜å¯†ç¢¼çš„ç”¨æˆ¶æ–‡ä»¶å¤¾ï¼Œè£é¢æœ‰ä¸€å€‹æ–‡ä»¶config.xmlï¼Œåœ¨è£é¢æ‰¾åˆ° ä½ç½® æŠŠ ä½ç½®çš„å…§å®¹æ›æˆ #jbcrypt:$2a$10$DdaWzN64JgUtLdvxWIflcuQu2fgrrMSAMabF5TSrGK5nXitqK9ZMS å„²å­˜ï¼Œé‡æ–°å•“å‹• Jenkins containerï¼Œç„¶å¾Œè¼¸å…¥ç”¨æˆ¶åï¼Œå¯†ç¢¼ï¼š111111 ç„¶å¾Œå°±OKäº†^^\nTroubleshootingï¼š å¦‚æœæœ‰é‡åˆ°åœ¨ Jenkins æƒ³æŸ¥ç”¨ç¶²é æŸ¥çœ‹æ–‡ä»¶ä½†æ²’è¾¦æ³•çœ‹çš„æœ‹å‹å¯ä»¥ç”¨ä¸‹é¢æ–¹æ³•è§£æ±ºä½†åªæ˜¯æš«æ™‚çš„æ¯æ¬¡ Jenkins é‡å•Ÿéƒ½è¦é‡åšä¸€éã€‚å¦‚æœæƒ³æ°¸ä¹…è§£æ±ºå¯ä»¥çœ‹ä¸‹é¢æ–‡ç« å…§æœ‰è§£æ±ºè¾¦æ³• Jenkinsé¦–é  =\u0026gt; Manage Jenkins =\u0026gt; ScriptConsole è¼¸å…¥\nSystem.setProperty(\u0026#34;hudson.model.DirectoryBrowserSupport.CSP\u0026#34;,\u0026#34;sandbox allow-scripts; default-src \u0026#39;none\u0026#39;; img-src \u0026#39;self\u0026#39; data: ; style-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39; data: ; script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39; \u0026#39;unsafe-eval\u0026#39; ;\u0026#34;) è¦æŒ‰ 2~3æ¬¡ Run æ‰æœƒæœ‰åæ‡‰\nReference # è½¯ä»¶æµ‹è¯•|Docker ä¸Šæ­å»ºæŒç»­é›†æˆå¹³å° Jenkins - è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘ (tencent.com)\nJenkinså¿˜è®°å¯†ç è§£å†³æ–¹æ³• windows/Linux - ç°¡æ›¸ (jianshu.com)\njenkinsåˆå§‹å¯†ç¢¼å¿˜è¨˜äº†+ä¿®æ”¹å¯†ç¢¼ - å°éƒ¨è½ (twblogs.net)\nTroubleshooting # Configuring Content Security Policy - Jenkins\nJenkins error - Blocked script execution in . because the document\u0026rsquo;s frame is sandboxed and the \u0026lsquo;allow-scripts\u0026rsquo; permission is not set\nWhere is jenkins.xml in jenkins docker container\n","date":"2023å¹´05æœˆ12æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/jenkins-build/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡è¬›è¿°å¦‚ä½•ä½¿ç”¨ Docker ç°¡å–®æ­å»º Jenkins æœå‹™ï¼Œä¸¦ç´€éŒ„éç¨‹ï¼\u003c/p\u003e","title":"Jenkins ç’°å¢ƒæ­å»º","type":"posts"},{"content":"","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/fly.io/","section":"Tags","summary":"","title":"Fly.io","type":"tags"},{"content":"","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/line-notify/","section":"Tags","summary":"","title":"Line Notify","type":"tags"},{"content":"æœ¬ç¯‡æ–‡ç« æ˜¯å› ç‚º Heroku çš„å…è²»åˆ¶åº¦çµæŸï¼Œåªå¥½æŠŠ Service æ¬é·åˆ° Fly.io çš„æ•…äº‹ã€‚\nLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ åŸæœ¬æƒ³èªª Line Notify ç³»åˆ—å¯ä»¥çµæŸäº†ï¼Œçµæœæ²’æƒ³åˆ° Heroku ç«Ÿç„¶èªª 2022/11/28 è¦çµæŸå…è²»æ–¹æ¡ˆ OMGï¼æ‰€ä»¥åªå¥½æ‰¾äº†ä¸€ä¸‹å…¶ä»–å¯ä»¥æ¬å®¶çš„åœ°æ–¹æ‰¾ä¾†æ‰¾å»ç™¼ç¾ Fly.io å¥½åƒæ»¿ä¸éŒ¯çš„ï¼Ÿç”¨èµ·ä¾†è·Ÿ Heroku æ»¿åƒçš„ã€‚ å…¶å¯¦æœ‰å¾ˆå¤šå¯ä»¥æ¬çš„åœ°æ–¹ Ex: Elastic Beanstalkã€Netlifyã€Google App Engineã€Renderã€Railwayã€Fly.io \u0026hellip; æœ¬æ¬¡æ¬å®¶åœ°æ–¹ï¼šhttps://fly.io/ é€²å»å°±å…ˆå‰µå»ºå¸³è™Ÿç„¶å¾Œç¶å€‹ä¿¡ç”¨å¡ï¼Œæˆ‘çœ‹ä¸€äº›æ–‡ç« ä¹‹å‰å¥½åƒä¸ç”¨ç¶ä¿¡ç”¨å¡ä¸çŸ¥é“æ˜¯ä¸æ˜¯ç¾åœ¨å› ç‚ºå¤ªå¤šå…è²»ä»”æ‰€ä»¥è¦ç¶äº†ï¼Ÿ ä»–ç¾åœ¨çŸ¥é“å¾ˆå¤šäººè¦å¾ Heroku è½‰å‡ºä¾†æ‰€ä»¥æœ‰å‡ºé€™ Turbocharge Your Heroku App with Fly æˆ‘çœ‹æ–‡ä»¶å› è©²æ˜¯ï¼ŒæŒ‰ä¸€æŒ‰å°±èƒ½æŠŠ Heroku ä¸Šçš„è³‡æ–™è½‰ç§»åˆ° Fly.io ä¸Šå»é‹è¡Œä¹‹å¾Œä½ åªè¦åœ¨ Heroku é‚£é‚Šä¿®æ”¹é€™é‚Šå¥½åƒæœƒè‡ªå‹•åŒæ­¥éä¾†ï¼Ÿ å› ç‚ºæˆ‘è¦ºå¾—ä¹‹å¾Œé‚„è¦å¾ Heroku é‚£é‚Šä¸Šå‚³å¾ˆéº»ç…©æˆ‘å°±åœ¨ Fly.io å‰µä¸€å€‹ä¸€æ¨£çš„å°ˆæ¡ˆå°±å¥½äº†ï¼ æˆ‘å€‘è¦ç”¨ Fly.io è¦å…ˆè£ä»–çš„ Flyctl å»è®“æˆ‘å€‘å¯ä»¥éƒ¨ç½²å°ˆæ¡ˆï¼Œæˆ‘å€‘å¯ä»¥é€éå®˜æ–¹æ–‡ç« å»å®‰è£\nå…ˆç™»å…¥Fly.io =\u0026gt; flyctl auth login\nå…ˆå‰µä¸€å€‹è³‡æ–™å¤¾ä¸¦æŠŠæˆ‘å€‘è³‡æ–™æ”¾é€²å»ä¸¦åœ¨æ­¤è³‡æ–™å¤¾ä¸‹åŸ·è¡Œ Command æˆ‘å€‘å¯ä»¥çœ‹åˆ° fly.toml æ˜¯æˆ‘å€‘æ²’æœ‰çš„å…¶ä»–éƒ½æ˜¯æˆ‘å€‘åŸæœ¬å°±æœ‰çš„ï¼Œæ²’é—œè¥¿å› ç‚ºç­‰ç­‰å‰µå»ºå°ˆæ¡ˆæ™‚ flyctl æœƒå¹«ä½ è£œä¸Šã€‚\nä½¿ç”¨æŒ‡ä»¤å‰µå»ºå°ˆæ¡ˆå¾Œä¸¦åˆæ¬¡ä½ˆç½²\nå‰µå»ºå°ˆæ¡ˆæŒ‡ä»¤ï¼šflyctl launch éƒ¨ç½²æŒ‡ä»¤ï¼šfly deploy éç¨‹çœ‹å¾—æ‡‚è‹±æ–‡å› è©²éƒ½ä¸é›£ç†è§£ä¸æ‡‚å°±ç…§æˆ‘åœ–ç‰‡åšã„…ã€‚ ? Would you like to set up a Postgresql database now? æ¯”è¼ƒè¦æ³¨æ„çš„æ˜¯ä½ å¦‚æœéœ€è¦ç”¨åˆ°ä»–çš„ database æœå‹™é€™é‚Šè«‹æ‰“ yes å°ˆæ¡ˆå»ºç«‹å®Œæˆ‘å€‘å°±æœ‰fly.tomlæª”äº†è£¡é¢æœ‰ç´€éŒ„ä½ çš„ä¸€äº›å°ˆæ¡ˆè¨­ç½®è·Ÿåç¨±\næ¥ä¸‹ä¾†åŸ·è¡Œ fly deploy åŸºæœ¬ä¸Šæ¥ä¸‹ä¾†ä»–å°±æœƒè‡ªå‹•éƒ¨å±¬äº† éƒ¨å±¬å®Œæˆ‘å€‘å°±å¯ä»¥åœ¨ Dashboard ä¸‹çœ‹åˆ°æˆ‘å€‘çš„å°ˆæ¡ˆæ˜¯ä¸æ˜¯å¾ˆç°¡å–®å•Šï¼ ä½ å› è©²éƒ¨ç½²å®Œæœƒèªªä½ çš„ Code è£¡é¢æœ‰ä¸€äº›è®Šæ•¸ä»–æ²’è¾¦æ³• get åˆ°ï¼Œä½†æˆ‘å€‘é‚„æ²’è¨­å®šå®Œé‚„è¨˜å¾—ä¹‹å‰ Heroku æœ‰è¨­å®šç’°å¢ƒè®Šæ•¸å—ï¼Ÿ æˆ‘å€‘ Fly.io ä¹Ÿèƒ½è¨­å®š æŒ‡ä»¤ï¼š\nfly secrets set \u0026lt;setting_name\u0026gt; = \u0026lt;your_input\u0026gt; æ¯æ¬¡è¨­å®šå®Œä»–éƒ½æœƒé‡æ–°éƒ¨å±¬æ‰€ä»¥éƒ½æœƒè·‘å¾ˆé•·ä¸€æ¢ï¼Œè¨­å®šå®Œå¾ŒåŸºæœ¬ä¸Šå°±èƒ½åƒä¹‹å‰ä¸€æ¨£ä½¿ç”¨ä½†è¨˜å¾— Line bot è·Ÿ Line Notify çš„ callback ç¶²å€è¦å»ä¿®æ”¹å–”ï¼ï¼\næœ€å¾Œæˆ‘è¦æŠ±æ€¨ä¸€ä¸‹å¥½åƒæ˜¯å¾ˆå¤šäººæ¬åˆ°é€™å¹³å°å®ƒ deploy å¸¸å¸¸æœƒæ²’è¾¦æ³•æ­£å¸¸ deploy ä¸Šå»ï¼Œé‚„è¦çœ‹é‹æ°£ï¼Œæˆ‘ç¬¬ä¸€å¤©ç”¨åŸºæœ¬ä¸Šå®Œå…¨ç„¡æ³•å®Œæ•´çš„éƒ¨ç½²ä¸Šå»æˆ‘æ˜¯åˆ°éš”å¤©æ—©ä¸Šå†è©¦ä¸€æ¬¡æ‰è¡Œçš„ã€‚é‚„åœ¨æƒ³æ˜¯å¦è¦æ›åˆ°åˆ¥çš„å¹³å°æ˜¯é‚„æ˜¯åœ¨ç­‰ç­‰çœ‹é€™å¹³å°èƒ½ä¸èƒ½è§£æ±ºï¼Œä¸éè‡³å°‘é€™å¹³å°çš„è«–å£‡æ˜¯å¾ˆå¤šäººçš„è€Œä¸”å›çš„ä¹Ÿå¾ˆå¿«æœ‰èˆˆè¶£å¯ä»¥çœ‹çœ‹æœ‰æ²’æœ‰äººé‡åˆ°ä¸€æ¨£çš„å•é¡Œï¼ æœ‰å•é¡Œæˆ–æœ‰ä¸æ‡‚çš„å¯ä»¥ç§è¨Šæˆ–ç•™è¨€çµ¦æˆ‘ï¼Œæˆ‘æœ‰ç©ºå°±æœƒçœ‹å”·ï¼ï¼\nUpdateï¼šLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ # ç›®å‰æˆ‘æ˜¯å…ˆæŠŠé€šçŸ¥æœå‹™ä¸²åœ¨ Discord ä¸Šï¼Œçœ‹äº†ä¸€ä¸‹æ¯”è¼ƒæœ‰æ©Ÿæœƒå–ä»£çš„å› è©²æ˜¯ä½¿ç”¨ Telegram Bot + Google App Script å–ä»£ã€‚ æœ‰èˆˆè¶£å¯ä»¥çœ‹é€™ç³»åˆ—æ–‡ç« ï¼š åˆ©ç”¨Google App Script å¯¦ä½œTelegram Bot ç³»åˆ— - iTé‚¦å¹«å¿™\nReference # å¹³å°åƒè€ƒï¼š\nTop 10 Alternatives to Heroku in 2022\n5 å€‹æ›¿ä»£ Heroku çš„å¹³å°å…è²»æ¸¬è©¦åŸ·è¡Œ\néƒ¨ç½²åƒè€ƒï¼š\nHeroku æ›¿ä»£æ–¹æ¡ˆ - Fly.io å¹³å°ä¹‹ ASP.NET Core éƒ¨ç½²ç­†è¨˜\nHeroku çš„æ›¿ä»£æ–¹æ¡ˆï¼Ÿ Fly.io å¹³å° â€” Python Flask å¯¦éš›ç¯„ä¾‹\n","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/line-bot-ex/","section":"Posts","summary":"\u003cp\u003eæœ¬ç¯‡æ–‡ç« æ˜¯å› ç‚º Heroku çš„å…è²»åˆ¶åº¦çµæŸï¼Œåªå¥½æŠŠ Service æ¬é·åˆ° Fly.io çš„æ•…äº‹ã€‚\u003c/p\u003e","title":"Line Notify æ¬å®¶è¨ˆç•«","type":"posts"},{"content":"","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/categories/line_bot/","section":"Categories","summary":"","title":"Line_Bot","type":"categories"},{"content":"","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/tags/heroku/","section":"Tags","summary":"","title":"Heroku","type":"tags"},{"content":"æœ¬ç¯‡æ˜¯å‰é¢ä¸‰ç¯‡æ–‡ç« çš„ç¶œåˆæ‡¶äººåŒ…è·Ÿç¸½çµä¸€ä¸‹ç›®å‰çš„æ¶æ§‹èˆ‡ç¨‹å¼ï¼ï¼\nLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ å‰æƒ…æè¦ï¼š # æœ¬ç¯‡æ˜¯é€™ä¸‰ç¯‡æ–‡ç« çš„ç¶œåˆæ‡¶äººåŒ…ï¼ï¼å¦‚æœä¸­é–“æœ‰ä¸å¤ªæ‡‚å¯ä»¥å›å»ç¿»ç¿»çœ‹é€™ä¸‰ç¯‡ï½ è®“æˆ‘å€‘ç”¨ Python é–‹ç™¼ä¸€å€‹ Line Bot Line Bot ä¹‹åˆ©ç”¨ Line Notify çªç ´é™åˆ¶å§ï¼ Line Notify å»ºç«‹è³‡æ–™åº«ä¸¦æä¾›ä¸ä¼‘æ¯çš„æœå‹™\næˆ‘å€‘è¦æœ€å¾Œåšå‡ºä¾†çš„æ¶æ§‹æœƒæ˜¯ä¸‹åœ–é€™æ¨£ï¼Œæœƒæ˜¯ Line_Bot + Line_Notify + Heroku + GoogleSheet æˆ‘å€‘ Line Bot or Line Notify ç­‰ç­‰\u0026hellip;ï¼Œé€™é‚Šå°±å¯ä»¥åƒè€ƒå‰é¢çš„æ–‡ç« å‰µå‡ºä¸€å€‹åŸºæœ¬çš„ Line Bot + Notify ç„¶å¾Œè¨­å®šä¸€ä¸‹ Heroku é€™é‚Šå°±ä¸åœ¨è´…è¿°ã€‚ æˆ‘å€‘é€™é‚Šçš„é‡é»å…ˆæ”¾åœ¨ç†è§£æ•´å€‹ Line Bot ç¨‹å¼ç¢¼ï¼ï¼\næˆ‘å€‘å…ˆå¾ route é€™é‚Šçœ‹\n@app.route(\u0026#34;/callback/notify\u0026#34;, methods=[\u0026#39;GET\u0026#39;]) def callback_notify(): #assert request.headers[\u0026#39;referer\u0026#39;] == \u0026#39;https://notify-bot.line.me/\u0026#39; code = request.args.get(\u0026#39;code\u0026#39;) state = request.args.get(\u0026#39;state\u0026#39;) # Get Access-Token client_id = os.environ[\u0026#39;NOTIFY_CLIENT_ID\u0026#39;] access_token = get_token(code, client_id, client_secret, redirect_uri) google_sheet(access_token) send_message(access_token,text_message=\u0026#34;ä½ å¥½\u0026#34;) #ç™¼è¨Šæ¯ return \u0026#39;æ­å–œå®Œæˆ LINE Notify é€£å‹•ï¼è«‹é—œé–‰æ­¤è¦–çª—ã€‚\u0026#39; Q. æœ‰äº›äººæœƒèªªé€™é‚Šçš„ \u0026ldquo;/callback/notify\u0026rdquo; ç”¨åœ¨å“ªè£¡ï¼Ÿ A. æœƒåœ¨ Notify è£¡çš„è¨­å®šçœ‹åˆ°ï¼ŒWeb å¾Œç«¯æ¥æ”¶åˆ°é€™å€‹ URL çš„ \u0026ldquo;GET\u0026rdquo; ä¹‹å¾Œå»è§¸ç™¼ Q. æˆ‘è©²å¦‚ä½•æ–°å¢åŠŸèƒ½ï¼Ÿ A. å¦‚æœåªæ˜¯è¦æ–°å¢åˆ©ç”¨æ–‡å­—å»äº’å‹•çš„åŠŸèƒ½çš„è©±åªéœ€è¦åœ¨ä¸‹é¢å¢åŠ å°±å¯ä»¥äº†\n@handler.add(MessageEvent, message=TextMessage) # ç›£è½ç•¶æœ‰æ–°è¨Šæ¯æ™‚ def handle_message(event): global Group_id , User_id if event.message.text == \u0026#34;å€‹äººè¨‚é–±\u0026#34; : url = create_auth_link(event) # å›å‚³ url çµ¦å‚³è¨Šæ¯çš„é‚£ å€‹äºº or ç¾¤çµ„ line_bot_api.reply_message(event.reply_token,TextSendMessage(text=url) ) # é€™é‚Šæ˜¯åˆ©ç”¨ event å…§çš„ user_id å»è·Ÿ Line æ‹¿åˆ°ä½¿ç”¨è€…çš„ç•¶å‰ Line ä½¿ç”¨çš„åå­ Ex: Zi-Yu(æ—å­è‚²) User_id = line_bot_api.get_profile(event.source.user_id).display_name Group_id = \u0026#39;\u0026#39; elif event.message.text == \u0026#34;ç¾¤çµ„è¨‚é–±\u0026#34; : url = create_auth_link(event) line_bot_api.reply_message(event.reply_token,TextSendMessage(text=url) ) # å› ç‚º event å…§åªæœƒå›å‚³å€‹äººè¨Šæ¯æ‰€ä»¥ç„¡æ³•æ‰¾åˆ° Group çš„åç¨±,æ‰€ä»¥åªèƒ½æ”¹æ‹¿ Group çš„ id Group_id = (event.source.group_id) # Group_id get! User_id = \u0026#39;\u0026#39; Q. è¨­å®šå®Œå¾Œï¼Œæˆ‘è©²å¦‚ä½•åœ¨åˆ¥çš„ç¨‹å¼åˆ©ç”¨ Line Notify å‚³è¨Šæ¯ï¼Ÿ A. Python çš„è©±å¥—ç”¨é€™å€‹å‡½å¼å°±å¯ä»¥ï¼Œå‚³é€è¨Šæ¯ã€‚å¦‚æœæƒ³è¦ Access Token ä¸å¯«æ­»ï¼Œå°±æ˜¯æ”¶åˆ°äººåå†å» Google Sheet æœå°‹ç›¸å°æ‡‰çš„ Access Token å°±èƒ½æ‘Ÿï¼\n#åˆ©ç”¨notifyç™¼å‡ºè¨Šæ¯ #==============================================================================================# def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() #==============================================================================================# main: send_message(access_token, text_message) Q. Clock + Line Bot åŒæ™‚ä½¿ç”¨å°è‡´æˆ‘çš„ Heroku æ™‚æ•¸çˆ†äº†æ•´éº¼è¾¦ï¼Ÿ A. æˆ‘ä¹Ÿæ˜¯å¾Œä¾†æ‰ç™¼ç¾æœ‰é€™å•é¡Œå› ç‚ºæˆ‘æ˜¯ 30 å¤©éƒ½æ˜¯ 24hr è®“ä»–å»é–‹è‘—ï¼Œå¯æ˜¯æˆ‘çš„å…è²»æ™‚æ•¸åªæœ‰ 1000hr å¯¦åœ¨æ˜¯ä¸å¤ ï¼Œ å¾Œä¾†æˆ‘å°±æƒ³åˆ°è§£æ±ºæ–¹æ³•æŠŠ Clock.py æ‹¿åˆ°ä¸€å°æ°¸é ä¸é—œæ©Ÿçš„é›»è…¦ä¸Šè·‘åšåˆ°ä¸€æ¨£çš„åŠŸèƒ½ã€‚ æ•´éº¼è§£æ±ºå‘¢ï¼Ÿå¾ˆç°¡å–®å°±æ˜¯åˆ©ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼ï¼‹å·¥ä½œæ’ç¨‹å™¨ æˆ‘å€‘å…ˆåœ¨æœ¬åœ°æ‰“ä¸€ä»½ Clock çš„ Pythonç¨‹å¼ç¢¼ï¼š\nfrom apscheduler.schedulers.blocking import BlockingScheduler from linebot import LineBotApi from linebot.models import TextSendMessage import urllib.request sched = BlockingScheduler() #åˆ©ç”¨notifyç™¼å‡ºè¨Šæ¯ def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() #å®šæ™‚å»æ“urlè®“æœå‹™ä¸ä¸­æ–· @sched.scheduled_job(\u0026#39;cron\u0026#39;, day_of_week=\u0026#39;mon-sun\u0026#39;, minute=\u0026#39;*/25\u0026#39;) def scheduled_job(): url = \u0026#34;https://\u0026lt;Your Heroku App Name\u0026gt;.herokuapp.com/\u0026#34; conn = urllib.request.urlopen(url) for key, value in conn.getheaders(): print(key, value) print(\u0026#34;æˆ³ä¸€ä¸‹\u0026#34;) æ¥ä¸‹ä¾†åœ¨æ’ç¨‹å™¨è¨­å®šæ¯å¤©åŸ·è¡Œ ç„¶å¾Œåœ¨å‹•ä½œçš„åœ°æ–¹çœ‹è¦æ˜¯ç›´æ¥åŸ·è¡Œpythonæª”æˆ–æ˜¯ç›´æ¥æŠŠå‘½ä»¤å¯«æˆbatæª”åŸ·è¡Œéƒ½å¯ä»¥æ‘Ÿï¼\næœ€å¾Œé™„ä¸Šå·²ç¶“ç”¨å¥½çš„æ¨¡ç‰ˆGitHubï¼š https://github.com/OKHand-Zy/Line-Bot_Module ä¸‹è¼‰ä¸‹ä¾†å¾ŒæŠŠHerokuè³‡æ–™å¤¾å…§çš„æª”æ¡ˆç§»å‡ºå¤–é¢ä¸€å±¤ç„¶å¾Œä¿®æ”¹æˆè‡ªå·±çš„å…§å®¹ä¸Šå‚³Herokuå°±å¯ä»¥æ‘Ÿï¼\nè£¡é¢æœ‰äº›æª”æ¡ˆè£¡é¢è¦æ›æˆè‡ªå·±çš„ App å æˆ–æ˜¯ é‡‘é‘° è¦æ³¨æ„ä¸€ä¸‹å”·ï¼\né‚„æœ‰ Heroku çš„ ç’°å¢ƒå€¼ ä¹Ÿè¨˜å¾—è¦è¨­å®šï¼\\\nå¤§å®¶ä¸€èµ·ä¾†æ‰“é€ å‡ºå±¬æ–¼è‡ªå·±çš„ Line Botå§ï¼ï¼ æœ‰å•é¡Œæˆ–æœ‰ä¸æ‡‚çš„å¯ä»¥ç§è¨Šæˆ–ç•™è¨€çµ¦æˆ‘ï¼Œæˆ‘æœ‰ç©ºå°±æœƒçœ‹å”·ï¼ï¼\n","date":"2023å¹´02æœˆ04æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/line-bot-end/","section":"Posts","summary":"\u003cp\u003eæœ¬ç¯‡æ˜¯å‰é¢ä¸‰ç¯‡æ–‡ç« çš„ç¶œåˆæ‡¶äººåŒ…è·Ÿç¸½çµä¸€ä¸‹ç›®å‰çš„æ¶æ§‹èˆ‡ç¨‹å¼ï¼ï¼\u003c/p\u003e","title":"Line Bot æ‡¶äººåŒ… - ç¸½çµ","type":"posts"},{"content":"æœ¬æ–‡æ˜¯å¯¦ä½œå¦‚ä½• Heroku æŒçºŒä¸é–“æ®µæœå‹™ èˆ‡ é€£çµ Google Sheet ç•¶ä½œæˆ‘å€‘çš„è³‡æ–™åº«ã€‚\nLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ å‰æƒ…æè¦ï¼š # ç¹¼ä¹‹å‰ è®“æˆ‘å€‘ç”¨ Python é–‹ç™¼ä¸€å€‹ LineBot è·Ÿ Line Bot ä¹‹åˆ©ç”¨ Line Notify çªç ´é™åˆ¶å§ï¼ï¼Œæˆ‘å€‘å·²ç¶“æœ‰äº† Line Bot è·Ÿ Line Notify ä¸¦ä¸²æ¥å¥½äº†ï¼Œé‚£æˆ‘å€‘ä¹‹å¾Œå°±æ˜¯è¦å»ç´€éŒ„é€™äº› Access Token æ˜¯èª°çš„ï¼Œç•¶éœ€è¦å‚³é€è³‡æ–™çš„æ™‚å€™å°±çŸ¥é“è¦å‚³çµ¦èª°äº†ï¼ï¼\nä¸ç¡è¦ºçš„æœå‹™ï¼š # èº«ç‚ºä¸€å€‹æ…£è€é—†ä¸‹çš„ç¤¾ç•œæˆ‘ä¹Ÿæƒ³ç•¶ä¸€ä¸‹æ…£è€é—†çš„æ»‹å‘³ï¼Œæ–¼æ˜¯æˆ‘å€‘çš„æœå‹™æ˜¯ä¸€ç›´é‹ä½œä¹Ÿæ˜¯ç†æ‰€ç•¶ç„¶çš„å§ï¼ï¼ é€™éƒ¨åˆ†æ¯”è¼ƒç°¡å–®åŸç†å¤§æ¦‚å°±æ˜¯å› ç‚º Heroku æ¯ 25 åˆ†é˜å¦‚æœæ²’äººä½¿ç”¨çš„è©±é‚£å€‹ APP å°±æœƒé€²å…¥æš«æ™‚æ€§çš„ä¼‘æ¯ï¼Œæ–¼æ˜¯æˆ‘å€‘åªè¦åœ¨ 24 åˆ†çš„æ™‚å€™å»æˆ³ä¸€ä¸‹è‡ªå·±çš„ Web è®“ä»–ä»¥ç‚ºæœ‰äººå«ä»–å°±å¯ä»¥è®“ä»–ä¸€ç›´å·¥ä½œäº†ã€‚ æˆ‘å€‘å…ˆå®‰è£ä¸€å€‹å¥—ä»¶ APScheduler =\u0026gt; pip install apscheduler ä¹‹å¾Œæˆ‘å€‘å°±å¯ä»¥è£½ä½œæˆ‘å€‘çš„ clock.pyï¼Œç•¶ç„¶ä½ è¦å®šæ™‚çš„å»å‚³é€è¨Šæ¯æˆ–æ˜¯åšä¸€äº›äº‹ä¹Ÿèƒ½æ‰“åœ¨è£¡é¢ã€‚\n# clock.py from apscheduler.schedulers.blocking import BlockingScheduler import urllib.request sched = BlockingScheduler() #å®šæ™‚å»æ“urlè®“æœå‹™ä¸ä¸­æ–· @sched.scheduled_job(\u0026#39;cron\u0026#39;, day_of_week=\u0026#39;mon-sun\u0026#39;, minute=\u0026#39;*/25\u0026#39;) def scheduled_job(): url = \u0026#34;https://ä½ çš„Heroku APPåå­—.herokuapp.com/\u0026#34; conn = urllib.request.urlopen(url) for key, value in conn.getheaders(): print(key, value) print(\u0026#34;æˆ³ä¸€ä¸‹\u0026#34;) sched.start() æˆ‘å€‘æœ‰äº† clock.py ä¹‹å¾Œæˆ‘å€‘ä¹Ÿè¦ä¿®æ”¹ä¸€ä¸‹ requirements.txt and Procfile requirements.txt =\u0026gt; å¤šåŠ  APScheduler == 3.8.1 Procfile =\u0026gt; å¤šåŠ  clock: python clock.py åŠ å¥½ä¹‹å¾Œä¸Šå‚³ Heroku ä¹‹å¾Œè¨˜å¾—å»é–‹å•Ÿ Clock æ‰æœƒå•Ÿç”¨å–”ï¼ï¼ ä¹‹å¾Œå°±èƒ½å»çœ‹ Log æˆ–æ˜¯ app ç‹€æ…‹ è§€å¯Ÿå®ƒæ˜¯å¦ä¸€ç›´æœ‰åœ¨é‹ä½œã€‚\nå»ºç«‹æˆ‘å€‘çš„è³‡æ–™åº« # æˆ‘é æœ¬æ˜¯æƒ³ç”¨ Heroku å…§çš„è³‡æ–™åº«å¯æ˜¯æˆ‘å­¸äº†ä¸€ä¸‹è¦ºçš„å¾ˆé›£ç”¨æ–¼æ˜¯æˆ‘å°±æŠŠç›®å…‰è½‰åˆ° Google Sheet ä¸Šäº†ï¼Œå°æ–¼æˆ‘å€‘åªè¦å„²å­˜ä¸€äº› Access Token è·Ÿä½¿ç”¨è€…åå­—æ˜¯å¤ ç”¨çš„ï¼ï¼(å¦‚æœæƒ³è¦ç”¨Herokuå…§çš„è³‡æ–™åº«å¯ä»¥å»çœ‹éº¥ç”°æ•æ‰‹çš„æ–‡ç« é€£çµåœ¨ä¸‹é¢) æˆ‘å€‘é€™é‚Šå°±è¬›è¦æ•´éº¼åˆ©ç”¨ GoogleSheet ç•¶æˆ‘å€‘çš„è³‡æ–™åº« å…ˆåˆ° Google Cloud Platform å»ºç«‹ä¸€ä»½ Google Sheet å’Œä¸€å€‹ Google Sheet çš„ API èº«ä»½ ç„¶å¾Œå†å»ç”³è«‹ä¸€ä¸‹é‡‘é‘°è®“æˆ‘å€‘å¯ä»¥è·Ÿ Google Sheet å»åšäº’å‹• ç”³è«‹æ†‘è­‰åœ¨ï¼šå´é‚Šæ¬„è£¡çš„ API å’Œæœå‹™ =\u0026gt; æ†‘è­‰ =\u0026gt; æœå‹™å¸³æˆ¶æ—é‚Šçš„ç®¡ç†å¸³æˆ¶ =\u0026gt; å»ºç«‹æœå‹™å¸³æˆ¶ æ†‘è­‰ç”³è«‹å®Œä¹‹å¾Œæœƒçµ¦ä½ ä¸‹è¼‰ä¸€å€‹ jason æª”å°±æ˜¯ä¹‹å¾Œè¦å¼•ç”¨çš„é‡‘é‘°(è«‹ä¿å­˜å¥½æ²’äº†å°±è¦é‡ç”³è«‹ï¼) ä¹‹å¾Œä½ æœƒåœ¨æœå‹™å¸³æˆ¶é‚£é‚Šçœ‹åˆ°é›»å­éƒµä»¶ä¹‹å¾Œæˆ‘å€‘å»å»ºç«‹ä¸€å€‹ GoogleSheet ä¸¦ä¸”åˆ†äº«ç·¨è¼¯æ¬Šé™çµ¦é€™å€‹ Email å®‰è£ç’°å¢ƒæ¸¬è©¦éœ€è¦çš„å¥—ä»¶ pygsheets å¥—ä»¶ =\u0026gt; pip3 install pygsheets è¨˜å¾—ï¼ç¬¬ä¸€ç¯‡æœ‰èªªçš„ Heroku çš„è¨­å®šæª”(requirements.txt)ä¹Ÿè¦åŠ æ‰å…¥å¥—ä»¶æ‰èƒ½åœ¨ Heroku ä¸Šä½¿ç”¨å–” ä¹‹å¾Œæˆ‘å€‘å°±å¯ä»¥é–‹å§‹ä½¿ç”¨ Google Sheet ç•¶æˆ‘å€‘çš„è³‡æ–™åº«å»åšä½¿ç”¨äº† \\\n# è‡ªå·±ç·´ç¿’è·Ÿ Google Sheet äº’å‹•çš„ç¨‹å¼ç¢¼ import pygsheets #çµ¦æ†‘è­‰ gc = pygsheets.authorize(service_file=\u0026#39;ä½ çš„æ†‘è­‰ä½ç½®\u0026#39;) # é–‹å•Ÿgooglesheet # google sheeté€£çµç¯„ä¾‹ = https://docs.google.com/spreadsheets/d/\u0026lt;docID\u0026gt;/edit#gid=\u0026lt;sheetID\u0026gt; sheet = gc.open_by_url( \u0026#39;https://docs.google.com/spreadsheets/d/\u0026lt;docID\u0026gt;/\u0026#39; ) #æ‰¾åˆ°ä¸‹æ–¹\u0026#34;å·¥ä½œè¡¨1\u0026#34;åˆ†é ä¸¦åœ¨è£¡é¢æ“ä½œ wks = sheet.worksheet_by_title(\u0026#34;å·¥ä½œè¡¨1\u0026#34;) #æš´åŠ›ç ´è§£ç›´åˆ—æœå°‹ (ç”¨ä¾†å°‹æ‰¾é€™å€‹äººçš„useridä¸¦æ‹¿å–ç›¸å°æ‡‰çš„accesstokenæˆ‘å€‘å°±èƒ½å‚³é€è¨Šæ¯çµ¦æŒ‡å®šçš„äºº) Count = int( wks.cell( \u0026#39;C1\u0026#39; ).value ) #äººæ•¸ #åœ¨C1è¨­å®šç›®å‰ç¶å®šäººæ•¸ä¸¦æ‹¿ä¾†ç•¶è¨ˆæ•¸å™¨ Userid = \u0026#34;\u0026#34; #å…ˆclear for i in range(1,Count ) : Userid = str(wks.cell( \u0026#39;A\u0026#39;+str(i) ).value) print(Userid) if Userid.value == \u0026#34;101112\u0026#34; : #æ‰¾åˆ°1011112å°±åšä¸‹é¢ print(\u0026#34;ç¬¬\u0026#34;+str(i)+\u0026#34;å€‹\u0026#34;) #é¡¯ç¤ºç¬¬å¹¾å€‹ print( wks.cell( \u0026#39;B\u0026#39;+str(i) ).value ) #é¡¯ç¤ºè£¡é¢å¾—å€¼ print(\u0026#34;ok\u0026#34;) break #æ‹¿åˆ°ä¸¦è·³å‡º #æ–°å¢è³‡æ–™æ–¹å¼ (æ–°å¢ç¶å®šäººè³‡æ–™ä¸¦çµ±è¨ˆäººæ•¸,ä¸¦è®“ä¸‹æ¬¡å¯ä»¥è·‘é€²è¿´åœˆ) wks.update_value(\u0026#39;A6\u0026#39;, \u0026#39;asderrgte231231564gh\u0026#39;) #æ–°å¢è³‡æ–™ wks.update_value(\u0026#39;C1\u0026#39;, Count+1) #äººæ•¸+1 A = wks.cell( \u0026#39;A6\u0026#39; ) print(A.value) #æª¢æŸ¥æ–°è³‡æ–™ Google sheet è©²å¦‚ä½•èˆ‡ Python é‹ä½œè·Ÿä¸Šé¢çš„è¨»å†Šè©³ç´°æˆ‘ä¸€æ¨£æœƒæŠŠåƒè€ƒè³‡æ–™éƒ½æ”¾åœ¨ä¸‹é¢(é‚„ä¸æ‡‚çš„å¯ä»¥çœ‹è£¡é¢æ•™çš„æ¯”è¼ƒè©³ç´°) æˆ‘çŸ¥é“æˆ‘è¬›çš„æœ‰é»ç°¡ç•¥å¦‚æœéƒ½ä¸è¡Œæˆ–æ˜¯é‚„æœ‰ç–‘å•å°±ç•™è¨€å§ï¼å¦‚æœæˆ‘æœƒï¼Œæˆ‘å°±ç›¡é‡å›ç­”ï¼ï¼ \\\nReference # Line Notifyï¼š\nè³´ç”°æ•æ‰‹ iTå¹«å¹«å¿™\nå¡ç±³ç‹— iTå¹«å¹«å¿™\nGoogle Sheetï¼š\n[è³‡æ–™åº«ç­†è¨˜] Python ä¸²æ¥ GoogleSheet æ–°å¢ã€è®€å–ã€æ›´æ–°å’Œåˆªé™¤\nPython è®€å¯« Google Sheets æ•™å­¸\n[Pythonçˆ¬èŸ²æ•™å­¸]è§£æå¦‚ä½•ä¸²æ¥Google Sheetè©¦ç®—è¡¨å¯«å…¥çˆ¬å–çš„è³‡æ–™\n","date":"2023å¹´02æœˆ02æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/line-bot3/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡æ˜¯å¯¦ä½œå¦‚ä½• Heroku æŒçºŒä¸é–“æ®µæœå‹™ èˆ‡ é€£çµ Google Sheet ç•¶ä½œæˆ‘å€‘çš„è³‡æ–™åº«ã€‚\u003c/p\u003e","title":"Line Notify å»ºç«‹è³‡æ–™åº«ä¸¦æä¾›ä¸ä¼‘æ¯çš„æœå‹™","type":"posts"},{"content":"æœ¬æ–‡ä¸»è¦æ˜¯å¯¦ä½œå¦‚ä½•å¾åŸºæœ¬çš„ Line Bot ä¸²æ¥ Line Notifyï¼Œå›å‚³å‡º URL è®“ä½¿ç”¨è€…å»ç¶å®šé”åˆ°å¯ä»¥å»äº’å‹•çš„æ•ˆæœï¼\nLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ å‰æƒ…æè¦ï¼š # ç¹¼ä¹‹å‰ è®“æˆ‘å€‘ç”¨Pythoné–‹ç™¼ä¸€å€‹LineBot é€™ç¯‡æ–‡ï¼Œæˆ‘å€‘å·²ç¶“æœ‰äº†ä¸€å€‹åŸºæœ¬çš„ Line Botï¼Œä½†æ˜¯ Line æœ‰å° Line Bot æœ‰çµ¦å…è²»ä»”å€‘åšä¸€äº›é™åˆ¶(Exï¼šæ¯å€‹æœˆä¸»å‹•ç™¼é€è¨Šæ¯(push_message)åªèƒ½ç™¼é€500å‰‡è¨Šæ¯ï¼Œå›å‚³è¨Šæ¯(reply_message)ä¸å—é™åˆ¶)ï¼Œé‚£æˆ‘å€‘è¦å¦‚ä½•çªç ´ä»–çš„ä¸Šé™å‘¢ï¼Ÿ é‚£å°±æ˜¯åˆ©ç”¨æœ‰å®˜æ–¹èªè­‰çš„ Line Notify å»å¹«æˆ‘å€‘ç™¼é€è¨Šæ¯ï¼Œå› ç‚ºæ˜¯å®˜æ–¹èªè­‰çš„å¸³è™Ÿæ‰€ä»¥å¯ä»¥ç„¡é™ç™¼é€è¨Šæ¯é‡é»æ˜¯é‚„å…è²»å•Šï¼ æ­£é¡Œï¼š # å»ºç«‹å€‹äºº Line Notifyï¼š æˆ‘å€‘è¦å…ˆå» Line Notify å»ç”³è«‹ä¸€å€‹æˆ‘å€‘çš„ Line Notify ï¼ ç™»å…¥ä¹‹å¾Œ =\u0026gt; å³ä¸Šé»ä½ çš„ Account =\u0026gt; ç®¡ç†ç™»å…¥æœå‹™ =\u0026gt; ä¸‹é¢çš„ç™»å…¥æœå‹™ =\u0026gt; å‰µå»ºä½ çš„ Line Notify è£¡é¢æœ‰ä¸€å€‹è¦æ³¨æ„çš„æ˜¯ Callback URL é€™å€‹ï¼Œé€™é‚Šè¦å¡«å…¥ä½ çš„ webhook é€™æ¨£ä¹‹å¾Œä»–æ‰èƒ½è·Ÿæˆ‘å€‘çš„ç¨‹å¼å»åšäº’å‹•ã€‚ Ex: https://ä½ çš„Heroku APPåå­—.herokuapp.com/callback/notify è®“ Line Bot ç™¼é€è¨Šæ¯è®“ä½¿ç”¨è€… è·Ÿ LineNotify ç¶å®š ï¼š # å‰µé€ ç¶å®šçš„URLï¼š æˆ‘å€‘å‰›å‰›æœ‰äº†æˆ‘å€‘å‰µå¥½çš„ Line Notifyï¼Œä¹‹å¾Œæˆ‘å€‘è¦å«ä½¿ç”¨è€…å»ç¶å®šæˆ‘å€‘çš„ Line Notify é€™æ¨£ä¹‹å¾Œæ‰èƒ½å°ä½¿ç”¨è€…ç™¼é€è¨Šæ¯ï¼ åœ¨å‰›å‰›ä½ å‰µå¥½çš„ Line Notify è£¡çœ‹åˆ° Client ID èˆ‡ Client Secret æ¥ä¸‹ä¾†å°±æ˜¯ç”¨ç¨‹å¼å‰µé€ å‡ºæˆ‘å€‘çš„URLè®“ä½¿ç”¨è€…å»ç¶å®šï¼ \\\n# å‰µé€ URLç¨‹å¼ç¢¼ï¼š # é€™é‚Šçš„ os.environ å°±æ˜¯æŠŠè³‡æ–™å¾ Heroku çš„è¨­å®šæª”é‚£é‚Šæ‰¾åˆ°ä¸¦æ‹¿ä¸‹ä¾†ç”¨ï¼Œä¸çŸ¥é“æ•´éº¼ç”¨çš„å¯ä»¥çœ‹ä¸Šä¸€ç¯‡ # é€™æ®µç¨‹å¼ç¢¼ä¸»è¦æ˜¯æœƒå›å‚³ä¸€ä¸² URL é€™æ™‚å€™å°±èƒ½è·Ÿæˆ‘å€‘ä¸Šæ¬¡çš„ LineBot å»åšçµåˆç›´æ¥å›å‚³å›å»çµ¦ä½¿ç”¨è€…å»åšç¶å®šï¼ line_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) import os, urllib client_id = os.environ[\u0026#39;NOTIFY_CLIENT_ID\u0026#39;] client_secret = os.environ[\u0026#39;NOTIFY_CLIENT_SECRET\u0026#39;] redirect_uri = f\u0026#34;https://{os.environ[\u0026#39;YOUR_HEROKU_APP_NAME\u0026#39;]}.herokuapp.com/callback/notify\u0026#34; def create_auth_link(user_id, client_id=client_id, redirect_uri=redirect_uri): data = { \u0026#39;response_type\u0026#39;: \u0026#39;code\u0026#39;, \u0026#39;client_id\u0026#39;: client_id, \u0026#39;redirect_uri\u0026#39;: redirect_uri, \u0026#39;scope\u0026#39;: \u0026#39;notify\u0026#39;, \u0026#39;state\u0026#39;: user_id } query_str = urllib.parse.urlencode(data) return f\u0026#39;https://notify-bot.line.me/oauth/authorize?{query_str}\u0026#39; å›å‚³çµ¦ Line Notify ä¸¦æ‹¿å–ä½¿ç”¨è€… Access Token # æˆ‘å€‘å‰é¢æœ‰äº† URL ä¹‹å¾Œå°±èƒ½é€é URL å»åšç¶å®šä¸¦è·Ÿ Line å»åšæºé€šè¦ä½¿ç”¨è€…çš„ Access Tokenï¼Œæˆ‘å€‘ä»¥å¾Œåªè¦é€éé€™å€‹ Access Token å°±èƒ½å‚³è¨Šæ¯çµ¦æˆ‘å€‘çš„ä½¿ç”¨è€…æˆ–ç¾¤çµ„æƒ¹ï¼\n# ç›£è½ç¶å®šå›å‚³è·Ÿç¶å®šå®Œæˆæœƒç™¼é€ä½ å¥½çš„è¨Šæ¯ç¨‹å¼ç¢¼ from flask import request @app.route(\u0026#34;/callback/notify\u0026#34;, methods=[\u0026#39;GET\u0026#39;]) def callback_notify(): #assert request.headers[\u0026#39;referer\u0026#39;] == \u0026#39;https://notify-bot.line.me/\u0026#39; code = request.args.get(\u0026#39;code\u0026#39;) state = request.args.get(\u0026#39;state\u0026#39;) #print(\u0026#34;Code:\u0026#34;+code) #print(\u0026#34;state:\u0026#34;+state) #print(event.source.group_id) # Get Access-Token access_token = get_token(code, client_id, client_secret, redirect_uri) #print(\u0026#34;AccessToken=\u0026#34;+access_token) #print(\u0026#34;Clinet_id\u0026#34;+client_id) google_sheet(client_id,access_token) send_message(access_token,text_message=\u0026#34;ä½ å¥½\u0026#34;) #ç™¼è¨Šæ¯ return \u0026#39;æ­å–œå®Œæˆ LINE Notify é€£å‹•ï¼è«‹é—œé–‰æ­¤è¦–çª—ã€‚\u0026#39; #æ‹¿å–å¹«ç¶è¨‚äººçš„access_token import json def get_token(code, client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri): url = \u0026#39;https://notify-bot.line.me/oauth/token\u0026#39; headers = { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39; } data = { \u0026#39;grant_type\u0026#39;: \u0026#39;authorization_code\u0026#39;, \u0026#39;code\u0026#39;: code, \u0026#39;redirect_uri\u0026#39;: redirect_uri, \u0026#39;client_id\u0026#39;: client_id, \u0026#39;client_secret\u0026#39;: client_secret } data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() res = json.loads(page.decode(\u0026#39;utf-8\u0026#39;)) #print(data) return res[\u0026#39;access_token\u0026#39;] #åˆ©ç”¨notifyç™¼å‡ºè¨Šæ¯ def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() é€™æ¨£åŸºæœ¬å°±å®Œæˆäº† LineBot è®“ä½¿ç”¨è€…ç¶å®š Line Notify äº†ï¼Œä¹‹å¾Œå°±ç”¨ä¸‹é¢çš„å‡½å¼(send_message)å°±èƒ½æŠŠä½ æƒ³è¦ç™¼é€çš„è¨Šæ¯çµ¦ä½ æŒ‡å®šçš„ç¾¤çµ„æˆ–ä½¿ç”¨è€…äº†ï¼\næˆ‘çŸ¥é“æˆ‘è¬›çš„æœ‰é»ç°¡ç•¥ï¼Œä½†å¯ä»¥æ­é…ä¸‹é¢å‰è¼©çš„æ–‡ç« ä¸€èµ·åƒè€ƒå–”ï¼ å¦‚æœéƒ½ä¸è¡Œæˆ–æ˜¯é‚„æœ‰ç–‘å•å°±ç•™è¨€å§ï¼å¦‚æœæˆ‘æœƒï¼Œæˆ‘å°±ç›¡é‡å›ç­”ï¼ï¼\nReference # Line Bot è²»ç”¨æ–¹æ¡ˆ\nè³´ç”°æ•æ‰‹ iTå¹«å¹«å¿™\nå¡ç±³ç‹— iTå¹«å¹«å¿™\n","date":"2023å¹´02æœˆ02æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/line-bot2/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡ä¸»è¦æ˜¯å¯¦ä½œå¦‚ä½•å¾åŸºæœ¬çš„ Line Bot ä¸²æ¥ Line Notifyï¼Œå›å‚³å‡º URL è®“ä½¿ç”¨è€…å»ç¶å®šé”åˆ°å¯ä»¥å»äº’å‹•çš„æ•ˆæœï¼\u003c/p\u003e","title":"Line Bot ä¹‹åˆ©ç”¨ Line Notify çªç ´é™åˆ¶å§ï¼","type":"posts"},{"content":"æœ¬æ–‡ä¸»è¦æ˜¯å¯¦ä½œå¦‚ä½•å¾ç„¡åˆ°æœ‰ä¸€å€‹ç°¡å–®çš„ Line Bot ä¸¦æŠŠç¨‹å¼ä¸Šå‚³åˆ° Heroku ç•¶ä¸€å€‹ Service å¯ä»¥å»è·Ÿæˆ‘å€‘åšç°¡å–®çš„äº’å‹•ã€‚\nLINE å®£å¸ƒå°‡æ–¼ 2025 å¹´ 3 æœˆ 31 æ—¥çµæŸ LINE Notify æœå‹™ã€‚ ç°¡å–®çš„ä»‹ç´¹ï¼š # æˆ‘å€‘è¦åš Line Bot å‰è¦å…ˆç†è§£ä¸€äº›ä»–å€‘çš„å‚³é€è³‡æ–™çš„æ–¹æ³•å’Œæ¶æ§‹ï¼ ç°¡å–®ä¾†èªªå°±æ˜¯æˆ‘å€‘ User å‚³é€çš„è³‡æ–™ or æ–‡å­—éƒ½æœƒé€é LineBot-API å…ˆå‚³åˆ° Lineï¼Œä¹‹å¾Œæœƒè½‰å‚³åˆ°æˆ‘å€‘æ›åœ¨ Heroku ä¸Šç”¨ Python+Flask å»ºç«‹çš„ç¶²é ï¼Œç„¶å¾Œç¶²é æ”¶åˆ°è«‹æ±‚å¾Œå»åŸ·è¡Œå°æ‡‰çš„ç¨‹å¼ç¢¼ï¼Œå†å›å‚³å›å» Line ä¸¦åŸ·è¡Œå°æ‡‰çš„å‹•ä½œ(Exï¼šå‚³è³‡æ–™çµ¦ User )ã€‚\nè¨»å†Šï¼š # Line Bot è¨»å†Šï¼š\næˆ‘å€‘å…ˆå» Line Developers å‰µå»ºæˆ‘å€‘çš„ Line Bot å…ˆåˆ°æˆ‘å€‘çš„ Account è£¡é¸æ“‡ Products ç„¶å¾Œé¸æ“‡ Messaging API ç„¶å¾Œé» Start Now ä¹‹å¾Œå°±é–‹å§‹å¡«ä¸€äº›åŸºæœ¬è³‡æ–™ï¼Œæœ‰äº›è³‡æ–™å¯ä»¥ä¸ç”¨å¡«ï¼Œé€™æ¨£æˆ‘å€‘å°±æœ‰äº†åŸºæœ¬çš„ LineBot äº†ã€‚ ä¹‹å¾Œå°±å»è¨»å†Š Herokuï¼Œç„¶å¾Œå°±å¯ä»¥å»ºç«‹ä¸€å€‹ Appï¼Œä¹‹å¾Œä¹Ÿæ˜¯å¡«ä¸€ä¸‹è³‡æ–™å°±å»ºç«‹å¥½äº†ï½ ç¨‹å¼èˆ‡ä¸Šå‚³ï¼š # æˆ‘å€‘æ˜¯ç”¨ Python+Flask å»ºæ§‹ä¸€å€‹ç¶²é æ›åœ¨ Heroku ä¸Šä¸¦æŒçºŒåŸ·è¡Œ ä¸Šå‚³è³‡æ–™åˆ° Heroku éœ€è¦å®‰è£ Git è·Ÿ HerokuCLI æˆ‘æ˜¯ç”¨ Python 3.8.6 å»é–‹ç™¼æ­¤å°ˆæ¡ˆï¼Œå¦‚æœéœ€åœ¨æœ¬åœ°é€²è¡Œæ¸¬è©¦ç’°å¢ƒéœ€å®‰è£ä¸€äº›è¦ä½¿ç”¨çš„å¥—ä»¶ï¼Œå¦‚æœä¸éœ€è¦æœ¬åœ°æ¸¬è©¦å°±ä¸ç”¨å®‰è£æ‘Ÿï½\npip install line-bot-sdk pip install Flask ä¹‹å¾Œå°±é–‹å§‹çœ‹æˆ‘å€‘çš„ Line Bot ç¨‹å¼ç¢¼äº†ï¼\n# main.py # åˆå§‹åŒ–LINT BOT import os from flask import Flask from linebot import LineBotApi, WebhookHandler app = Flask(__name__) line_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) # åˆ©ç”¨ handler è™•ç† LINE è§¸ç™¼äº‹ä»¶ from linebot.models import MessageEvent, TextMessage, TextSendMessage @handler.add(MessageEvent, message=TextMessage) def handle_message(event): line_bot_api.reply_message( event.reply_token, TextSendMessage(text=f\u0026#34;Hello {line_bot_api.get_profile(event.source.user_id).display_name}!\u0026#34;) ) # åˆ©ç”¨ route è™•ç†è·¯ç”± from flask import request, abort from linebot.exceptions import InvalidSignatureError @app.route(\u0026#34;/callback\u0026#34;, methods=[\u0026#39;POST\u0026#39;]) def callback(): signature = request.headers[\u0026#39;X-Line-Signature\u0026#39;] body = request.get_data(as_text=True) app.logger.info(\u0026#34;Request body: \u0026#34; + body) try: handler.handle(body, signature) except InvalidSignatureError: abort(400) return \u0026#39;OK\u0026#39; æˆ‘å€‘å¯ä»¥çœ‹åˆ°ç¨‹å¼ç¢¼è£¡é¢æœ‰ CHANNEL_ACCESS_TOKEN è·Ÿ CHANNEL_SECRET éƒ½æ˜¯åœ¨æˆ‘å€‘å‰›å‰›å‰µ Line Bot çš„åœ°æ–¹å¯ä»¥çœ‹åˆ°ï¼Œé€™å€‹å¾ˆé‡è¦å…ˆè¨˜è‘—ï¼ Channel secret åœ¨ Basic Setting ä¸‹ Channel access token åœ¨ Messaging API ä¸‹ ä¹‹å¾Œå°±è¦å›åˆ° Heroku çš„éƒ¨åˆ†å› ç‚ºæˆ‘å€‘è¦ä¸Šå‚³åˆ° Herokuï¼Œæˆ‘å€‘å…ˆæŠŠç’°å¢ƒè¨­å®šèˆ‡ç¨‹å¼ç¢¼çš„éƒ¨åˆ†æå®šåœ¨ä¸Šå‚³ æˆ‘å€‘è¦æŠŠç¨‹å¼ä¸Šå‚³åˆ° Heroku éœ€è¦å¹¾å€‹æ±è¥¿è®“ Heroku çŸ¥é“è¦æˆ‘å€‘è¦ä½¿ç”¨çš„å¥—ä»¶èˆ‡æŒ‡å®šè¦è·‘çš„ç¨‹å¼ç­‰ç­‰\u0026hellip; è¦ä¸Šå‚³Herokuæœ‰å¹¾å€‹å¿…è¦çš„æ±è¥¿ Procfileï¼Œrequirements.txtï¼Œruntime.txt é€™ä¸‰å€‹è¨­å®šæª”è·Ÿä½ çš„ä¸»ç¨‹å¼(main.py)ã€‚\nProcfileï¼šä¸»è¦æ˜¯å¯«èªªä½ é€™å€‹ç¨‹å¼æ˜¯ä»€éº¼æ±è¥¿ä¸¦ä¸»è¦åŸ·è¡Œçš„ç¨‹å¼ æˆ‘å€‘è¦åœ¨è£¡é¢å¡«ä¸Š web: gunicorn main:app â€“preload èªªæ˜è¦ç”¨ main é€™å€‹ç¨‹å¼é‹è¡Œä¸€å€‹ app ä¸¦ä¸”æ˜¯ç”¨ Gunicorn æ­å»ºä¸€å€‹ Web æœå‹™ ç­‰ç­‰ä¸Šå‚³å°±å¯ä»¥åœ¨ä½ çš„ Heroku ä¸Šçœ‹åˆ° requirements.txtï¼šé€™å¾ˆé‡è¦ï¼é€™æ˜¯è¦æŠŠæˆ‘å€‘éœ€è¦ç”¨åˆ°çš„ Library å»è·Ÿ Heroku èªªï¼Œä»–æœƒåœ¨ä¸Šå‚³ç¨‹å¼ç¢¼æ™‚ä¸€èµ·æŠŠå¥—ä»¶è£èµ·ä¾† é€™é‚Šå°±åˆ—å‡ºæˆ‘å€‘éœ€è¦ç”¨çš„ å¥—ä»¶åå­—==ç‰ˆæœ¬\nFlask==2.0.2 gunicorn==19.9.0 line-bot-sdk==2.0.1 requests==2.27.1 psycopg2==2.9.3 numpy==1.19.4 Pillow==8.0.1 pygsheets==2.0.5 runtime.txtï¼šé€™è£¡é¢æ˜¯èªªæ˜ä½ è¦ç”¨ä»€éº¼èªè¨€è·Ÿç‰ˆæœ¬å»åŸ·è¡Œç¨‹å¼ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯ python-3.8.6 ä¹‹å¾Œæˆ‘å€‘å°±ç…§è‘— Heroku è£¡ Deploy ä¸‹çš„æ­¥é©Ÿä¸€æ­¥ä¸€æ­¥æ“ä½œå°±èƒ½ä¸Šå‚³ç¨‹å¼ç¢¼åˆ° Heroku ä¸Šäº† éç¨‹è·Ÿä¸Šå‚³ Github çš„æ–¹æ³•87ï¼…åƒï¼Œä¹‹å¾Œæˆ‘å€‘å‰›å‰›å¯ä»¥çœ‹åˆ°ç¨‹å¼ç¢¼è£¡æœ‰é€™å…©å¥\nline_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) é€™é‚Šç”¨çš„ os.environ[\u0026lsquo;CHANNEL_ACCESS_TOKEN\u0026rsquo;]ï¼Œæ˜¯åˆ©ç”¨æˆ‘å€‘ Heroku ä¸Šè¨­å®šç’°å¢ƒè®Šæ•¸ä¸¦ç•¶ä½ è·Ÿ Heroku è¦çš„æ™‚å€™æœƒåå‡ºæŒ‡å®šçš„æ±è¥¿çµ¦ä»–é‚£è¦æ•´éº¼è¨­å®šå‘¢ï¼Ÿ åœ¨ä½ çš„ Heroku App è£¡çš„ Setting å¯ä»¥çœ‹åˆ° Config Vars æŠŠæ—é‚Šçš„é»é–‹å°±èƒ½çœ‹åˆ°å…©è¡Œå¯ä»¥è¼¸å…¥çš„æ±è¥¿ï¼Œæˆ‘å€‘å°±åœ¨é€™é‚Šè¼¸å…¥æˆ‘å€‘ LineBot çš„è³‡è¨Šå°±ä¸ç”¨æŠŠæ©Ÿå¯†å¯«åœ¨ç¨‹å¼è£¡æ‘Ÿï¼ï¼ å®‰å…¨å§ï¼ æˆ‘å€‘æœ‰äº†å‰›å‰›è¬›çš„é€™ä¸‰å€‹æª”æ¡ˆè·Ÿä¸»ç¨‹å¼(main.py)å°±å¯ä»¥ä¸Šå‚³åˆ°ä½ çš„ Herokuï¼Œä¸¦ä¸”å»åˆ° Heroku è¨­å®šä¸€ä¸‹ç’°å¢ƒè¨­å®š å°±å›å»å‰›å‰›çš„ LineBot è£¡çš„ Webhook URL å¡«ä¸Š https://ä½ herokuçš„APPåå­—.herokuapp.com/callback æŒ‰ Verify æ­£å¸¸éçš„è©±å°±æ˜¯ä»£è¡¨èƒ½ç”¨æ‘Ÿï¼ï¼\nTrouble shooting # å…ˆæª¢æŸ¥ Webhook URL æ˜¯å¦æœ‰å°åˆ°ä½ çš„ HerokuAPP å†æª¢æŸ¥ CHANNEL_ACCESS_TOKEN è·Ÿ CHANNEL_SECRET æ˜¯å¦å¡«å° å¦‚æœä½ ä¸è¦ºçš„æ˜¯ Heroku çš„å•é¡Œï¼Œä¹Ÿèƒ½æ”¹æˆç›´æ¥å¯«åœ¨ç¨‹å¼è£¡åœ¨æœ¬åœ°åŸ·è¡Œç¨‹å¼å»é€²è¡Œæ¸¬è©¦\nline_bot_api = LineBotApi(\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;) Ex: line_bot_api = LineBotApi(\u0026#39;sdgfdfhfgjfgjerwer3534534\u0026#39;) handler = WebhookHandler(\u0026#39;CHANNEL_SECRET\u0026#39;) Ex: handler = WebhookHandler(\u0026#39;dsfdsf453465sdgsg\u0026#39;) éä¾†å°±æ˜¯æª¢æŸ¥ä¸Šå‚³ Heroku çš„è³‡æ–™æ˜¯å¦éƒ½æœ‰ï¼Œå†æª¢æŸ¥æ˜¯å¦æœ‰ä¸Šå‚³æˆåŠŸ\næˆ‘çŸ¥é“æˆ‘è¬›çš„æœ‰é»ç°¡ç•¥ï¼Œä½†å¯ä»¥æ­é…ä¸‹é¢å‰è¼©çš„æ–‡ç« ä¸€èµ·åƒè€ƒå–”ï¼ å¦‚æœéƒ½ä¸è¡Œæˆ–æ˜¯é‚„æœ‰ç–‘å•å°±ç•™è¨€å§ï¼å¦‚æœæˆ‘æœƒï¼Œæˆ‘å°±ç›¡é‡å›ç­”ï¼ï¼\nReference # LINE Bot ç³»åˆ—æ–‡ â€” ä»€éº¼æ˜¯ Webhook?\nè³´ç”°æ•æ‰‹ iTå¹«å¹«å¿™\nå¡ç±³ç‹— iTå¹«å¹«å¿™\n[ChatBot] å‰µé€ è‡ªå·±çš„ Line botï¼Œç¬¬ä¸€æ¬¡å°±ä¸Šæ‰‹ï¼(1) â€” Line bot æ¶æ§‹åŠå·¥å…·ç°¡ä»‹\n","date":"2023å¹´02æœˆ01æ—¥","externalUrl":null,"permalink":"/zh-tw/posts/line-bot1/","section":"Posts","summary":"\u003cp\u003eæœ¬æ–‡ä¸»è¦æ˜¯å¯¦ä½œå¦‚ä½•å¾ç„¡åˆ°æœ‰ä¸€å€‹ç°¡å–®çš„ Line Bot ä¸¦æŠŠç¨‹å¼ä¸Šå‚³åˆ° Heroku ç•¶ä¸€å€‹ Service å¯ä»¥å»è·Ÿæˆ‘å€‘åšç°¡å–®çš„äº’å‹•ã€‚\u003c/p\u003e","title":"è®“æˆ‘å€‘ç”¨ Python é–‹ç™¼ä¸€å€‹ Line Bot","type":"posts"},{"content":"","externalUrl":null,"permalink":"/zh-tw/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/zh-tw/series/","section":"Series","summary":"","title":"Series","type":"series"}]