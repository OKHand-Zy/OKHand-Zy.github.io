


[{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/categories/ai/","section":"Categories","summary":"","title":"AI","type":"categories"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/tags/gemini/","section":"Tags","summary":"","title":"Gemini","type":"tags"},{"content":"這是一份 Googel 在2024年10月針對 Gemini 模型並如何正確下 Prompt 的一份文件。因為對於新手來說這對下 Prompt 也算是一個不錯的教學！\nPromprt 主要考慮4大主要要素 # 角色 (Persona) 任務 (Task) 上下文 (Context) 風格 或 格式 (Format) 範例：\n應用4大要素使 “gemini 在 Gmail 和 Google 文檔” 效果更好\n英文版：\nYou are a program manager in [industry]. Draft an executive summary email to [persona] based on [details about relevant program docs]. Limit to bullet points.\n中文版：\n您是 [行業] 的項目經理。根據 [相關項目文檔的詳細信息]，為 [角色] 草擬一封執行摘要郵件。限制使用項目符號。\n這邊的範例,我們可以分析出4大要素\n角色: You are a program manager in [industry] 任務: Draft an executive summary email to 上下文: [persona] based on [details about relevant program docs]. 格式: Limit to bullet points. 你不用每次一定需要這4個要素在你的 Prompt 中, 但使用 Prompt時帶有其中幾個要素會對 LLM 有所幫助! 但要記住在 \u0026ldquo;任務\u0026rdquo; 中一定要包含 \u0026ldquo;動作\u0026rdquo; 或是 \u0026ldquo;命令\u0026rdquo; 這是 Prompt 組成中最重要的部分。\n提示詞 # 以下是一些可以幫助您開始使用 Gemini for Google Workspace 的快速提示：\nUse natural language (使用自然語言):\n像與人交談一樣寫作。用完整的句子表達完整的思想。\nBe specific and iterate (具體化並持續疊代):\n告訴 Gemini 您需要它做什麼（總結、撰寫、改變語氣、創建）。提供盡可能多的上下文信息。\nBe concise and avoid complexity (簡潔與避免複雜):\n用簡短但具體的語言陳訴你的請求。避免使用專業術語(或是一些時下的詞彙或是簡寫 等等…)。\nMake it a conversation (將其視為對話):\n如果結果不符合您的期望，或者您認為有改進空間，請調整您的提示词。使用後續調整的 Prompt 並 審查 和 最佳化 的疊代過程来產生更好的結果。\nUse your documents (利用你的文件檔案):\n使用您在 Google Drive 中的文件資訊来個性化 Gemini 的輸出。\nMake Gemini your prompt editor (讓 Gemini 成為您的Prompt編譯器):\n在使用 Gemini Advanced 時，以如下內容開始您的 Prompt：”將此内容轉化為一個強大的提示詞：[在此處填入原始 prompt]。” Gemini 將針對如何改進您的提示詞提出建議。確保其表達了您所需的内容，然後將其複製貼回 Gemini Advanced 以獲取輸出。\nPrompt 撰寫是一項大家都可以學習的技能。您不必是提示詞工程師才能使用生成式 AI。但是，如果您使用第一次沒有得到期望的結果，您可能需要多嘗試幾種不同的提示詞方法。\n根據統計最有成效的 Prompt 平均約包含 21個單詞和相關的上下文，但人們嘗試的提示詞通常少於 9 個單詞。 提升您撰寫 Prompt 水平的方法 # Brake it up (分解任務):\n如果您希望 Gemini for Workspace 執行多個相關任務，請將它們分解為單獨的 Prompt。\nGive constraints (給出限制):\n為了生成特定的結果，請在 Prompt 中包含詳細信息，例如字符数限制或您希望生成的选项数量。\nAssign a role (分配腳色):\n為了鼓勵創造力，請分配一個角色。您可以通過以下 Prompt 来實現這一點：\n英文:\n“You are the head of a creative department for a leading advertising agency …”\n中文:\n”您是一家領先廣告公司的創意部門負責人……”\nAsk for feedback (尋求回饋):\n在與 Gemini Advanced 的對話中，告訴它您正在給它一個項目，包括所有相關細節，然後描述您想要的輸出。通過提出 例如: “您有什麼問題可以幫助您提供最佳輸出？” 之類的問題來繼續對話。\n英文:\n“What questions do you have for me that would help you provide the best output?”\n中文:\n“您有什麼問題可以幫助您提供最佳輸出？”\nConsider tone (考慮語氣風格):\n根據您的目標受眾調整您的 Prompt。要求輸出具有特定的語氣，例如: 正式、非正式、技術性、創意性 或 休閒性。\nSay it another way (嘗試不同說法):\n如果產生結果不符合您的期望，或者您認為有改進的空間，請調整您的 Prompt。審查 和 最佳化的疊代過程通常會產生更好的结果 。\n文章最後還打個預防針:\n因為 AI Model 一直在進步，所以 Prompt 有時可能會產生不可預測的響應。\n在下 Prompt 前請先確認 Prompt 保有其清晰性、相關性 和 準確性。\n最後還補上一句請牢記一點 \u0026ldquo;生成式 AI 旨在幫助人類但最終輸出由您負責\u0026rdquo;。\n懶人包大概就是:\n你用了上述技巧如果回應還是很糟糕要不是你的問題，就是AI的不可預測性問題，別來找我麻煩。\n因為我只想看 Prompt 部分文件之後都是各行業的使用情境使使用範例如果大家有興趣可以去看看!!\n額外補充: 如果是使用Gemini API 有 thinking 可以使用\nfrom google import genai from google.genai import types client = genai.Client(api_key=\u0026#34;GOOGLE_API_KEY\u0026#34;) prompt = \u0026#34;What is the sum of the first 50 prime numbers?\u0026#34; response = client.models.generate_content( model=\u0026#34;gemini-2.5-pro-preview-06-05\u0026#34;, contents=prompt, config=types.GenerateContentConfig( thinking_config=types.ThinkingConfig( include_thoughts=True ) ) ) Reference # Google WorkspaceGemini for Google Workspace Prompt Guide\n","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/posts/gemini-workspace-prompt/","section":"Posts","summary":"\u003cp\u003e這是一份 Googel 在2024年10月針對 Gemini 模型並如何正確下 Prompt 的一份文件。因為對於新手來說這對下 Prompt 也算是一個不錯的教學！\u003c/p\u003e","title":"Gemini for Workspace Prompt","type":"posts"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/","section":"OKH@nd's Blog","summary":"","title":"OKH@nd's Blog","type":"page"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/tags/prompt/","section":"Tags","summary":"","title":"Prompt","type":"tags"},{"content":"","date":"2025年08月31日","externalUrl":null,"permalink":"/zh-tw/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025年08月22日","externalUrl":null,"permalink":"/zh-tw/tags/api/","section":"Tags","summary":"","title":"API","type":"tags"},{"content":"","date":"2025年08月22日","externalUrl":null,"permalink":"/zh-tw/tags/model/","section":"Tags","summary":"","title":"Model","type":"tags"},{"content":"因應最新的 GPT-5 出來的同時 API 多了幾個(對我來說的)新參數，Reasoning Effort 跟 Verbosity\nreasoning effort 推理 # reasoning.effort 參數有以下幾種程度可選擇\nminimal low medium high 預設值為 medium\n參數控制模型在產生回應之前 推理多久 與 產生多少推理 Token。\n其實 reasoning.effort 在之前 o 系列(Ex：o1, o3)能使用，這次新增的是 minimal 會以最快的輕量化的方式思考(需要或不需要)添加非常少的推理 token 。\nVerbosity 詳細程度 # verbosity 參數有以下幾種程度可選擇\nlow medium high verbosity 決定了產生多少輸出 Token。\n下面是詢問同一個問題並且使用同個 Model 與 reasoning 階段調整 verbosity 的回應\nmodel: gpt-5-nano\neffort: high\nverbosity: low\ncompletion_tokens=3959, prompt_tokens=30, total_tokens=3989 量子糾纏是指多個量子系統的整體狀態無法寫成各自子系統狀態的乘積，必須以共同的量子態存在，兩者之間有著不能用古典方式解釋的強相關。\\n\\n直觀要點\\n- 兩個粒子（或量子位）一起被創建，彼此即使分開很遠，測量結果仍顯示高度相關。\\n- 這種相關性在多個測量基底（如 Z、X 基底）都能看到，且不是單純的概率預測，而包含量子相干（干涉）信息。\\n\\n數學範例\\n- 一個常見的糾纏態是 Bell 态 |Φ+\u0026gt; = (|00\u0026gt; + |11\u0026gt;)/√2。\\n - 在 Z 基底測量：若第一粒子是 0，第二粒子必定是 0；若第一粒子是 1，第二粒子必定是 1。\\n - 在 X 基底測量：若對第一粒子得到 +，第二粒子也得到 +；若得到 −，第二粒子也得到 −。\\n- 單粒子邊際的密度矩陣是混合態（資訊被「分裝」在整體中），但整體是純態，且包含跨基底的相干性。\\n- 與古典混合相比，糾纏態具有無法用乘積狀態組合來描述的特性；同樣的邊際分布在某些情況下可能看起來相同，但缺少跨基底的相干性。\\n\\n重要性與限制\\n- 這些量子相關性無法用局部隱變量模型解釋，屬於量子非局部性的一種表現。\\n- 不能用單單糾纏量子態來傳遞訊息；需要經由經典通訊來比對結果。\\n- 亮點應用：量子態傳送（ teleportation ）、超密編碼（ superdense coding ）、量子密鑰分發（ QKD，如 Ekert91）等。\\n\\n簡單总结\\n糾纏是多粒子系統的一種「共同存在的」量子狀態，體現在跨粒子的測量結果上，既強烈相關又不能用古典機制完全解釋，並且是許多量子資訊技術的核心資源。 model: gpt-5-nano\neffort: high\nverbosity: medium\ncompletion_tokens=5433, prompt_tokens=30, total_tokens=5463, 下面用比較直觀與幾何的方式，講解什麼是量子糾纏，以及它為什麼重要。\\n\\n1) 什麼是量子糾纏\\n- 多個量子系統（例如兩個粒子、兩個光子）被處於一個整體的量子態，這個態不能寫成各自系統態的直積：ψ ≠ ψ_A ⊗ ψ_B。也就是說，整個系統的狀態無法分解成各部分各自的“預先決定的值”。\\n- 這意味著：對其中任一子系統的測量結果，與另一子系統的測量結果之間存在著「非經典的相關性」，即使兩個系統相隔很遠，這種相關性也不依賴於傳遞信號。\\n\\n2) 用最常見的兩粒子例子說明\\n- 貝爾態（Bell states）是兩個量子比特最典型的糾纏態，例如其中一個是：\\n - |Φ+⟩ = (|00⟩ + |11⟩) / √2\\n 另外還有 |Φ−⟩、|Ψ+⟩、|Ψ−⟩，每一個都無法寫成 |a⟩⊗|b⟩ 的形式。\\n- 另一個常見例子是“singlet”態：\\n - |Ψ−⟩ = (|01⟩ − |10⟩) / √2\\n 這個態在測量兩個粒子自旋沿同一軸時，結果是完全反相關的（一個 +1，另一個 −1）。\\n- 直覺重點：對單一粒子的性質來說，量子糾纏態的個別邊際狀態通常是混合的（看起來像是“未知的”，或是沒有 definite 值），只有把兩個粒子一起測量時，才會看到穩定的聯繫。\\n\\n3) 測量與相關性（不等於“資訊以光速瞬間傳遞”）\\n- 對糾纏對而言，若在某個方向測量第一個粒子自旋（或偏振），第二個粒子的結果會以某種方式被“自動地”相關地顯示出來，這種相關性不需要任何信號傳遞。\\n- 對不同測量方向的設定，相關性可以寫成：對兩個粒子分別在測量方向 a 和 b，其結果的相關函數 E(a,b) = ⟨σ(a) ⊗ σ(b)⟩，在 singlet 态中有 E(a,b) = -a · b，即兩測量方向的夾角 θ 的餘弦負值。\\n- 這種現象不等於“預先設定的值”或“局部因果影響”；如果你用局部實在論去解釋，就會遇到 Bell 不等式等限制。\\n\\n4) Bell 不等式與實驗驗證\\n- 局部實在論者會認為每個粒子在被測量前就已經有預先決定的結果，測量只是揭示這些值；這導致某些數學不等式（如 CHSH 不等式）必須成立。\\n- 量子力學的預測在適當的設定下會違背這些不等式，最大可達到的量子值是 S = 2√2（Cirel’son 極限）。\\n- 實驗中常做佛述的 Bell 測試（如 CHSH 測試）。多個實驗已經觀察到對應的量子預測的違背，支持量子糾纏與量子力學的非局部相關性。也出現了“漏洞自由”的實驗設計，以排除某些替代解釋。\\n\\n5) 如何產生與檢驗糾纏\\n- 產生：實驗室常用機制包括光子的自發參量下轉換（SPDC）將一次光子對變為糾纏的二子光子（偏振、時間位、路徑等任一度態）。也有利用原子、離子、超導量子比特、氮空位（NV）中心等系統的糾纏。\\n- 檢驗/證明：\\n - 量子態層析（quantum state tomography）以重複測量與統計推估整體態。\\n - 糾纏檢驗（entanglement witnesses）或計算糾纏度（如 concurrence、negativity）。\\n - Bell 測試（CHSH 不等式）用以證明非局部相關性。\\n- 量子態的部分跡（例如單一粒子邊際密度矩陣）往往是完全混合的，而只有結合起來才呈現明顯的糾纏性。\\n\\n6) 為什麼量子糾纏重要（應用層面）\\n- 量子遞送（量子 teleportation）：不以傳送物理粒子為前提，而是利用糾纏對結合一個未知量子態的傳送。\\n- 超密碼編碼（superdense coding）：用一個量子比特與預先共享的糾纏對，傳送兩個資料比特的資訊。\\n- 量子鑰匙分配（quantum key distribution, QKD，特別是 Ekert 協議）：利用糾纏帶來的測量結果相關性，探測竊聽並安全分發密鑰。\\n- 量子計算中的資源：糾纏是實現某些量子演算法與量子錯誤更正的核心資源。\\n\\n7) 常見誤解與要點\\n- 不存在“超光速資訊傳遞”：測量結果本身是隨機的，只有把兩端的結果透過經典通道比對後，才出現對應的相關性。\\n- 糾纏不是「兩個粒子同時擁有某個確定值」的證明；相反，直到測量，個別粒子的性質往往是未確定的。\\n- Entanglement 是不可分割的資源，但也有“單向分享”限制（monogamy of entanglement）：一個量子對的糾纏程度不能被任意地分配給第三方。\\n\\n如果你想，我可以再深入某一部分，例如：\\n- 具體推導兩粒子 Bell state 的測量相關性與 E(a,b) 的公式\\n- CHSH 不等式的推導與一個具體的實驗設定例子\\n- 如何用量子態層析進行糾纏度的量測與計算\\n- 具體的實驗平台比較（光子、離子、超導量子比特等）的糾纏產生與測量方式\\n\\n告訴我你想更深入哪個部分，我可以給你更精確的公式與步驟。 model: gpt-5-nano\neffort: high\nverbosity: high\ncompletion_tokens=8620, prompt_tokens=30, total_tokens=8650 以下用比較直白的語言，並輔以一點點數學要點，幫你理解什麼是量子糾纏、為什麼它重要，以及它在實驗和應用上的意義。\\n\\n一、什麼是量子糾纏（Q.E.：量子糾纏）\\n- 定義要點：當兩個或以上的量子系統組成一個整體時，它們的量子狀態有別於各自單獨狀態的乘積形式。也就是說，無法把整個系統寫成兩部分各自的狀態的乘積 |ψ\u0026gt; ≠ |a\u0026gt;⊗|b\u0026gt;。這種“不可分割”的整體狀態就叫作糾纏狀態。\\n- 核心特徵：對其中一個系統的測量結果，會與另一個系統的結果出現深刻的相關性，這些相關性在很多情況下無法用任何局部的“預先存在的屬性”來解釋。\\n- 重要的約束：雖然這種相關性很「神祕」，但它並不會讓你用它進行超光速訊息傳遞（無法單獨用糾纏來傳送信息，必須借助經典通道的比較才能看到相關性）。\\n\\n二、用一個最常見的例子說明\\n- 貝爾對（Bell pair）是兩個量子系統最典型的糾纏態之一。最常見的形式是：\\n |Φ+\u0026gt; = (|00\u0026gt; + |11\u0026gt;)/√2\\n 這裡的“|0\u0026gt; 與 |1\u0026gt;”是兩個量子比特的基態。\\n- 如果你在兩個量子比特上都測量“計算基底”Z基底（即判定是0還是1），你會得到兩個結果總是相同的：要麼同時是 0-0，要麼同時是 1-1，各有 1/2 的機率。\\n- 如果你在兩個量子比特上都測量另一個基底（例如X基底，|+\u0026gt; = (|0\u0026gt;+|1\u0026gt;)/√2 與 |-\u0026gt; = (|0\u0026gt;-|1\u0026gt;)/√2），你也會看到同樣的結果：兩者總是相同。\\n- 這種在不同測量基底下仍保持高度相關的現象，就是量子糾纏的直觀寫照。對於不同的測量角度，相關的強度會依角度變化（這也正是後面要談的“不等式”背後的物理意義）。\\n\\n三、為什麼糾纏比一般的「相關」還要特別\\n- 區別於經典相關：如果把兩個粒子放在一起，但實際上每個粒子事先就有某些屬性（提前设定好，例如顏色、方向等）可以被我們在實驗時就預測，這叫「局部實在論」。量子糾纏的相關性，讓這種局部實在論難以解釋，因而出現了著名的 Bell 不等式及實驗上的違背。\\n- 混合態也可能糾纏：並非只有“純態”的 |Φ+\u0026gt; 類型才糾纏。混合態的密度矩陣 ρ 也可能是糾纏的（但有時候看起來像是“部分預先決定的混合”，要用具體的糾纏檢驗才行）。\\n- 糾纏與“資訊的控制”關係：糾纏提供了一種非局部的量子相關資源，讓量子通訊、量子計算等技術成為可能；但它本身不等於傳遞訊息的工具，必須結合經典通道與測量的後處理。\\n\\n四、數學觀點的快速入門（可選加深）\\n- 對於兩個量子系統，整體狀態在希爾伯特空間 H_A ⊗ H_B。若存在兩個單獨的狀態 |α\u0026gt;_A、|β\u0026gt;_B，使得 |ψ\u0026gt; = |α\u0026gt;_A ⊗ |β\u0026gt;_B，則該狀態是“非糾纏的”。若不能這樣寫，則為糾纏狀態。\\n- Schmidt 展開：任意純態 |ψ\u0026gt;_AB 都可以寫成 |ψ\u0026gt; = ∑_i √λ_i |u_i\u0026gt;_A ⊗ |v_i\u0026gt;_B，其中 λ_i 為非負實數且 ∑ λ_i = 1。若只有一個非零 λ_i，則該狀態是非糾纏的；若有多個非零 λ_i，則糾纏存在。\\n- 直觀的實驗檢驗法：Bell 不等式與 CHSH 不等式提供一個「局部實在論的邊界」，用實驗上的測量來檢驗是否有顯著違背。若違背，意味著量子力學的糾纏特性無法被局部隱變量解釋。\\n\\n五、實驗證據與里程碑\\n- 歷史上的起點：EPR 論證（愛因斯坦、波多爾斯基、羅森）認為量子力學似乎缺乏完備性，糾纏被視為“超距作用”的問題。之後 Bell 的不等式提供了可檢驗的預測。\\n- 實驗發展： Aspect 等人（1980s）用光子實驗測試 CHSH 不等式，看到量子預測的違背。\\n- 後續改進：出現了“ loophole-free Bell test（不設漏洞的貝爾測試）”在 2015 年左右分別由多個團隊完成，同時克服了探測率與 局域性等漏洞的問題，給予對量子糾纏的更強證據。\\n- 目前實驗對象廣泛：光子、冷離子、超導量子比特、中性原子等平台都能製備與操控糾纏態。\\n\\n六、實際的應用（糾纏作為資源）\\n- 量子 teleportation（量子隧道傳輸）：利用事先共享的糾纏對與經典通道，在不直接傳送量子比特的情況下，將一個未知量子狀態“傳送”到遠端。核心步驟是先做一個 Bell 基態測量，然後根據測量結果進行經典位元的控制操作。\\n- 超密编码（Superdense Coding）：用一個量子比特與一對糾纏比特，能讓一方傳送兩位經典訊息到另一方，超出單比特原本的資訊容量。\\n- 量子密鑰分發（QKD）：例如 Ekert 指出，糾纏對的測量結果可以用來建立安全的密鑰，任何竄改都會被探測到。\\n- 糾纏蒐集與糾纏淨化：在實際網路或量子計算中，常需要從雜訊中提取“高品質”的糾纏對，這就需要糾纏淨化/蒐集等技術。\\n\\n七、常見的誤解與釐清\\n- 誤解1：糾纏就是“能瞬間傳遞訊息”。實際上，兩端的測量結果在局部看都是隨機的，只有把兩端的結果經過傳統通道比對後才看到相關性，因此不能用來超光速傳遞資訊。\\n- 誤解2：糾纏等於“已經預先決定好了兩個結果”。其實，對於單端的任何測量，結果都是隨機的；關鍵在於聯合測量的統計關係，這種關係是無法用單純的預先存在的值來解釋。\\n- 誤解3：所有相關都是“糾纏”。有些相關是因為古典相關性（例如同時看到兩個裝置的共同情況），而量子糾纏指的是無法用局部定義的隱變量去解釋的相關性，通常需要用 Bell 不等式來驗證。\\n\\n八、想更深入嗎？可以從以下方向拓展\\n- 進階數學：學習密度矩陣、部分轉置（PPT）判別、負性（Negativity）作為糾纏量度、 Schmidt 分解等工具。\\n- 不等式與實驗設計：熟悉 CHSH 不等式、實驗中的檢測率、局域性與自由意志假說等實驗細節。\\n- 量子糾纏與量子計算的連結：理解在量子電腦中如何用糾纏作為量子門和多量子比特干涉的資源。\\n- 參考案例與讀物：Ekert 1991 的 QKD 論文、Bell 不等式的教科書推導、Hensen/Shalm/Giustina 等的實驗報告，以及「Werner state」等混合狀態的研究。\\n\\n如果你願意，我可以再深挖某一部分，例如：\\n- 更詳細的數學推導（例如 Schmidt 展開、CHSH 不等式的推導與量子機制）\\n- 具體實驗裝置與測量設計的物理原理（比如 SPDC 產生的糾纏光子對、離子閘控與測量等）\\n- 量子 teleportation、dense coding、QKD 的步驟與實例\\n\\n告訴我你想先深挖哪個部分，我可以給你更具體的說明與例子。 推薦大家可以自己去試試看自己哪種組合比較喜歡，筆者是比較喜歡 Low 的簡短回答。\n範例 Code：\nfrom openai import OpenAI client = OpenAI( base_url=\u0026#34;\u0026lt;router-url\u0026gt;\u0026#34;, api_key=\u0026#34;\u0026lt;your-api-key\u0026gt;\u0026#34;, ) completion = client.chat.completions.create( model=\u0026#34;openai/gpt-5-nano\u0026#34;, reasoning_effort= \u0026#34;low\u0026#34;, verbosity=\u0026#39;low\u0026#39;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;你是一位科學研究助理。\u0026#34; } ] }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;請解釋量子糾纏。\u0026#34; } ] } ] ) Reference # OpenAI Platform - Using GPT-5\n","date":"2025年08月22日","externalUrl":null,"permalink":"/zh-tw/posts/gpt-5_api_feature/","section":"Posts","summary":"\u003cp\u003e因應最新的 GPT-5 出來的同時 API 多了幾個(對我來說的)新參數，Reasoning Effort 跟 Verbosity\u003c/p\u003e","title":"New API feature in GPT-5","type":"posts"},{"content":"","date":"2025年08月22日","externalUrl":null,"permalink":"/zh-tw/tags/openai/","section":"Tags","summary":"","title":"OpenAI","type":"tags"},{"content":" Hi 👋, I\u0026rsquo;m OKH@nd_ZiYu # 很高興能在這裡與你相遇。\n我是一名工程師，致力於用我有限的知識，嘗試去改變現今的教育及社會，讓世界變得更美好。\n這是我用來記錄學習、分享經驗的角落。\n我會將業界的實務經驗與學術上的新知結合，轉化成好懂、實用的內容。\n我的目標很簡單：希望透過分享，幫助像我一樣走在技術路上的夥伴，並一起思考如何運用我們的所學，為教育與社會帶來正向的改變。\n謝謝你的來訪，期待與你一同成長！\n","date":"2025年08月15日","externalUrl":null,"permalink":"/zh-tw/about/","section":"OKH@nd's Blog","summary":"","title":"關於 我","type":"page"},{"content":"","date":"2025年06月20日","externalUrl":null,"permalink":"/zh-tw/categories/cloudflare/","section":"Categories","summary":"","title":"Cloudflare","type":"categories"},{"content":"因為 Imgur 大約從2025年5月16日開始，無預警地封鎖了來自台灣的 IP，不再允許台灣使用者登入或是上傳圖片等\u0026hellip;動作。所以就想說之後都把圖片改放在 Cloudflare R2 上面。\n這邊先假設我們都有自己的 Domain 名稱，並且已經在 Cloudflare 上設定好了。 Cloudflare R2 的好處是他是與 Amazon S3 API 是相容的所以你要登入就用 Amazon S3 的方式就能連接操作。\n費用的部分看這邊：cloudflare-r2 pricing\n我們先建立一個 Cloudflare R2 Storage\n接著我們到 設定 -\u0026gt; Custom Domains\n建立一個可以讓外部使用的自訂域名，我這邊就用 myimage 加上我的 Domain ，如果你是用 Claudflare DNS 的話他會自動幫你新增上去。\n之後我們確定 狀態是\u0026quot;使用中\u0026quot; 與 Access是\u0026quot;已啟用\u0026quot; 最後確認上方公開存取的狀態是\u0026quot;已啟用\u0026quot;就代表可以摟！！\n之後我們來設定 API，這是如果你不想在網頁上使用就要設定。 點擊 \u0026ldquo;管理 API 權杖\u0026rdquo;\n我這邊是建立 \u0026ldquo;使用者 API 權杖\u0026rdquo; 權限：選擇 \u0026ldquo;系統管理員讀取和寫入\u0026rdquo; (看個人我是因為方便操作所以選擇這個) 建立之後就會跳出金鑰這邊要保存好，之後就能用這個跟我們的 R2 連接了。\n之後你要使用到 R2 上的檔案時 URL 會長以下這樣\n無資料夾 URL： https://\u0026lt;Custom_Domain\u0026gt;/\u0026lt;檔名\u0026gt; 有資料夾 URL： https://\u0026lt;Custom_Domain\u0026gt;/\u0026lt;資料夾名\u0026gt;/\u0026lt;檔名\u0026gt; 之後就能用你方便的工具連上進行放置資料等等\u0026hellip;的操作了。 簡單吧！不過最累的還是要把圖片分類搬過去\u0026hellip;.\nReference # Imgur 封鎖台灣 IP，我把圖床搬到 Cloudflare R2\n架設Cloudflare R2免費圖床，給Hugo靜態網站託管圖片\n白嫖CloudFlare R2搭建个人图床\n","date":"2025年06月20日","externalUrl":null,"permalink":"/zh-tw/posts/cloudflare-r2/","section":"Posts","summary":"\u003cp\u003e因為 Imgur 大約從2025年5月16日開始，無預警地封鎖了來自台灣的 IP，不再允許台灣使用者登入或是上傳圖片等\u0026hellip;動作。所以就想說之後都把圖片改放在 Cloudflare R2 上面。\u003c/p\u003e","title":"Cloudflare R2","type":"posts"},{"content":"","date":"2025年06月20日","externalUrl":null,"permalink":"/zh-tw/tags/cloudflare-r2/","section":"Tags","summary":"","title":"Cloudflare-R2","type":"tags"},{"content":"","date":"2025年06月20日","externalUrl":null,"permalink":"/zh-tw/tags/storage/","section":"Tags","summary":"","title":"Storage","type":"tags"},{"content":"","date":"2025年01月27日","externalUrl":null,"permalink":"/zh-tw/tags/sid/","section":"Tags","summary":"","title":"SID","type":"tags"},{"content":"在 Windows 上 Clone 同份 Image 為多個 VM 上要加入 Domain 時發生的 SID 相同問題與解決方法！\n最近因為需要實驗東西，所以 Clone 同一台的 Image 當作 VM 的基底，但當我需要加入 Domain 時會發生 SID 相同的問題。 根據網路上的文章是說如果需要 Clone VM 使用建議 Clone 前先使用 sysrep 去去除安全性識別碼(SID)等等\u0026hellip;即可解決這問題。 我們可以到 Windows\\System32\\Sysrep 下找到同名工具並使用 使用完之後會重新設定機台的密碼就完成了！！\nReference # clone a windows VM with unique SSID - #2 by chivo243 - Virtualization - Spiceworks Community\n德瑞克：SQL Server 學習筆記: Sysprep 變更SID(Security Identifier)，以 Windows Server 2012 為例\n","date":"2025年01月27日","externalUrl":null,"permalink":"/zh-tw/posts/win-sid-error/","section":"Posts","summary":"\u003cp\u003e在 Windows 上 Clone 同份 Image 為多個 VM 上要加入 Domain 時發生的 SID 相同問題與解決方法！\u003c/p\u003e","title":"Window SID 相同錯誤","type":"posts"},{"content":"","date":"2025年01月27日","externalUrl":null,"permalink":"/zh-tw/categories/windows-server/","section":"Categories","summary":"","title":"Windows Server","type":"categories"},{"content":"","date":"2025年01月26日","externalUrl":null,"permalink":"/zh-tw/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":"Claude Model Context Protocol(MCP)，在 Windows 環境中 Step By Step 安裝步驟！\n環境確認： # Enable Develop Mode Claude Desktop 左上角選項 -\u0026gt; Help -\u0026gt; Enable Develop Mode 按 Enable 之後重啟就能在看到 左上角選項 -\u0026gt; Developer -\u0026gt; Open MCP Log File\n確認 Node.js and Python Env\n版本要求：\nNode.js \u0026gt;= 18 Python \u0026gt;= 3.10 Node：\ninstall node.js or npm # Check Version Command node --version # or npm --version # Check root Path Command where node # or npm root -g # Record the paths returned by the last two commands - you\u0026#39;ll need them later # Ex: C:\\Users\\\u0026lt;UserName\u0026gt;\\AppData\\Roaming\\npm\\node_modules Python：\ninstall python\u0026gt;=3.10 and \u0026ldquo;Add Python to PATH\u0026rdquo; # Check Python Version Command python -V # Show Env Python Version Python 3.12.8 Install Package Managers # 安裝 Python 管理套件 :\nnpm install -g uv Install MCP Servers # 有三種安裝方式 npm(npx), uv, pip\n使用 Global npm 安裝，需要的 Servers\n# Install core servers globally npm install -g @modelcontextprotocol/server-filesystem npm install -g @modelcontextprotocol/server-memory npm install -g @modelcontextprotocol/server-brave-search Python-based Servers\n# Using uvx uvx mcp-server-git # Using pip pip install mcp-server-git python -m mcp_server_git (Windows) Configure Claude Desktop\nClaude 文件位置：%AppData%\\Claude Desktop\\\n創建或修改 Claude Config 文件：claude_desktop_config.json\nConfig 使用以下 json 配置 (請自行替換成你環境中的 Node.js 或 npm 路徑):\n{ \u0026#34;globalShortcut\u0026#34;: \u0026#34;Ctrl+Space\u0026#34;, \u0026#34;mcpServers\u0026#34;: { \u0026#34;sqlite\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;uvx\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;mcp-server-sqlite\u0026#34;, \u0026#34;--db-path\u0026#34;, \u0026#34;C:\\\\Users\\\\YourUsername\\\\test.db\u0026#34;] }, \u0026#34;filesystem\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;-y\u0026#34;, \u0026#34;@modelcontextprotocol/server-filesystem\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Downloads\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Documents\u0026#34;, \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\Desktop\u0026#34; ], \u0026#34;env\u0026#34;: { \u0026#34;DEBUG\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;memory\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;C:\\\\Program Files\\\\nodejs\\\\node.exe\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;C:\\\\Users\\\\\u0026lt;UserName\u0026gt;\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\@modelcontextprotocol\\\\server-memory\\\\dist\\\\index.js\u0026#34; ], \u0026#34;env\u0026#34;: { \u0026#34;DEBUG\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;mcp-installer\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;@anaisbetts/mcp-installer\u0026#34; ] } } } 補充：\nMCP 安裝與資料設定好後重啟 Claude Desktop 開進去因該就有顯示 MCP Tool 因為我們還沒設定好 SQLite 所以會有 Error SQLite 我是用Docker架設所以等等會修改 filesystem 裡的 args 中的 Path 是他能使用到的地方 memory 中的 args 要設定成剛剛 node or npm 的 path 中的 model 位置 SQLite - Docker版 # modelcontextprotocol/servers - sqlite · GitHub\n先把檔案下載下來並執行下列 command：\ndocker build -t mcp/sqlite . docker volume create claude_sqlite 修改 claude_desktop_config.json：\n//claude_desktop_config.json \u0026#34;mcpServers\u0026#34;: { \u0026#34;sqlite\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;run\u0026#34;,\u0026#34;--rm\u0026#34;,\u0026#34;-i\u0026#34;,\u0026#34;-v\u0026#34;,\u0026#34;claude_sqlite:/mcp\u0026#34;,\u0026#34;mcp/sqlite\u0026#34;,\u0026#34;--db-path\u0026#34;,\u0026#34;/mcp/claude_sqlite.db\u0026#34;] }, } 嘗試執行 Claude 使用 MCP： 嘗試叫他幫我找尋 D:\\Project 底下有哪些專案的資料夾 他會先跟你確認要用哪個 MCP Serve 並之後執行 完美的找出 Project 下的資料夾有哪些！！ 之後要使用別的套件基本上也是參照 MCP Server 安裝方式安裝即可使用！ 檢查 MCP Server 錯誤時可以透過 Developer 中的 Open MCP Log File 檢查 Log\nReference # MCP-Windows · GitHub\nmodelcontextprotocol/servers: Model Context Protocol Servers · GitHub\nmodelcontextprotocol.io\n","date":"2025年01月26日","externalUrl":null,"permalink":"/zh-tw/posts/claude_mcp/","section":"Posts","summary":"\u003cp\u003eClaude Model Context Protocol(MCP)，在 Windows 環境中 Step By Step 安裝步驟！\u003c/p\u003e","title":"Claude MCP","type":"posts"},{"content":"","date":"2025年01月26日","externalUrl":null,"permalink":"/zh-tw/tags/mcp/","section":"Tags","summary":"","title":"MCP","type":"tags"},{"content":"","date":"2025年01月26日","externalUrl":null,"permalink":"/zh-tw/tags/tool/","section":"Tags","summary":"","title":"Tool","type":"tags"},{"content":"","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/categories/database/","section":"Categories","summary":"","title":"DataBase","type":"categories"},{"content":"","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/tags/elastic/","section":"Tags","summary":"","title":"Elastic","type":"tags"},{"content":"今天來嘗試使用 Elastic 向量 DB 聽說是有針對資料搜尋特化的一個向量DB，那我們就來試試看吧！！\n我是使用 Docker 來搭建 Service 所以以下範例都是以 Docker 來操作。 我這邊是使用 Single Node 來架設DB，但因為 Elastic 是可以有多節點來作分散式備份等功能有興趣可以參考最下面的參考資料。\n建立環境 # Step1. (Option) Create a new docker network docker network create elastic Step2. docker run elastic 這邊有分有無要在 Elastic 內部使用 LLM 設定因為會有關 Ram 使用的大小 普通建構 無須在內部使用 LLM docker run --name elasticsearch --net elastic -p 9200:9200 -it -m 1GB -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:8.16.1 需使用機器學習功能，例如使用 ELSER 進行語義搜索 需要記憶體超過 1GB 的更大容器。 docker run -d --name elasticsearch --net elastic -p 9200:9200 -m 6GB -it -e \u0026#34;xpack.ml.use_auto_machine_memory_percent=true\u0026#34; -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:8.16.1 補充： 不要啟動 security feature (強制使用https選項) ⇒ \u0026ldquo;xpack.security.enabled=false\u0026rdquo; 設定 single-node ⇒ \u0026ldquo;discovery.type=single-node\u0026rdquo; Step3. Kibana 的 elastic 使用者密碼和註冊令牌 我們在有啟用 security feature 情況下首次登入 elastic (https://0.0.0.0:9200) 是需要輸入帳號密碼的 docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic 就能看到 elastic 重製好的密碼顯示在上面 ❯ docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic WARNING: Owner of file [/usr/share/elasticsearch/config/users] used to be [root], but now is [elasticsearch] WARNING: Owner of file [/usr/share/elasticsearch/config/users_roles] used to be [root], but now is [elasticsearch] This tool will reset the password of the [elastic] user to an autogenerated value. The password will be printed in the console. Please confirm that you would like to continue [y/N]y Password for the [elastic] user successfully reset. New value: 4If*lQS*fXrh3iq_bvnc What\u0026#39;s next: Try Docker Debug for seamless, persistent debugging tools in any container or image → docker debug elasticsearch Learn more at https://docs.docker.com/go/debug-cli/ Step4. docker run kibana (GUI Web) 這邊建立一個官方用來方便管理 Elastic 的 GUI Web Kibana docker run -d --name kibana --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.16.1 之後我們就能到 http://0.0.0.0:5601 看到 Kibana Web 一樣如果有啟用 security feature 情況下首次登入Token Step5. 取得 Kibana Token docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana ❯ docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana eyJ2ZXIiOiI4LjE0LjAiLCJhZHIiOlsiMTcyLjE4LjAuMjo5MjAwIl0sImZnciI6ImJjMjI0N2Q3ODNlY2FjYWQ1Zjc0YzdlN2I4ZjM1YTU4YWMyYjBjZGM4NTI3Mzc5MWM0Yjc4OTVmNjQxMWIyNDUiLCJrZXkiOiJMOGFKZHBNQlRra0lBWHVNTk40Zzpqa3RxQ1Q4U1JHaXRlb25YMExjdm9RIn0= What\u0026#39;s next: Try Docker Debug for seamless, persistent debugging tools in any container or image → docker debug elasticsearch Learn more at https://docs.docker.com/go/debug-cli/ 之後我們就能輸入Token，讓 Kibana 跟 Elastic 連接之後就會看到要輸入認證 Code Step6. 取得認證 Code \u0026gt; docker exec -it kibana /bin/bash \u0026gt; kibana@da057b8cc1fa:~$ bin/kibana-verification-code Kibana is currently running with legacy OpenSSL providers enabled! For details and instructions on how to disable see https://www.elastic.co/guide/en/kibana/8.16/production.html#openssl-legacy-provider Your verification code is: 632 200 kibana@da057b8cc1fa:~$ 手動取消安全安全認證 # 為了之後我們方便開發時連線不用帶金鑰等等…麻煩的設定\nElastic ❯ docker exec -u root -it elasticsearch /bin/bash root@1604ebd3d6d6:/usr/share/elasticsearch# cd config/ root@1604ebd3d6d6:/usr/share/elasticsearch/config# cat elasticsearch.yml cluster.name: \u0026#34;docker-cluster\u0026#34; network.host: 0.0.0.0 #----------------------- BEGIN SECURITY AUTO CONFIGURATION ----------------------- # # The following settings, TLS certificates, and keys have been automatically # generated to configure Elasticsearch security features on 29-11-2024 07:00:36 # # -------------------------------------------------------------------------------- # Enable security features xpack.security.enabled: false xpack.security.enrollment.enabled: true # Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents xpack.security.http.ssl: enabled: false keystore.path: certs/http.p12 # Enable encryption and mutual authentication between cluster nodes xpack.security.transport.ssl: enabled: true verification_mode: certificate keystore.path: certs/transport.p12 truststore.path: certs/transport.p12 #----------------------- END SECURITY AUTO CONFIGURATION ------------------------- root@1604ebd3d6d6:/usr/share/elasticsearch/config# 補充： 這邊是要把 xpack.security.enabled 跟 xpack.security.http.ssl 修改成 false 即可 Kibana ❯ docker exec -u root -it kibana /bin/bash root@7bf3cda51529:/usr/share/kibana# cd config/ root@7bf3cda51529:/usr/share/kibana/config# cat kibana.yml # # ** THIS IS AN AUTO-GENERATED FILE ** # # Default Kibana configuration for docker target server.host: \u0026#34;0.0.0.0\u0026#34; server.shutdownTimeout: \u0026#34;5s\u0026#34; elasticsearch.hosts: [ \u0026#34;http://elasticsearch:9200\u0026#34; ] monitoring.ui.container.elasticsearch.enabled: true root@7bf3cda51529:/usr/share/kibana/config# 補充： elasticsearch.hosts: [ \u0026ldquo;http://elasticsearch:9200\u0026rdquo; ] 這邊的 elasticsearch 是依照你的 elastic 的 container 名去修改(這是因為 DNS指向的關係) , 並且注意要是 http 開頭 停用後頁面會顯示 Could not retrieve current user, security plugin is not ready 不用怕照樣能用 這樣就建立好一個 ElasticSearch 的服務了！！\nReference # [Elasticsearch] 分散式特性 \u0026amp; 分散式搜尋的機制 - 小信豬的原始部落\n","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/posts/elastic/","section":"Posts","summary":"\u003cp\u003e今天來嘗試使用 Elastic 向量 DB 聽說是有針對資料搜尋特化的一個向量DB，那我們就來試試看吧！！\u003c/p\u003e","title":"Elastic 搭建","type":"posts"},{"content":"想說都建立 Elastic 不試試看這 DB 的搜尋效果就不夠意思了吧，就有了這篇 Elastic 搜尋篇\n上次我們建立好了一個基礎的 Elastic 環境，這部份就來試試如何添加資料進 Elastic 並搜尋出來。\n！！注意！！ 以下因為 Elastic 已關閉安全驗證，並且接是使用 Python 去作操作\nNormal Search # 寫入 Data # from elasticsearch import Elasticsearch # 1. 連接到 Elasticsearch es = Elasticsearch(\u0026#34;http://172.20.10.8:9200/\u0026#34;) # 確保 Elasticsearch 在該位址運行 # 2. 建立索引 index_name = \u0026#34;defect_data\u0026#34; mapping = { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;project\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # 新增 keyword 類型 } }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # 新增 keyword 類型 } }, \u0026#34;description\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, \u0026#34;project_title\u0026#34;: { # 組合索引欄位 \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } } if not es.indices.exists(index=index_name): es.indices.create(index=index_name, body=mapping) print(f\u0026#34;Index \u0026#39;{index_name}\u0026#39; created.\u0026#34;) # 3. 插入文件 for key, value in data.items(): title = key description = value document = { \u0026#34;project\u0026#34;: f\u0026#34;{project}\u0026#34;, \u0026#34;title\u0026#34;: f\u0026#34;{title}\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;{description}\u0026#34;, \u0026#34;project_title\u0026#34;: f\u0026#34;{project}|{title}\u0026#34; # 組合索引值 } # 檢查是否在同一個 Project 下有相同的 Title query = { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;project_title\u0026#34;: f\u0026#34;{project}|{title}\u0026#34; } } } search_response = es.search(index=index_name, body=query) if search_response[\u0026#34;hits\u0026#34;][\u0026#34;total\u0026#34;][\u0026#34;value\u0026#34;] == 0: response = es.index(index=index_name, body=document) print(\u0026#34;Document inserted:\u0026#34;, response) else: print(\u0026#34;Document already exists. Skipping insert.\u0026#34;) 查詢 # from elasticsearch import Elasticsearch # 1. 連接到 Elasticsearch es = Elasticsearch(\u0026#34;http://0.0.0.0:9200/\u0026#34;) # 確保 Elasticsearch 在該位址運行 index_name = \u0026#34;defect_data\u0026#34; query = { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;RM\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;] } } } search_response = es.search(index=index_name, body=query) print(len(search_response[\u0026#39;hits\u0026#39;][\u0026#39;hits\u0026#39;])) for hits in search_response[\u0026#39;hits\u0026#39;][\u0026#39;hits\u0026#39;]: print(hits) print(\u0026#34;===================\u0026#34;) Hybrid Search # 此方法是藉由外部啟動 LLM Embedding 所以不用搭建較多 Ram 的 Elastic\n寫入 Data # from elasticsearch import Elasticsearch from sentence_transformers import SentenceTransformer # 初始化 Elasticsearch 客戶端 es = Elasticsearch(\u0026#34;http://0.0.0.0:9200\u0026#34;) model = SentenceTransformer(\u0026#34;Alibaba-NLP/gte-Qwen2-1.5B-instruct\u0026#34;, trust_remote_code=True) # In case you want to reduce the maximum length: model.max_seq_length = 131072 def generate_embedding(text): # 使用 SentenceTransformer 直接生成嵌入 embedding = model.encode(text, convert_to_numpy=True) # 如果需要轉換為列表，使用 tolist() return embedding.tolist() # 定義索引結構，包含 kNN 向量欄位 index_name = \u0026#34;defect_embed_data\u0026#34; index_mapping = { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;project\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # 保留 keyword 用於精確查詢 } }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;} # 保留 keyword 用於精確查詢 } }, \u0026#34;description\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; # 保留 description 作為全文檢索用 }, \u0026#34;project_title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; # 用於組合索引查詢 }, \u0026#34;embedding\u0026#34;: { # 新增 embedding 欄位 \u0026#34;type\u0026#34;: \u0026#34;dense_vector\u0026#34;, \u0026#34;dims\u0026#34;: 1536, # 嵌入向量的維度，需與嵌入模型一致 \u0026#34;similarity\u0026#34;: \u0026#34;cosine\u0026#34; } } } } # 建立索引 if not es.indices.exists(index=index_name): es.indices.create(index=index_name, body=index_mapping) data = [ { \u0026#34;project\u0026#34;: \u0026#34;Login System\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Fix login timeout issue\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Users are experiencing timeouts when logging in.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;Login System - Fix login timeout issue\u0026#34; }, { \u0026#34;project\u0026#34;: \u0026#34;Database\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Database connection failure\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Database connection intermittently fails.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;Database - Connection failure\u0026#34; }, { \u0026#34;project\u0026#34;: \u0026#34;UI\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;UI layout breaks on small screens\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Responsive design issue causing layout to break.\u0026#34;, \u0026#34;project_title\u0026#34;: \u0026#34;UI - Layout issue on small screens\u0026#34; } ] # 匯入資料到 Elasticsearch for record in data: embedding = generate_embedding(record[\u0026#34;title\u0026#34;]) # 生成嵌入向量 record[\u0026#34;embedding\u0026#34;] = embedding # 加入嵌入 es.index(index=index_name, body=record) # 匯入到 Elasticsearch print(\u0026#34;資料匯入完成\u0026#34;) 向量查詢 # # 查詢標題 query_title = \u0026#34;Timeout during login\u0026#34; # 生成查詢向量 query_vector = generate_embedding(query_title) # kNN 搜尋 knn_query = { \u0026#34;size\u0026#34;: 5, # 返回最相似的 5 筆結果 \u0026#34;knn\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;embedding\u0026#34;, \u0026#34;query_vector\u0026#34;: query_vector, \u0026#34;k\u0026#34;: 10, \u0026#34;num_candidates\u0026#34;: 100 }, \u0026#34;_source\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;] # 指定返回的欄位 } # 執行查詢 response = es.search(index=index_name, body=knn_query) # 顯示結果 for hit in response[\u0026#34;hits\u0026#34;][\u0026#34;hits\u0026#34;]: print(f\u0026#34;Title: {hit[\u0026#39;_source\u0026#39;][\u0026#39;title\u0026#39;]}, Score: {hit[\u0026#39;_score\u0026#39;]}\u0026#34;) Hybrid 查詢 # # 構建 Hybrid 查詢 query_text = \u0026#34;Troubleshooting login issues\u0026#34; query_vector = generate_embedding(query_text) # 生成查詢向量 hybrid_query = { \u0026#34;size\u0026#34;: 5, \u0026#34;_source\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;description\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: query_title, \u0026#34;boost\u0026#34;: 1.5 # 可選：提高標題匹配的權重 } } }, { \u0026#34;match\u0026#34;: { \u0026#34;description\u0026#34;: { \u0026#34;query\u0026#34;: query_title, \u0026#34;boost\u0026#34;: 1.0 } } }, { \u0026#34;script_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;exists\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;embedding\u0026#34; # 確保文檔有 embedding 欄位 } }, \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;cosineSimilarity(params.query_vector, \u0026#39;embedding\u0026#39;) + 1.0\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;query_vector\u0026#34;: query_vector } }, \u0026#34;boost\u0026#34;: 0.5 # 向量相似性的權重 } } ], \u0026#34;minimum_should_match\u0026#34;: 1 } } } 補充： 如果是要對全文件向量搜尋 script_score 可以改成以下\n# 匹配所有文檔的查詢 \u0026#34;script_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, 總結：\n普通搜尋： Elastic 先把句子把你的字詞記下地理位置，之後搜尋時依照你輸入的詞彙去對應地址去搜尋大致相對應地理位置的DB中的句子，並使用 BM25 方式區對你的句子去搜尋，依照出現的頻率去計算平均出現機率。 向量搜尋： 是依照句子轉換成向量之後去使用 歐氏距離 與 餘弦相似度 去搜尋相似度。 混合搜尋： 透過你設定普通搜尋會有分數，向量搜尋也會有分數，之後透過 script_score 的計算方式去計算出你的混合分數。 Reference # 密集向量欄位類型 - elastic 中文\n","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/posts/hybrid-search/","section":"Posts","summary":"\u003cp\u003e想說都建立 Elastic 不試試看這 DB 的搜尋效果就不夠意思了吧，就有了這篇 Elastic 搜尋篇\u003c/p\u003e","title":"Hybrid Search","type":"posts"},{"content":"","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/tags/rag/","section":"Tags","summary":"","title":"RAG","type":"tags"},{"content":"","date":"2024年12月05日","externalUrl":null,"permalink":"/zh-tw/tags/vectordb/","section":"Tags","summary":"","title":"VectorDB","type":"tags"},{"content":"","date":"2024年11月11日","externalUrl":null,"permalink":"/zh-tw/categories/environment/","section":"Categories","summary":"","title":"Environment","type":"categories"},{"content":"","date":"2024年11月11日","externalUrl":null,"permalink":"/zh-tw/tags/gpu/","section":"Tags","summary":"","title":"GPU","type":"tags"},{"content":"","date":"2024年11月11日","externalUrl":null,"permalink":"/zh-tw/tags/nvdia/","section":"Tags","summary":"","title":"NVDIA","type":"tags"},{"content":"因為Nvidia驅動每次都會莫名其妙不見，然後又要重裝套件，紀錄一下如何完整的移除驅動與套件。\n查看是否有 nvidia 驅動： dpkg -l | grep -i nvidia 移除nvidia-cuda-toolkit驅動： 只移除nvidia-cuda-toolkit驅動 sudo apt-get remove nvidia-cuda-toolkit 移除nvidia-cuda-toolkit及其依賴套件 sudo apt-get remove --auto-remove nvidia-cuda-toolkit 移除 nvidia-cuda-toolkit與其依賴套件跟環境配置： sudo apt-get purge --auto-remove nvidia-cuda-toolkit 移除所有關於cuda的内容： sudo apt-get --purge -y remove \u0026#39;cuda*\u0026#39; # cuda10.1及以上的卸载 cd /usr/local/cuda-xx.x/bin/ sudo ./cuda-uninstaller sudo rm -rf /usr/local/cuda-xx.x 移除所有關於nvidia的内容： sudo apt-get --purge -y remove \u0026#39;nvidia*\u0026#39; 檢查cuda的文件夾是否還存在： ls /usr/local/ | grep cuda Reboot： sudo reboot 查看是否有 cudnn 驅動： dpkg -l | grep cudnn 移除 cudnn 驅動： 移除剛剛查詢到系统中存在的cudnn套件, command 以 cudnn8 為例 sudo dpkg --remove libcudnn8 libcudnn8-dev libcudnn9-samples Reference # Ubuntu下完全移除cuda和nvidia驱动并重新安装新版本cuda_ubuntu卸载cuda toolkit-CSDN博客\n","date":"2024年11月11日","externalUrl":null,"permalink":"/zh-tw/posts/nvdriver-rm/","section":"Posts","summary":"\u003cp\u003e因為Nvidia驅動每次都會莫名其妙不見，然後又要重裝套件，紀錄一下如何完整的移除驅動與套件。\u003c/p\u003e","title":"移除 Nvidia 驅動與 CUDA 套件","type":"posts"},{"content":"最近在寫 Python 想說把一些 Model 匯聚成一個 Package 使用時，突然發現好像沒有一個像 Next.js 那種建立一個初始化 Templates 的工具，然後我就找到了這個。\nCookiecutter # GitHub：Cookiecutter - GitHub\nInstallation：\npip install cookiecutter 之後就是找到你需要用的 Template： cookiecutter.io\nCookiecutter: 更好的项目模板工具 简介及可用资源汇总 - 博客園\n找到之後下載並使用，例如我找到的這個 cookiecutter-pypackage：\ncookiecutter https://github.com/audreyfeldroy/cookiecutter-pypackage.git Reference # Cookiecutter - GitHub\ncookiecutter.io\nCookiecutter: 更好的项目模板工具 简介及可用资源汇总 - 博客園\n","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/posts/cookiecutter/","section":"Posts","summary":"\u003cp\u003e最近在寫 Python 想說把一些 Model 匯聚成一個 Package 使用時，突然發現好像沒有一個像 Next.js 那種建立一個初始化 Templates 的工具，然後我就找到了這個。\u003c/p\u003e","title":"Cookiecutter","type":"posts"},{"content":"","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/categories/python/","section":"Categories","summary":"","title":"Python","type":"categories"},{"content":"","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/tags/conda/","section":"Tags","summary":"","title":"Conda","type":"tags"},{"content":"某次因 Server 上需先掛 Proxy 後才能上網導致 Python 安裝套件過程中需要設定 Proxy 才能下載套件紀錄。\nConda and Pip Proxy Setting # Conda Proxy Setting # conda config --set proxy_servers.http http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; conda config --set proxy_servers.https http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; Pip Proxy Setting # pip config set global.proxy http://\u0026lt;account\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;IP\u0026gt;:\u0026lt;Port\u0026gt; Writing to /root/.config/pip/pip ","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/posts/pypi_proxy/","section":"Posts","summary":"\u003cp\u003e某次因 Server 上需先掛 Proxy 後才能上網導致 Python 安裝套件過程中需要設定 Proxy 才能下載套件紀錄。\u003c/p\u003e","title":"Conda \u0026 Pip Proxy 設定","type":"posts"},{"content":"","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/tags/pip/","section":"Tags","summary":"","title":"Pip","type":"tags"},{"content":"","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/tags/proxy/","section":"Tags","summary":"","title":"Proxy","type":"tags"},{"content":"","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/tags/testlink/","section":"Tags","summary":"","title":"TestLink","type":"tags"},{"content":"本文講述當初剛使用 TestLink 時想透過 TestLink 的 API 去互動時遇到的問題並解決的紀錄！！\n當初在使用 TestLink API 時有報 xmlrpc 的錯誤所以來記錄一下解決方法 使用 Docker 或是 使用 Local 安裝 TestLink 要使用 TestLink 本身的 API 時需要開啟幾個設定! 用 Local 安裝 TestLink 在安裝的地方下因該也能找到這兩個檔案 下面是以 Docker 來示範︰\n修改 config.inc.php 檔案位置︰/opt/bitnami/testlink 修改檔案裡的 config $tlCfg-\u0026gt;exec_cfg-\u0026gt;enable_test_automation = ENABLED; $tlCfg-\u0026gt;api-\u0026gt;enabled = TRUE; 修改 xmlrpc.php 檔案位置︰/opt/bitnami/testlink/lib/api/xmlrpc/v1 修改並添加到檔案底下 require_once(\u0026#34;xmlrpc.class.php\u0026#34;); define(\u0026#39;XMLRPC_REQUEST\u0026#39;, true); // Some browser-embedded clients send cookies. We don\u0026#39;t want them.` `$_COOKIE = array(); $GLOBALS[\u0026#39;HTTP_RAW_POST_DATA\u0026#39;] = file_get_contents(\u0026#34;php://input\u0026#34;);` $XMLRPCServer = new TestlinkXMLRPCServer(); 這樣設定完之後就能使用 TestLink 的 API 進行對 TestLink 操作了!!\nReference # java - TestLink XML-RPC The call to the xml-rpc client failed - Stack Overflow\nTestLink 1.8.5: How to configure TestLink to enable XMLRPC - TestLink\ntestlink-code/lib/api/xmlrpc/v1/xmlrpc.class.php at testlink_1_9 · TestLinkOpenSourceTRMS/testlink-code · GitHub\n","date":"2024年09月12日","externalUrl":null,"permalink":"/zh-tw/posts/testlink-api-enabled/","section":"Posts","summary":"\u003cp\u003e本文講述當初剛使用 TestLink 時想透過 TestLink 的 API 去互動時遇到的問題並解決的紀錄！！\u003c/p\u003e","title":"Testlink Api Enabled","type":"posts"},{"content":"","date":"2024年09月11日","externalUrl":null,"permalink":"/zh-tw/tags/a100/","section":"Tags","summary":"","title":"A100","type":"tags"},{"content":"剛好有幸用到 8 Core 80G GPU 的 A100 機台，但以為設定跟之前一樣卻要用 CUDA 跑 LLM 時遇到問題並紀錄解決方法。\n當你今天是使用 ( V100 / A100 / A30 \u0026hellip;等等 ) 時因為是使用 NVSwitch 連通所以需要安裝 3 以後的步驟才能正常使用 NVIDA GPU 的功能\nInstall CUDA\nFollow: CUDA Toolkit 12.6 Downloads | NVIDIA Developer\nBase Installer:\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda-repo-ubuntu2204-12-6-local_12.6.0-560.28.03-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-6-local_12.6.0-560.28.03-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-6 Driver Installer:\nsudo apt-get install -y nvidia-open Setting NVCC: Command 中的 cuda-12 請依照你安裝的版本去替換 sudo vim ~/.bashrc export PATH=/usr/local/cuda-12/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-12/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} Install cuDNN\nFollow: cuDNN 9.3.0 Downloads | NVIDIA Developer\nBase Installer:\nwget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2204-9.3.0/cudnn-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cudnn If install specific CUDA version package:\nsudo apt-get -y install cudnn-cuda-\u0026lt;CUDA-Version\u0026gt; Install libfreeimage:\nsudo apt install libfreeimage-dev Test cuDNN:\ngit clone https://github.com/NVIDIA/cuda-samples.git cd cuda-samples/Samples/bandwidthTest make ./bandwidthTest 如果失敗請安裝接下來的步驟\nInstall DCGM\nFollow: NVIDIA DCGM | NVIDIA Developer\nsudo apt-get update sudo apt-get install -y datacenter-gpu-manager Install nvidia-fabricmanager\nFollow: fabric-manager-user-guide.pdf (nvidia.com) - Chapter 2.6\nversion=\u0026lt;your-gpu-Driver Version\u0026gt; main_version=$(echo $version | awk -F \u0026#39;.\u0026#39; \u0026#39;{print $1}\u0026#39;) apt-get update apt-get -y install nvidia-fabricmanager-${main_version}=${version}-* Nvidia-smi: +-----------------------------------------------------------------------------------------+ | NVIDIA-SMI 560.35.03 Driver Version: 560.35.03 CUDA Version: 12.6 | |-----------------------------------------+------------------------+----------------------+ 以此為例 version = 560.35.03 Disabel nv-hostengine\nsudo nv-hostengine -t Start the fabricmanager\nsudo service nvidia-fabricmanager start Test cuDNN again\ngit clone https://github.com/NVIDIA/cuda-samples.git cd cuda-samples/Samples/bandwidthTest make ./bandwidthT root@test-ORACLE-SERVER-E4-2c:~/cudnn_samples_v9/mnistCUDNN# ./mnistCUDNN Executing: mnistCUDNN cudnnGetVersion() : 90400 , CUDNN_VERSION from cudnn.h : 90400 (9.4.0) Host compiler version : GCC 11.4.0 There are 8 CUDA capable devices on your machine : device 0 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=0 device 1 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=1 device 2 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=2 device 3 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=3 device 4 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=4 device 5 : sms 108 Capabilities 8.0, SmClok 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=5 device 6 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=6 device 7 : sms 108 Capabilities 8.0, SmClock 1410.0 Mhz, MemSize (Mb) 81155, MemClock 1593.0 Mhz, Ecc=1, boardGroupID=7 Using device 0 Testing single precision Loading binary file data/conv1.bin Loading binary file data/conv1.bias.bin Loading binary file data/conv2.bin Loading binary file data/conv2.bias.bin Loading binary file data/ip1.bin Loading binary file data/ip1.bias.bin Loading binary file data/ip2.bin Loading binary file data/ip2.bias.bin Loading image data/one_28x28.pgm Performing forward propagation ... Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.027648 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.036864 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.062464 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.070656 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.091136 time requiring 2057744 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.092160 time requiring 184784 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 129072 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.055296 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.064512 time requiring 1433120 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.090112 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.093184 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.098304 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.189440 time requiring 129072 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Resulting weights from Softmax: 0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 Loading image data/three_28x28.pgm Performing forward propagation ... Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.023552 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.026624 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.028672 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.057344 time requiring 184784 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.057344 time requiring 178432 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.064512 time requiring 2057744 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnGetConvolutionForwardAlgorithm_v7 ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 129072 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Testing cudnnFindConvolutionForwardAlgorithm ... ^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.053248 time requiring 2450080 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.055296 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.063488 time requiring 1433120 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.064512 time requiring 4656640 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.092160 time requiring 0 memory ^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.102400 time requiring 129072 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory ^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory Resulting weights from Softmax: 0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 Loading image data/five_28x28.pgm Performing forward propagation ... Resulting weights from Softmax: 0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5 Test passed! 看到 Test passed 恭喜你成功可以正常使用 GPU 了!!\n補充： # NVLink Topology Command：\nnvidia-smi topo -m NVLink Status Command：\nnvidia-smi nvlink --status 更多相關 Nvidia-smi 查看 Nvlink Command： nvidia-smi 工具检查NVIDIA NVLink - Docs\nReference # cuda runtime error (802) : system not yet initialized \u0026hellip;/THCGeneral.cpp:50 · Issue #35710 · pytorch/pytorch · GitHub\nHow to Configure NVLink on Machines - digitalocean\n","date":"2024年09月11日","externalUrl":null,"permalink":"/zh-tw/posts/nvidia-a100_env/","section":"Posts","summary":"\u003cp\u003e剛好有幸用到 8 Core 80G GPU 的 A100 機台，但以為設定跟之前一樣卻要用 CUDA 跑 LLM 時遇到問題並紀錄解決方法。\u003c/p\u003e","title":"Nvidia A100 環境設定","type":"posts"},{"content":"","date":"2024年06月09日","externalUrl":null,"permalink":"/zh-tw/tags/chroma/","section":"Tags","summary":"","title":"Chroma","type":"tags"},{"content":"","date":"2024年06月09日","externalUrl":null,"permalink":"/zh-tw/tags/langchain/","section":"Tags","summary":"","title":"LangChain","type":"tags"},{"content":"","date":"2024年06月09日","externalUrl":null,"permalink":"/zh-tw/tags/llama.cpp/","section":"Tags","summary":"","title":"Llama.cpp","type":"tags"},{"content":"此文紀錄使用 LLama3 + Langchain + llamacpp + Chroma 組合成一個簡單的 RAG !\n整體 RAG 架構圖： 先讀入我們補充的資料 利用語言模型幫我們做 Embedding 幫我們的字串分析並轉成向量 把轉換後的向量存去向量資料庫 利用 LangChain 的 Library 內的 LLamaCpp 啟動我們的 LLama3 模型 我們就能輸入問題 拿到問題後他會嘗試去資料庫找相似的答案 經由 LLama3 回答問題 Code：\nimport os import sys import time import chromadb from dotenv import load_dotenv from langchain.chains import ConversationalRetrievalChain from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter from langchain_community.document_loaders import PyPDFLoader from langchain_community.document_loaders import Docx2txtLoader from langchain_community.document_loaders import TextLoader from langchain_community.vectorstores import Chroma from langchain.embeddings import HuggingFaceEmbeddings from langchain.callbacks.manager import CallbackManager from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler from langchain_community.llms import LlamaCpp from langchain.chains import RetrievalQA from langchain.chains import LLMChain from langchain.prompts import PromptTemplate # 讀取資料 pdf, docs, docx, txt ... documents = [] # Create a List of Documents from all of our files in the ./docs folder for file in os.listdir(\u0026#34;docs\u0026#34;): print(f\u0026#39;Now Load：{file}\u0026#39;) if file.endswith(\u0026#34;.pdf\u0026#34;): pdf_path = \u0026#34;./docs/\u0026#34; + file loader = PyPDFLoader(pdf_path) documents.extend(loader.load()) elif file.endswith(\u0026#39;.docx\u0026#39;) or file.endswith(\u0026#39;.doc\u0026#39;): doc_path = \u0026#34;./docs/\u0026#34; + file loader = Docx2txtLoader(doc_path) documents.extend(loader.load()) elif file.endswith(\u0026#39;.txt\u0026#39;): text_path = \u0026#34;./docs/\u0026#34; + file loader = TextLoader(text_path) documents.extend(loader.load()) # 讀取並切割字串 (RecursiveCharacterTextSplitter 這一段有3種不同的切割方式有興趣的同學可以自己去看一下 Langchain 的 library) start_time = time.time() # Split the documents into smaller chunks text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50) documents = text_splitter.split_documents(documents) end_time = time.time() splitter_time = end_time-start_time # 把剛剛切割的字串使用 ntfloat/multilingual-e5-large-instruct 模型去作 Embedding ,我這邊是選擇用 CPU 可以用 GPU 會比較快 start_time = time.time() # Embedding Sentence-transformer Model model_name = \u0026#39;intfloat/multilingual-e5-large-instruct\u0026#39; model_kwargs = {\u0026#39;device\u0026#39;: \u0026#39;cpu\u0026#39;} embedding = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs) end_time = time.time() embedding_time = end_time-start_time # 把轉好的資料放到 Chroma DB 裡,這邊是使用簡易版直接放到 memory 中 start_time = time.time() # setup Chroma in-memory, for easy prototyping. Can add persistence easily! client = chromadb.Client() # Create collection. get_collection, get_or_create_collection, delete_collection also available! collection = client.create_collection(\u0026#34;all-my-documents\u0026#34;) persist_directory = Chroma(client=client, collection_name=\u0026#34;all-my-documents\u0026#34;) # Convert the document chunks to embedding and save them to the vector store vectordb = Chroma.from_documents(documents, embedding=embedding, persist_directory=persist_directory) vectordb.persist() end_time = time.time() vectordb_time = end_time-start_time # 啟用 LLama3 並使用 LLamaCpp 一樣可以設定參數 # Main LLM llm = LlamaCpp( model_path=\u0026#34;/root/LLM-models/Llama3-8B-Chinese-Chat-q8_0-v2_1.gguf\u0026#34;, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=False, n_gpu_layers=100, n_batch=1600, n_ctx=8000, f16_kv=False, temperature=0.7, use_mlock=True, use_mmap=True, vocab_only=False, ) # 設定 模版 等等... 並設定會去 DB 找再回傳給 LLama3 回答 # With Langchain Model # This controls how the standalone question is generated. # Should take `chat_history` and `question` as input variables. template = ( \u0026#34;Combine the chat history and follow up question into \u0026#34; \u0026#34;a standalone question. Chat History: {chat_history}\u0026#34; \u0026#34;Follow up question: {question}\u0026#34; ) prompt = PromptTemplate.from_template(template) # create our Q\u0026amp;A chain pdf_qa = ConversationalRetrievalChain.from_llm( llm=llm, condense_question_prompt=prompt, retriever=vectordb.as_retriever(search_kwargs={\u0026#39;k\u0026#39;: 6}), return_source_documents=True, verbose=False, ) # 原版模型用來跟有 LangChain 來比對回答 # Original Model template = \u0026#34;\u0026#34;\u0026#34; Question: {question} Answer: \u0026#34;\u0026#34;\u0026#34; prompt = PromptTemplate(template=template, input_variables=[\u0026#34;question\u0026#34;]) # Create an LLMChain to manage interactions with the prompt and model Ollm = LLMChain(prompt=prompt, llm=llm) yellow = \u0026#34;\\033[0;33m\u0026#34; green = \u0026#34;\\033[0;32m\u0026#34; white = \u0026#34;\\033[0;39m\u0026#34; chat_history = [] print(f\u0026#34;{yellow}---------------------------------------------------------------------------------\u0026#34;) print(f\u0026#39;Init Time：\u0026#39;) print(f\u0026#39;Splitter_Time：{splitter_time} seconds\u0026#39;) print(f\u0026#39;Embedding_Time：{embedding_time} seconds\u0026#39;) print(f\u0026#39;Vectordb_Time：{vectordb_time} seconds\u0026#39;) print(\u0026#39;Welcome to the DocBot. You are now ready to start interacting with your documents\u0026#39;) print(\u0026#39;---------------------------------------------------------------------------------\u0026#39;) while True: query = input(f\u0026#34;{green}Prompt: \u0026#34;) if query == \u0026#34;exit\u0026#34; or query == \u0026#34;quit\u0026#34; or query == \u0026#34;q\u0026#34; or query == \u0026#34;f\u0026#34;: print(\u0026#39;Exiting\u0026#39;) sys.exit() if query == \u0026#39;\u0026#39;: continue # 有搭配找尋 chroma DB 在回答的 LLama3 回答 result = pdf_qa.invoke( {\u0026#34;question\u0026#34;: query, \u0026#34;chat_history\u0026#34;: chat_history}) print(f\u0026#34;{white}Answer: \u0026#34; + result[\u0026#34;answer\u0026#34;]) print(\u0026#34;=====================================================\u0026#34;) # 原版 LLama3 回答 Ollm_answer = Ollm.invoke(query) print(Ollm_answer, \u0026#39;\\n\u0026#39;) print(\u0026#34;=====================================================\u0026#34;) # 紀錄功能 #chat_history.append((query, result[\u0026#34;answer\u0026#34;])) 最後就能實作出簡單的 RAG 了簡單吧！！ 有興趣的同學還能串接網頁搜尋的 API 不過我看都要錢所以我就沒接了QQ\nReference # RAG實作教學，LangChain + Llama2 |創造你的個人LLM\n用筆電就能跑 LLaMA ! llama.cpp 教學\n","date":"2024年06月09日","externalUrl":null,"permalink":"/zh-tw/posts/langchain2rag/","section":"Posts","summary":"\u003cp\u003e此文紀錄使用 LLama3 + Langchain + llamacpp + Chroma 組合成一個簡單的 RAG !\u003c/p\u003e","title":"用 LangChain 實作出簡易版 RAG","type":"posts"},{"content":"","date":"2024年06月08日","externalUrl":null,"permalink":"/zh-tw/tags/ollama/","section":"Tags","summary":"","title":"Ollama","type":"tags"},{"content":"這邊紀錄從 Ollama github 上的 Modefile 紀錄有哪些可以修改的參數。\nOllama Modelfile： # Modelfile 內指令參數：\nFROM : (必填) 定义要使用的基本模型。 PARAMETER\t: 设置 Ollama 如何运行模型的参数。 TEMPLATE\t: 要发送到模型的完整提示模板。 SYSTEM\t: 指定将在模板中设置的系统消息。 ADAPTER\t: 定义要应用于模型的 （Q）LoRA 适配器。 LICENSE\t: 指定合法许可证。 MESSAGE\t: 指定消息历史记录。 Base model specification # FROM： Defines the base model to use for creating your customized model. 定義一個 model , 去所建立客製化 model\nModel parameters # PARAMETER mirostat [0/1/2]： Enable Mirostat sampling for perplexity control. 0=disabled, 1=Mirostat, 2=Mirostat 2.0. Mirostat值：可以有效避免出現過度重複或不連貫的内容 預設:0 , 0 是不使用 , 1是Mirostat , 2是Mirostat2.0\nPARAMETER mirostat_eta [float]： Learning rate for Mirostat. Default=0.1. Adjusts algorithm responsiveness. mirostat_eta值：影響算法對生成文本反應的響應速度，從而影響生成文本的質量和特徵。 較低的值調整速度較慢，較高的值使算法更具影響性，對於需要快速迭代或調整模型輸出的場景非常有用。 ; 預設:0.1\nPARAMETER mirostat_tau [float]： Balance between coherence and diversity. Default=5.0. Lower values = more focused text. mirostat_tau：可以控制生成文本的連貫性和多樣性之間的平衡,從而影響文本的重複性和連貫性等重要属性。 較低的值可以更加集中和連貫，較高的值則會增加輸出的多樣性。預設:5.0\nPARAMETER num_ctx [int]： Context window size. Default=2048. Controls tokens used for generating the next token. num_ctx：這個參數用於設置上下文 token 的數量。它决定了模型在生成響應時可以考慮的上下文長度。預設:2048\nPARAMETER num_gqa [int]： Number of GQA groups in the transformer layer. Required for some models, e.g., 8 for llama2:70b. num_gqa：可以控制模型同時處理的任務數量，從而最佳化模型的性能和效率，設定 Transformer 層中 GQA 组的數量。某些模型需要，例如 llama2:70b 為 8\nPARAMETER num_gpu [int]： Number of layers to send to the GPU(s). macOS default：1 for metal support. num_gpu：設置模型在推理時使用的 GPU layers 數量。預設：1，禁用：0\nPARAMETER num_thread [int]： Number of threads for computation. Recommended: number of physical CPU cores. num_thread：設置模型在推理時使用的 CPU 線程數量。 Ollama 將檢測到這一點以獲得最佳性能。建議將此值設置為系統具有的物理 CPU 核心數（而不是邏輯核心數）。\nPARAMETER repeat_last_n [int]： Lookback distance to prevent repetition. Default=64, 0=disabled, -1=num_ctx. repeat_last_n：模型在生成文本時檢測和懲罰重複 n-gram 的\u0026quot;數量\u0026quot;。告訴模型在嘗試不重複最后一部分對話時應該考慮的 token 數量。 簡單來說就是 控制模型在生成文本時避免重複前 n-gram 的 token 出現,從而提高文本的多樣性和質量。 預設：64，禁用：0，-1=num_ctx\nPARAMETER repeat_penalty [float]： Penalty for repetitions. Higher values penalize more. Default: 1.1. repeat_penalty：設置模型在生成文本時對重複 n-gram 的懲罰\u0026quot;程度\u0026quot;。 可以控制模型對重複 n-gram 的懲罰力度,從而影響生成文本的流暢性和連貫性。 較高的值（例如，1.5）將更強烈的懲罰重複，而較低的值（例如，0.9）將更寬鬆。預設:1.1\nPARAMETER temperature [float]： Model creativity vs coherence. Higher values = more creative. Default=0.8. temperature：參數可以影響生成文本的多樣性,值越\u0026quot;高\u0026quot;生成的文本越具有創造性和變化性,值越\u0026quot;低\u0026quot;生成的文本越趨向於保守和穩定。預設:0.8\nPARAMETER seed [int]： Random seed for generation consistency. Default=0. seed：通過設定固定的種子值，可以確保每次運行相同的模型和相同的輸入時，得到的輸出是一致的。 預設：0\nPARAMETER stop \u0026ldquo;[string]\u0026quot;： Stop sequences for generation end. Multiple stops possible with separate parameters. stop：設置要使用的停止文字。當遇到這種模式時，LLM 將停止生成文本並返回。 可以通過 stop 在模型文件中指定\u0026quot;多個\u0026quot;單獨的參數来設置多個停止模式。\nPARAMETER tfs_z [float]： Tail free sampling for reducing less probable tokens\u0026rsquo; impact. Default=1, \u0026gt;1 reduces impact more. tfs_z：通過調整 tfs_z(尾自由採樣) 的影響力度来影響模型輸出的多樣性和連貫性。 當 tfs_z 值較高（例如，2.0）時，它會減少不太可能的 token 的影響力，從而使輸出更加多樣化。 相反，當 tfs_z 值為 1.0 時，這個設置被禁用，意味著尾自由采样的影響力度為最低，模型輸出的多樣性和連貫性可能會受到影響。 預設:1.0\nPARAMETER num_predict [int]： Max tokens to predict. Default=128, -1=infinite generation, -2=fill context. num_predict：參數代表了在生成文本时模型預測的最大 token 數量。這個參數的功能主要是控制文本生成的過程中模型的輸出長度。 較小的 num_predict 值可以提高生成效率,但可能會限制模型生成更豐富的文本。較大的 num_predict 值則可以讓模型生成更長更複雜的文本,但可能會降低生成速度。預設:128, 無限制：-1 (模型無限制地生成文本,直到遇到停止標記), 填充上下文：-2 (會根據給定的上下文生成文本，而不會生成新的令牌)\nPARAMETER top_k [int]： Limits nonsense generation. Higher values = more diverse answers. Default=40. top_k: 參數用於控制模型在生成文本時考慮的候選 token 數量。 較高的值（例如 100）將給出更多樣化的答案，而較低的值（例如 10）將更加保守。預設:40 (取前40個)\nPARAMETER top_p [float]： Works with top-k for output diversity. Higher values = more diversity. Default=0.9. top_p: 值會讓模型考慮累計概率較高的 token 。 較高的值（例如，0.95）將導致更加多樣化的文本，而較低的值（例如，0.5）將生成更加集中和保守的文本。預設：0.9 (代表取權重前90%的)\nPrompt template # TEMPLATE \u0026quot;\u0026rdquo;\u0026quot; \u0026hellip; \u0026ldquo;\u0026quot;\u0026quot;： Full prompt template including optional system message, user\u0026rsquo;s message, and the model\u0026rsquo;s response. TEMPLATE：該參數用於定義模型的模板或系统提示，控制模型在生成文本時的輸出結構和風格。 例如，可以使用 TEMPLATE 參數来指定模型在生成文本時是否包含系统提示、用户提示、模型響應等信息。 控制模型生成文本的整體結構和格式。 (使用 Go 語法格式) Example:\n| Variable | Description | | {{ .System }} | The system message used to specify custom behavior. 用於設定自訂義行為| | {{ .Prompt }} | The user prompt message. 使用者提示消息| | {{ .Response }} | The response from the model. When generating a response, text after this variable is omitted. 模型生成的回复。在生成回复时，此变量后的文本将被省略。| TEMPLATE \u0026#34;\u0026#34;\u0026#34;{{ if .System }}system {{ .System }} {{ end }}{{ if .Prompt }}user {{ .Prompt }} {{ end }}assistant \u0026#34;\u0026#34;\u0026#34; System message # SYSTEM \u0026ldquo;\u0026rdquo;\u0026quot;[system message]\u0026rdquo;\u0026quot;\u0026quot;： Custom system message specifying chat assistant behavior. SYSTEM：參數的主要功能是為模型提供一個初始的對話上下文。 通過設置 SYSTEM 參數，開發者可以控制模型在開始生成文本之前，系统消息的内容。 簡單來說就是開始回答前先跟它講是現在是哪種身分與設定，影響模型生成文本的風格和内容。\nExample：\nSYSTEM \u0026#34;\u0026#34;\u0026#34;You are a helpful medicine assistant.\u0026#34;\u0026#34;\u0026#34; LoRA adapter # ADAPTER： Specifies the LoRA adapter to apply. Path relative to the Modelfile or absolute. ADAPTER: 指定要應用於基礎模型的 (Q)LoRA 檔案。 必須采用 GGML 文件格式。 Example：\nADAPTER ./ollama-lora.bin License # LICENSE： Legal license under which the model is shared or distributed. LICENSE：此模型分享與合法授權遵守的 License 規則。 Example：\nLICENSE \u0026#34;\u0026#34;\u0026#34; \u0026lt;license text\u0026gt; \u0026#34;\u0026#34;\u0026#34; Message # MESSAGE [role] [message]： Sets up a predefined message history for the model to consider when generating responses, helping to provide context or guide the model\u0026rsquo;s outputs. MESSAGE：指令允許您為模型指定消息歷史紀錄，以便在響應時使用。使用多個 MESSAGE 命令的迭代来建構對話，這將引導模型以類似的方式回答。 Example:\n| Variable | Description | | system | Alternate way of providing the SYSTEM message for the model. 为模型提供系统消息的替代方式。| | user | An example message of what the user could have asked. 用户可能会提出的示例消息。| | assistant | An example message of how the model should respond. 模型应该如何回应的示例消息。| MESSAGE user Is Toronto in Canada? MESSAGE assistant yes ... 筆記： # temperature, top_k, top_p 3者相關性：\ntemperature：擷取 prompt 中的 token。 top_k：從 tokens 里選擇 k 個作為候選，然后根据它們的 likelihood scores 来採樣。 top_p：從 tokens 里按百分比選擇候選詞。 順序：temperature 整體參數取樣 =\u0026gt; top_k 取樣前n個重新賦予權重排名 =\u0026gt; top_p 取前 n% 來使用 Reference # 翻譯與找資料：perplexity.ai and phind.ai\n基于Ollama定制自己的大语言模型 - 53ai\n上百大语言模型快速部署调用工具 Ollama使用指南\nOllama GitHub - Modefile\nOllama GitHub - Modefile\nOllama GitHub - import 自定义大型语言模型-使用OLLAMA和Modelfile定制、运行和保存LLM - 知乎\n閱讀文章：\npromptingguide.ai\nlearnprompting.org\nGitHub：\nOllama - GitHub\n","date":"2024年06月08日","externalUrl":null,"permalink":"/zh-tw/posts/ollama-modefile/","section":"Posts","summary":"\u003cp\u003e這邊紀錄從 Ollama github 上的 Modefile 紀錄有哪些可以修改的參數。\u003c/p\u003e","title":"Ollama Modefile 可調參數紀錄","type":"posts"},{"content":"此文章介紹如何從安裝 Nvidia 驅動到從 HuggingFace 下載的 LLM Model 使用 Ollama 啟動 LLM 並使用 OpenWeb ui 進行溝通的部署過程紀錄。\n整體流程：\nLLM Model(HugingFace) =\u0026gt; Download .gguf model =\u0026gt; Ollama (backend run) =\u0026gt; OpenWeb ui (forten Web) 環境安裝：\n禁用 nouveau 驅動\n# 在 /etc/modprobe.d/blacklist-nouveau.conf 檔案中加入下方兩行字 # blacklist nouveau # options nouveau modeset=0 echo \u0026#34;blacklist nouveau\u0026#34; | sudo tee /etc/modprobe.d/blacklist-nouveau.conf \u0026amp;\u0026amp; echo \u0026#34;options nouveau modeset=0\u0026#34; | sudo tee -a /etc/modprobe.d/blacklist-nouveau.conf # 更新 kernel initramfs sudo update-initramfs -u # 重開機 reboot # 執行後，沒有出現任何訊息，就表示成功禁用 nouveau 驅動 lsmod | grep nouveau # 也可以使用以下指令檢查一下 configuration 是否還有 nouveau 文字 sudo lshw -numeric -C display Ref: How to disable Nouveau kernel driver - askubuntu\napt-install tool\nsudo apt-get update sudo apt-get install libc-dev -y sudo apt-get install linux-headers-$(uname -r) -y sudo apt-get install ubuntu-drivers-common install nvidia-CUDA-Toolkit\n解安裝舊 NVIDIA 驅動： sudo apt-get --purge remove nvidia* sudo apt-get --purge remove libnvidia* Base Installer： wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-4 Driver Installer： sudo apt-get install -y cuda-drivers Follower：Nvidia cuda 官方安裝網頁\n補充：\nCheck Nvidia Version: modinfo nvidia|grep version setting nvcc env bashrc and check nvcc\nsudo nano ~/.bashrc # 加在最下面 export PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/lib64:$LD_LIBRARY_PATH\u0026#34; source ~/.bashrc nvcc --version install cuDNN\nwget https://developer.download.nvidia.com/compute/cudnn/9.1.0/local_installers/cudnn-local-repo-ubuntu2204-9.1.0_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2204-9.1.0_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2204-9.1.0/cudnn-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cudnn Get:1 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-cuda-12 9.1.0.70-1 [439 MB] Get:2 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-dev-cuda-12 9.1.0.70-1 [34.1 kB] Get:3 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-static-cuda-12 9.1.0.70-1 [436 MB] Get:4 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9-cuda-12-4 9.1.0.70-1 [12.3 kB] Get:5 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9-cuda-12 9.1.0.70-1 [12.3 kB] Get:6 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 libcudnn9-samples 9.1.0.70-1 [1670 kB] Get:7 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn9 9.1.0-1 [2442 B] Get:8 file:/var/cudnn-local-repo-ubuntu2204-9.1.0 cudnn 9.1.0-1 [2414 B] Selecting previously unselected package libcudnn9-cuda-12. (Reading database ... 216732 files and directories currently installed.) Preparing to unpack .../0-libcudnn9-cuda-12_9.1.0.70-1_amd64.deb ... Unpacking libcudnn9-cuda-12 (9.1.0.70-1) ... Follower: Nvidia cuDNN 官方安裝網頁\nCheck cuDNN:\nsee version:\ncat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 # or cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 check can use cuDNN:\nsudo apt install libfreeimage3 libfreeimage-dev cp -r /usr/src/cudnn_samples_v9/ /home/cuDNN-test/ cd /home/cuDNN-test/cudnn_samples_v9/mnistCUDNN make clean \u0026amp;\u0026amp; make ./mnistCUDNN Resulting weights from Softmax: 0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5 Test passed! install miniconda\nmkdir -p ~/miniconda3 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 rm -rf ~/miniconda3/miniconda.sh ~/miniconda3/bin/conda init bash conda create --name llama_py python=3.10 Follower: miniconda 官方網頁\ninstall pytorch\npip3 install torch torchvision torchaudio Ref: pytorch 官方網頁\nTry run LLama2\ngit clone https://github.com/meta-llama/llama.git pip install -e . download the model (Ex:llama-2-7b-chat) torchrun --nproc_per_node 1 example_chat_completion.py --ckpt_dir llama-2-7b-chat/ --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 6 Ref：LLama GitHub Page\nDocker run Ollama \u0026amp; openWeb ui\nRun in LLM folder create docker-compose.yaml docker-compose.yaml：\nversion: \u0026#39;3.8\u0026#39; services: ollama: image: ollama/ollama:latest ports: - 11434:11434 runtime: nvidia environment: NVIDIA_VISIBLE_DEVICES: all volumes: - .:/code - ./ollama/ollama:/root/.ollama container_name: ollama pull_policy: always tty: true restart: always open-webui: image: ghcr.io/open-webui/open-webui:main container_name: open-webui volumes: - ./ollama/open-webui:/app/backend/data depends_on: - ollama ports: - 8080:8080 environment: - \u0026#39;/ollama/api=http://ollama:11434/api\u0026#39; extra_hosts: - host.docker.internal:host-gateway restart: unless-stopped Create Ollama Modelfile to Ollama use Model\ncreate ./Makefile Makefile： (還有其他 LLM 詳細設定可以到 Ollama 的 github 上看)\nFROM ./\u0026lt;model_name\u0026gt;.gguf docker compose up -d docker exec -it ollama /bin/bash cd code ollama create \u0026lt;Ollama_Show_Model_Name\u0026gt; -f Modelfile root@454866b8147a:/code# ollama create llama3-8B-chat -f ./Modelfile transferring model data creating model layer using already created layer sha256:ce22d8a49a949089fd2b50a4c19fd043b8480da951d9ace3aa50446d64d4468c writing layer sha256:6e8dc213cf73dab521788f5a7e506d202db50b73d104d7d1bbc343089dfd1e8a writing manifest success root@454866b8147a:/code# ls Ref: Ollama GitHub Page - import\nGo to Web use\n補充： # Docker install:\nuninstall old docekr\nfor pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done install docker source\n# Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update install docker\nLast version: sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Specific version: # List the available versions: apt-cache madison docker-ce | awk \u0026#39;{ print $3 }\u0026#39; 5:26.1.0-1~ubuntu.24.04~noble 5:26.0.2-1~ubuntu.24.04~noble ... VERSION_STRING=5:26.1.0-1~ubuntu.24.04~noble sudo apt-get install docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-buildx-plugin docker-compose-plugin Verify Docker\nsudo docker run hello-world Ref：docker 官方網頁\nNvidia container toolkit：\ninstall Nvidia container toolkit curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list sudo apt-get update sudo apt-get install -y nvidia-container-toolkit # Configure NVIDIA Container Toolkit sudo nvidia-ctk runtime configure --runtime=docker sudo systemctl restart docker # Test GPU integration docker run --gpus all nvidia/cuda:11.5.2-base-ubuntu20.04 nvidia-smi Reference # Nvidia container-toolkit\n傻瓜 LLM 架設 - Ollama + Open WebUI 之 Docker Compose 懶人包\n","date":"2024年05月02日","externalUrl":null,"permalink":"/zh-tw/posts/ollama-deploy/","section":"Posts","summary":"\u003cp\u003e此文章介紹如何從安裝 Nvidia 驅動到從 HuggingFace 下載的 LLM Model 使用 Ollama 啟動 LLM 並使用 OpenWeb ui 進行溝通的部署過程紀錄。\u003c/p\u003e","title":"Ollama Deploy LLM","type":"posts"},{"content":"","date":"2024年02月28日","externalUrl":null,"permalink":"/zh-tw/categories/devops/","section":"Categories","summary":"","title":"DevOps","type":"categories"},{"content":"","date":"2024年02月28日","externalUrl":null,"permalink":"/zh-tw/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"2024年02月28日","externalUrl":null,"permalink":"/zh-tw/tags/k8s/","section":"Tags","summary":"","title":"K8s","type":"tags"},{"content":"","date":"2024年02月28日","externalUrl":null,"permalink":"/zh-tw/tags/nvidia/","section":"Tags","summary":"","title":"NVIDIA","type":"tags"},{"content":"本文介紹在 Ubuntu Server 22.04 上安裝 Docker 與 Kubernetes 並在 Container 上使用 GPU 的紀錄\n環境介紹 # K8s-Controller（V100 GPU）\nOS：Ubuntu Server 22.04 IP：192.168.137.154 Hostname：k8s-controller.com K8s-Node1（T4 GPU）\nOS：Ubuntu Server 22.04 IP：192.168.137.168 Hostname：k8s-node1.com K8s-Node2（T4 GPU）\nOS：Ubuntu Server 22.04 IP：192.168.137.249 Hostname：k8s-node2.com 如果不太懂 K8s 上該使用 GPU 整體架構可以先看這篇文章，可以大致上先了解等等會用到的套件 K8s GPU 整體架構介紹：https://zhuanlan.zhihu.com/p/670798727\nGPU 設定 及 安裝 (每台都需要設定) # 環境設定 # Disable nouveau 開源版本的 GPU 驅動 當系統安裝完成之後，會安裝系統開源的 NVIDIA 驅動版本，名稱為 nouveau 創建 /etc/modprobe.d/blacklist-nouveau.conf 文件 sudo vim /etc/modprobe.d/blacklist-nouveau.conf 將下面内容添加進去： blacklist nouveau blacklist lbm-nouveau options nouveau modeset=0 alias nouveau off alias lbm-nouveau off 創建 /etc/modprobe.d/nouveau-kms.conf 文件，並將 options nouveau mdeset=0 添加進去： echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf 更新一下 initramfs： sudo update-initramfs -u 重啟伺服器： sudo reboot 查看 nouveau 是否加載，沒顯示的話就表示已經禁用： sudo lsmod | grep nouveau 套件安裝 # 有分 \u0026ldquo;一次全部安裝好(CUDA Toolkit)\u0026rdquo; 跟 \u0026ldquo;各個小套件分別安裝\u0026rdquo; 的方法,這邊推薦直接裝一次全部裝好的版本\n安裝 Nvidia CUDA Toolkit 套件 (一次全裝版本) # 可以去官網選擇你的 OS 與版本去安裝合適套件與步驟： Nvidia CUDA Toolkit：https://developer.nvidia.com/cuda-downloads 這邊是使用 Local deb 安裝, 安裝 Ubuntu 22.04 local deb 版本\n移除舊 NVIDIA 驅動 sudo apt-get --purge remove nvidia* sudo apt-get --purge remove libnvidia* 安装 CUDA Toolkit (裡面包含 Driver Cuda NVCC 等等\u0026hellip;) Base Installer: wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.3.2/local_installers/cuda-repo-ubuntu2204-12-3-local_12.3.2-545.23.08-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-3-local_12.3.2-545.23.08-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-3 Driver Installer：二擇一即可我是裝上面就行了 To install the legacy kernel module flavor: sudo apt-get install -y cuda-drivers To install the open kernel module flavor: sudo apt-get install -y nvidia-kernel-open-545 sudo apt-get install -y cuda-drivers-545 單純安裝 Nvidia GPU Drive (之後還要裝 Cuda): # 實作中發現有 error 要控制 OS core 版本所以沒特別去解!! 所以要嘗試單個套件安裝的請自行 Debug，或哪天我找到正確方法我在補上！ wget NVIDIA GPU Driver\n找自己型號的 Driver 並複製下載連結： https://www.nvidia.com/Download/index.aspx?lang=en-us 下載 Driver 到機台上 wget \u0026#34;Driver-Url\u0026#34; install GPU Driver\nchmod 777 \u0026#34;GPU-Driver\u0026#34; ./\u0026#34;GPU-Driver\u0026#34; 安裝後就顯示這個錯誤\nERROR: An error occurred while performing the step: \u0026#34;Building kernel modules\u0026#34;. See /var/log/nvidia-installer.log for details. ERROR: An error occurred while performing the step: \u0026#34;Checking to see whether the nvidia kernel module was successfully built\u0026#34;. See /var/log/nvidia-installer.log for details. 調整到跟 uname -r 一樣的版本或是調低 uname 到一樣的版本 install linux-kernel-headers kernel-package:\nsudo apt-get install linux-kernel-headers kernel-package 解決方法：https://www.linuxprobe.com/ubuntu-nvidia-v100-gpu.html\n補充： # 裝完之後要使用 nvcc： # sudo nano ~/.bashrc\n# 加在最下面 export PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/\u0026lt;cuda-version-folder\u0026gt;/lib64:$LD_LIBRARY_PATH\u0026#34; # 或者用這個也可 export PATH=\u0026#34;/usr/local/cuda/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/cuda/lib64:$LD_LIBRARY_PATH\u0026#34; # 或者用這個也可 (我是用這個) # ref : https://blog.csdn.net/qq_41094058/article/details/116207333 if [ $LD_LIBRARY_PATH ]; then export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:\u0026#39;/usr/local/cuda/lib64\u0026#39; else export LD_LIBRARY_PATH=\u0026#39;/usr/local/cuda/lib64\u0026#39; fi if [ $PATH ]; then export PATH=$PATH:\u0026#39;/usr/local/cuda/bin\u0026#39; else export PATH=\u0026#39;/usr/local/cuda/bin\u0026#39; fi if [ $CUDA_HOME ]; then export CUDA_HOME=$CUDA_HOME:\u0026#39;/usr/local/cuda\u0026#39; else export CUDA_HOME=\u0026#39;/usr/local/cuda\u0026#39; fi source ~/.bashrc\nnvcc --version 對於多版本 cuda 的切換，也可以通過建立連結的方法：\nsudo rm -rf cuda sudo ln -s /usr/local/cuda-11.1/ /usr/local/cuda Check Driver, CUDA, NVCC\nnvidia-smi nvcc -V 參考資料：https://zhuanlan.zhihu.com/p/338507526\nGPU 相關資源： # Nvidia Download Website: https://developer.nvidia.com/downloads Nvidia CUDA Toolkit : https://developer.nvidia.com/cuda-downloads Nvidia Driver : https://www.nvidia.com.tw/Download/index.aspx?lang=tw GPU Check Command: # nvidia-smi nvcc -V GPU 補充: # 搭配性 : GPU 驅動 去跟 CUDA 匹配， CUDA 可以裝低一點版本的只要 GPU 驅動有兼容到即可 nvidia-smi 顯示的是當前驅動支持的最高版本的 cuda。 不是已經安裝的 cuda 版本。 Cuda Toolkit 版本內裝的各套件版本 https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html CUDA : 為 GPU 通用計算建構的運算平台 cudnn : 為深度學習計算設計的套件 CUDA Toolkit (nvidia) : CUDA 完整的工具安裝包，其中提供 Nvidia 驅動、開發 CUDA 程式相關開發工具等可供安裝的選項。包括 CUDA 編譯器、IDE、調適器等，CUDA 程式所對應的問件以及他們的頭文件 CUDA Toolkit (Pytorch): CUDA 不完整的工具安裝包，其主要包含在使用 CUDA 相關功能時所依賴的動態連接庫。不會安裝驅動程式!! NVCC 是 CUDA 的編譯器，只是 CUDA Toolkit 的一部分 K8s安裝 (會寫說在哪個 Node 上安裝，沒特別寫就是每台都要裝) # set hostname (All nodes) 依照你要設定的 Hostname 去設定\nsudo hostnamectl set-hostname \u0026lt;k8smaster.example.net\u0026gt; exec bash set /etc/hosts (All nodes)\n// IP Hostname ServerName 192.168.137.154 k8sc.net k8sc 192.168.137.168 k8sn1.net k8sn1 192.168.137.249 k8sn2.net k8sn2 disable swap , selinux, firewall\nswap:\nswapon --show sudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab sudo swapoff -a selinux:\nsudo selinux-config-enforcing # or sudo vim /etc/selinux/config Modify =\u0026gt; SELINUX=disabled Reboot system firewall:\nsudo ufw status sudo ufw disabl 參考資料：https://www.zhihu.com/question/374752553/answer/1052244227\nmodify core\nsudo tee /etc/modules-load.d/containerd.conf \u0026lt;\u0026lt;EOF overlay br_netfilter EOF reload mod\nsudo modprobe overlay sudo modprobe br_netfilter modify core\nsudo tee /etc/sysctl.d/kubernetes.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF reload system\nsudo sysctl --system install CRI suite\nsudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates add docker apt repository\nAdd Docker\u0026rsquo;s official GPG key:\nsudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg Add the repository to Apt sources:\necho \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null install Docker\nsudo apt-get update # 安裝 docker 相關套件 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # 新增 docker 群組 sudo groupadd docker # 把現在的 $USER 加到 docker 中 sudo usermod -aG docker $USER # 切換到 docker 群組 newgrp docker 設置 docker 使用 cgroupdriver=systemd 因為要配合 k8s 使用 systemd 所以要設定 docker daemon\nmkdir -p /etc/docker vim /etc/docker/daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } systemctl enable docker \u0026amp;\u0026amp; systemctl systemctl status docker install cri-docker\nV0.3.9： wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.9/cri-dockerd_0.3.9.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.9.3-0.ubuntu-jammy_amd64.deb systemctl daemon-reload systemctl enable cri-docker \u0026amp;\u0026amp; systemctl start cri-docker \u0026amp;\u0026amp; systemctl status cri-docker V0.3.10： wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.10/cri-dockerd_0.3.10.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.10.3-0.ubuntu-jammy_amd64.deb systemctl daemon-reload systemctl enable cri-docker \u0026amp;\u0026amp; systemctl start cri-docker \u0026amp;\u0026amp; systemctl status cri-docker Docker 試跑: Run container =\u0026gt; docker run --name hello-world hello-world 看資源 =\u0026gt; docker ps -a 刪除 container =\u0026gt; docker rm hello-world Add Kubernetes apt repository：\n# (推薦)官方使用原生包管理工具安装 sudo apt-get update # apt-transport-https 可以是一个虚拟包；如果是这样，你可以跳过这个包 sudo apt-get install -y apt-transport-https ca-certificates curl # 如果 `/etc/apt/keyrings` 目录不存在，则应在 curl 命令之前创建它，请阅读下面的注释。 sudo mkdir -p -m 755 /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list !!註解: 想要別的版本請改 V?.?? 要升级 kubectl 到别的次要版本，你需要先升级 /etc/apt/sources.list.d/kubernetes.list 中的版本， 再运行 apt-get update 和 apt-get upgrade。 ref: https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/ install Kubernetes suite for Kubectl, kubeadm, kubelet\nsudo apt update sudo apt install -y kubelet kubeadm kubectl (option) sudo apt-mark hold kubelet kubeadm kubectl Kubeadm init (Controller Node) 特別注意！！ 參數基本上都是依照你的環境狀態去新增或修改！！ \u0026ndash;pod-network-cidr \u0026lt;cidr_ip\u0026gt; 請依照你後來要使用的 cidr_ip 需求去修改 Normal command: sudo kubeadm init --control-plane-endpoint=k8sc.net --pod-network-cidr=172.168.0.0/16 Docekr cri-dockerd command: sudo kubeadm init --control-plane-endpoint=k8sc.net --pod-network-cidr=172.168.0.0/16 --cri-socket unix:///run/cri-dockerd.sock 初始化好會顯示 Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 \\ --control-plane Then you can join any number of worker nodes by running the following on each as root: kubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 Work Node Join cluster (WorkNode) 請依照你剛剛建立好的 k8s 去修改要輸入的 kubeadm join code Normal command:\nkubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 Docekr cri-dockerd command:\nkubeadm join k8sc.net:6443 --token m4mgvk.ds9gbxubeelkyg1d \\ --discovery-token-ca-cert-hash sha256:967a99a31596e6d6ad9b40dabf69813b8c605f9fe1c8590ddbe68fa23d58e095 --cri-socket unix:///run/cri-dockerd.sock Check all node join (MasterNode) - kubectl get nodes\ninstall Calico Pod network suite (MasterNode)\n此版本為 V3.27.0 因為這次使用的是 --pod-network-cidr=172.168.0.0/16 所以需要改文件\n# 建立它所需要的套件 kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml # 下載設定檔 wget https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml 修改設定檔：\n# 因為預設是 192.168.0.0 跟我們 IP 撞到,修改成 172.168.0.0 nano custom-resources.yaml # This section includes base Calico installation configuration. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation apiVersion: operator.tigera.io/v1 kind: Installation metadata: name: default spec: # Configures Calico networking. calicoNetwork: # Note: The ipPools section cannot be modified post-install. ipPools: - blockSize: 26 cidr: 172.168.0.0/16 \u0026lt;= 修改這 encapsulation: VXLANCrossSubnet natOutgoing: Enabled nodeSelector: all() --- 部屬 CNI：\nkubectl create -f custom-resources.yaml Waite all pods Running：\nwatch kubectl get pods -n calico-system # or watch kubectl get pods --all-namespaces # 移除在 control-plane 上的 汙點(taint) kubectl taint nodes --all node-role.kubernetes.io/control-plane- # 移除在 master 上的 汙點(taint) kubectl taint nodes --all node-role.kubernetes.io/master- 參考資料： https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart https://www.cnblogs.com/khtt/p/16563088.html Check All Cluster Node STATUS\nkubectl get nodes -o wide 會都相下面一樣顯示 Ready 代表 k8s 以可以正常使用！！\nNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8smaster.net Ready control-plane 52m v1.29.1 192.8.1.66 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 k8snode1.net Ready \u0026lt;none\u0026gt; 23m v1.29.1 192.8.1.65 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 k8snode2.net Ready \u0026lt;none\u0026gt; 23m v1.29.1 192.8.1.69 \u0026lt;none\u0026gt; Ubuntu 22.04.3 LTS 5.15.0-78-generic containerd://1.6.27 Trouble Shooting: # \u0026ldquo;初始錯誤\u0026quot;要重建 k8s：\n# 如果 kubeadm reset (使用 containerd.io) kubeadm reset (使用 cri-dockerd) kubeadm reset --cri-socket unix:///run/cri-dockerd.sock # 清除 k8s 文件 rm -rf $HOME/.kube # 重啟 k8s 服務 systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart kubelet # 之後請回到 step.15 \u0026ldquo;建立 CNI 之後\u0026quot;重建 k8s：\n# 如果 kubeadm reset (使用 containerd.io) kubeadm reset (使用 cri-dockerd) kubeadm reset --cri-socket unix:///run/cri-dockerd.sock # 刪除 CNI 文件 rm -rf /etc/cni/net.d # 刪除之前 CNI 所建立的 iptable sudo iptables -F \u0026amp;\u0026amp; sudo iptables -t nat -F \u0026amp;\u0026amp; sudo iptables -t mangle -F \u0026amp;\u0026amp; sudo iptables -X # 刪除 k8s 文件 sudo rm -f $HOME/.kube/config kubectl get nodes 如果出現\nroot@k8sc:~/K8s# kubectl get node E0201 16:03:23.299872 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.300534 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.302286 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.302901 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused E0201 16:03:23.304646 18786 memcache.go:265] couldn\u0026#39;t get current server API group list: Get \u0026#34;http://localhost:8080/api?timeout=32s\u0026#34;: dial tcp 127.0.0.1:8080: connect: connection refused The connection to the server localhost:8080 was refused - did you specify the right host or port? 解決方法: =\u0026gt; mkdir ~/.kube =\u0026gt; cp /etc/kubernetes/admin.conf ~/.kube/config 參考資料： rfe: https://www.gbase8.cn/12320 Docker use GPU # 有 GPU 的 host 都需要裝\ninstall nvidia-container-toolkit\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/libnvidia-container.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y nvidia-container-toolkit Setting /etc/docker/daemon.json\nnano /etc/docker/daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;default-runtime\u0026#34;: \u0026#34;nvidia\u0026#34;, \u0026#34;runtimes\u0026#34;: { \u0026#34;nvidia\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/usr/bin/nvidia-container-runtime\u0026#34;, \u0026#34;runtimeArgs\u0026#34;: [] } } } sudo systemctl restart docker check container can use GPU\ndocker run --rm -it nvcr.io/nvidia/cuda:10.2-base nvidia-smi 如果可以看到下面這樣 Nvidia-smi 畫面就代表你的 docker container 裡可以使用 GPU 了!!\nThu Feb 1 09:55:47 2024 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 545.23.08 Driver Version: 545.23.08 CUDA Version: 12.3 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 Tesla T4 On | 00000000:18:00.0 Off | 0 | | N/A 28C P8 9W / 70W | 7MiB / 15360MiB | 0% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ 參考資料： https://github.com/NVIDIA/k8s-device-plugin?tab=readme-ov-file#enabling-gpu-support-in-kubernetes Install NGC # 為了可以讓 k8s 可以找到 GPU 資源需要 Nvidia NGC 中的 images\nInstall NGC Command Line\nwget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.37.0/files/ngccli_linux.zip -O ngccli_linux.zip \u0026amp;\u0026amp; unzip ngccli_linux.zip find ngc-cli/ -type f -exec md5sum {} + | LC_ALL=C sort | md5sum -c ngc-cli.md5 chmod u+x ngc-cli/ngc echo \u0026#34;export PATH=\\\u0026#34;\\$PATH:$(pwd)/ngc-cli\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/.bash_profile \u0026amp;\u0026amp; source ~/.bash_profile # rfe: https://ngc.nvidia.com/setup/installers/cli set NGC config set\nngc.nvidia.com 辦一個會員 右上角頭像 SetUp -\u0026gt; API Key Generate API Key ngc config set 輸入 api key 跟一些資料 docker login nvcr.io Username: 輸入 =\u0026gt; $oauthtoken Password: 輸入你的 token 完成就會像這樣 root@k8sc:~/NVD# docker login nvcr.io Username: $oauthtoken Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 確認是否可連上並下載回來 images docker pull nvcr.io/nvidia/k8s-device-plugin:v0.14.4 Check Pods Ruing\nroot@k8sc:~/NVD/test# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE ........ ........ ...... kube-system nvidia-device-plugin-daemonset-g7pn5 1/1 Running 0 11m kube-system nvidia-device-plugin-daemonset-j5t79 1/1 Running 0 11m kube-system nvidia-device-plugin-daemonset-pjjr9 1/1 Running 0 11m ........ ........ ...... Check kubectl describe nodes 確認有 nvidia.com/gpu 就代表成功了\nAddresses: InternalIP: 192.168.137.249 Hostname: k8sn2.net Capacity: cpu: 96 ephemeral-storage: 3843514416Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 395820888Ki nvidia.com/gpu: 5 pods: 110 Allocatable: cpu: 96 ephemeral-storage: 3542182879921 hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 395718488Ki nvidia.com/gpu: 5 pods: 110 System Info: Machine ID: 99a1ca0433d9443aafba35201ede1a9b System UUID: d8c50c1b-e0ef-2445-bc45-140d4f639386 Boot ID: 5a8a1c1f-f155-44af-9e70-105e821bd24c Kernel Version: 6.5.0-15-generic OS Image: Ubuntu 22.04.3 LTS Operating System: linux Architecture: amd64 Container Runtime Version: docker://25.0.2 Kubelet Version: v1.29.1 Kube-Proxy Version: v1.29.1 PodCIDR: 172.168.2.0/24 PodCIDRs: 172.168.2.0/24 Non-terminated Pods: (5 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age --------- ---- ------------ ---------- --------------- ------------- --- calico-system calico-node-rvhj8 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h calico-system calico-typha-5f87879b7d-tjwld 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h calico-system csi-node-driver-b58b7 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h kube-system kube-proxy-xcf67 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h kube-system nvidia-device-plugin-daemonset-pjjr9 0 (0%) 0 (0%) 0 (0%) 0 (0%) 14m Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 0 (0%) 0 (0%) memory 0 (0%) 0 (0%) ephemeral-storage 0 (0%) 0 (0%) hugepages-1Gi 0 (0%) 0 (0%) hugepages-2Mi 0 (0%) 0 (0%) nvidia.com/gpu 0 0 Events: \u0026lt;none\u0026gt; 參考資料： https://github.com/NVIDIA/k8s-device-plugin https://bluesmilery.github.io/blogs/afcb1072/ Trouble Shooting: # reboot 之後 nvidia-smi 會報錯: sudo ubuntu-drivers devices # 安裝帶有 recommended 版本的 Driver sudo apt-get install nvidia-driver-\u0026lt;*\u0026gt; # ref: # https://zhuanlan.zhihu.com/p/337013545 # https://www.zhihu.com/question/474222642 create -f k8s device plugin 之後發現 control-plane 沒有被派發任務， step.19 沒做到此動作，輸入完即可 # 移除在 control-plane 上的 汙點(taint) kubectl taint nodes --all node-role.kubernetes.io/control-plane- # 移除在 master 上的 汙點(taint) kubectl taint nodes --all node-role.kubernetes.io/master- GPU Burn # 使用 wilicc/gpu-burn 作為 GPU Burn 程式並且打包成 images 使用\nwilicc/gpu-burn to image git clone https://github.com/wilicc/gpu-burn cd gpu-burn nano Dockerfile # 把它修改版本及執行方式成我們要的樣子方便後面 k8s 使用 ARG CUDA_VERSION=12.3.1 ARG IMAGE_DISTRO=ubuntu22.04 FROM nvidia/cuda:${CUDA_VERSION}-devel-${IMAGE_DISTRO} AS builder WORKDIR /build COPY . /build/ RUN make FROM nvidia/cuda:${CUDA_VERSION}-runtime-${IMAGE_DISTRO} COPY --from=builder /build/gpu_burn /app/ COPY --from=builder /build/compare.ptx /app/ WORKDIR /app # Create a /app/result directory and link it to the local ./result directory RUN mkdir /app/result \u0026amp;\u0026amp; ln -s /app/result /result # 打包成 Images docker build -t gpu_burn . # 確認是否有打包好的 images docker images Private Docker Registry Server # 因為需要下在自己打包的 image 給其他 node 使用又不想上傳到 dockerhub 所以自己建一個 Private Docker Registry\n# 用 docker 架起 Registry docker run -d --restart always -p 5000:5000 -v /root/K8s/registry:/var/lib/registry --name registry registry:2 # 把我們剛剛打包好的 image 打上 tag docker tag \u0026lt;images_name\u0026gt; \u0026lt;registries_ip\u0026gt;:5000/\u0026lt;images_name\u0026gt; # 在所有要下載的 server 修改 docker 設定檔新增以下 code nano /etc/docker/daemon.json (all node) \u0026#34;live-restore\u0026#34;: true, \u0026#34;group\u0026#34;: \u0026#34;dockerroot\u0026#34;, \u0026#34;insecure-registries\u0026#34;: [\u0026#34;\u0026lt;registries_ip\u0026gt;:5000\u0026#34;] # 重啟 docker 讓他讀取新設定檔 (all node) systemctl restart docker # 上傳剛剛打上 tag 的 images docker push \u0026lt;registries_IP\u0026gt;:5000/\u0026lt;images_name\u0026gt; K8s exec GPU-Burn # gpu-burn-CN5c.yaml:\napiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-controller labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sc.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # 設置每個 Pod 使用的 GPU 數量 volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory --- apiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-node1 labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sn1.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # 設置每個 Pod 使用的 GPU 數量 volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory --- apiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-node2 labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never nodeSelector: kubernetes.io/hostname: k8sn2.net containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 5 # 設置每個 Pod 使用的 GPU 數量 volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory gpu-burn-R4c-3pod.yaml:\napiVersion: batch/v1 kind: Job metadata: name: gpu-burn-job-random labels: app: gpu-burn spec: ttlSecondsAfterFinished: 100 completions: 3 # 完成幾個 parallelism: 3 # 同時執行幾個 template: metadata: labels: app: gpu-burn spec: restartPolicy: Never containers: - name: gpu-burn image: 192.168.137.154:5000/gpu_burn imagePullPolicy: Never command: [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./gpu_burn 60 \u0026gt; /app/result/output.txt \u0026amp;\u0026amp; exit\u0026#34; ] resources: limits: nvidia.com/gpu: 4 # 設置每個 Pod 使用的 GPU 數量 volumeMounts: - name: result-volume mountPath: /app/result volumes: - name: result-volume hostPath: path: /root/gpu-result type: Directory 建立任務: =\u0026gt; kubectl create -f \u0026lt;yaml\u0026gt; 刪除任務: =\u0026gt; kubectl delete -f \u0026lt;yaml\u0026gt; 查看 job : =\u0026gt; kubectl get pods 查看 job 詳細資訊 : =\u0026gt; kubectl describe pods or =\u0026gt; kubectl describe pod \u0026lt;pod_name\u0026gt; 查看執行 Logs : =\u0026gt; kubectl Logs \u0026lt;pod_name\u0026gt; ","date":"2024年02月28日","externalUrl":null,"permalink":"/zh-tw/posts/k8sgpu/","section":"Posts","summary":"\u003cp\u003e本文介紹在 Ubuntu Server 22.04 上安裝 Docker 與 Kubernetes 並在 Container 上使用 GPU 的紀錄\u003c/p\u003e","title":"如何正確在 Docker 與 K8s 使用 GPU","type":"posts"},{"content":"","date":"2024年02月08日","externalUrl":null,"permalink":"/zh-tw/tags/s2d/","section":"Tags","summary":"","title":"S2D","type":"tags"},{"content":"本文紀錄 Windows Server 2019 上建立 S2D 的過程！！\n先介紹安裝環境，此次是不含 ADDS 並使用外接 USB 當作仲裁驗證方式部屬 S2D。\n我們總共有 2 台機台分別是 Node1 跟 Node2，我們這邊把 Node1 當主要部署及後續操作機台。\n那由於我們沒有 ADDS 跟 DHCP 所以我們就先把 Node1 跟 Node2 設定為靜態 IP。\nNode1 IP : 192.8.1.42 Node2 IP : 192.8.1.43 # 這邊先擬定一個給 Cluster 建立用的 IP Cluster IP : 192.8.1.57 Quorum 仲裁機制 : \u0026lt;Host IP\u0026gt;/Q:\\\\ 建立 S2D 步驟 # 設定 hosts (每個 Node 都需要設定) 由於我們是沒有 DHCP、ADDS 情況下部屬我們要讓機台互相可以能溝通到所以要設定本機上的 hosts 編輯 C:\\Windows\\System32\\drivers\\etc\\hosts\nEx: IP hostname 192.8.1.43 Node2 192.8.1.42 Node1 192.8.1.57 S2D-Cluster 設定 TrustedHosts (每個 Node 都需要設定)\n新增 TrustedHosts Set-Item WSMan:\\localhost\\Client\\TrustedHosts -Concatenate -Value \u0026#34;S2D-Controller , Node1 , Node2“ 確認 TrustedHosts Get-Item WSMAN:\\Localhost\\Client\\TrustedHosts 安裝需要用到的服務 (每個 Node 都需要設定)\n安裝套件 Windows 腳色和功能 Install-WindowsFeature -Name \u0026#34;Hyper-V\u0026#34;, \u0026#34;Failover-Clustering\u0026#34;, \u0026#34;Data-Center-Bridging\u0026#34;, \u0026#34;RSAT-Clustering-PowerShell\u0026#34;, \u0026#34;Hyper-V-PowerShell\u0026#34;, \u0026#34;FS-FileServer\u0026#34; -IncludeManagementTools 清空 S2D 磁碟 (每個 Node 都需要設定)\n初始化 S2D 硬碟 (確保硬碟都是沒有被 Claimed 的狀態 )\n如果硬碟沒設定過就不需要該步驟(須避開作業系統硬碟)\n請先以 Diskpart 指令確認硬碟編號，然後就可以使用 Clear-Disk 的 PowerShell 來清掃硬碟中所有的內容。\n(請注意!! 硬碟必須為 Online 狀態下，那麼 Clear-Disk 指令才能順利清掃硬碟內容。)\n#處理單顆硬碟： Clear-Disk –Number 1 -RemoveData -RemoveOEM #一次處理多顆硬碟： Clear-Disk –Number 1,2,3,4 -RemoveData -RemoveOEM 執行完 Clear-Disk 動作後，硬碟的狀態應恢復到「Unknown、Not Initialized、Unallocated」才是正確狀態\n請注意 !! 若硬碟未呈現正確狀態的話，稍後啟動「Software Storage Bus」機制時，將無法順利把節點主機的本機硬碟加入至儲存資源池中。\n測試建立 Cluster 環境 (Node1)\n測試 Node1 Node2 是否符合建立 Cluster 的環境\nTest-Cluster Node1 , Node2 測試完會顯示目前問題與報告產生的地方，有問題建議去看報告會有詳細的問題說明 建立 Cluster (Node1)\n建立 Cluster New-Cluster –Name S2DCluster -Node Node1,Node2 -AdministrativeAccessPoint DNS -StaticAddress 192.8.1.57 Quorum USB 設定 (Node2)\n先到 USB Properties，之後開啟 Share… Advanced Shareing… \u0026gt; Permissions \u0026gt; Everyone 點選 Full Control 設定 Cluster 的仲裁機制 (Node1)\n設定 仲裁機制為外接 USB Set-ClusterQuorum -FileShareWitness \\\\192.8.1.43\\q -Credential $(Get-Credential) 之後會出現登入畫面請輸入相對應機台的帳號與密碼 開啟 Storage Spaces Direct 服務 (Node1)\nEnable-ClusterStorageSpacesDirect 跑完一小段之後它會問你是不是要使用你剛剛創的 Cluster 輸入 Y 開始建立 查看 Failover Cluster Manager (Node1 or Node2)\nServer Manager \u0026gt; Tool \u0026gt; Failover Cluster Manager 點擊 Failover Cluster Manager 右鍵 \u0026gt; Connect to Cluster \u0026gt; 點擊 OK 它會自己找到目前機台有連接的 Cluster 你可以在 Disks, Pools 下找到剛剛建立好的 Disks, Pools 建立 Share Disk 步驟 # 建立好 Cluster 後想要切出一個空間給某個功能用可以依照以下方法執行 先在 Pool 中點擊右鍵，點選 New Virtual Disk 之後切出你要的空間 切完之後到另一台 Node 下 Disk Management 可以看到此硬碟 初始化它(可以用 ReFS 或是 NTFS 格式化)並設定 槽區 回到原本 Node 下到 Failover Cluster Manager \u0026gt; Disks 下把硬碟加入到 Cluster Share Volumes 從 Pool 中建立新的虛擬磁碟 (Node1)\n從 Pool 中切出一個要使用的空間 盡量不要選 Max 因為我們架構沒有空間給它快取有可能在建構的時候會造成 Fail 切好之後的彈出視窗是可以幫你建立槽區但現在的架構不是單純的一個機台或有AD的情境下所以不適用 之後我們自己手動切槽區 切完之後我們可以看到下面會長出一個新的 Virtual Disk 確認有切出虛擬磁碟 (Node2)\n跳到 Node2 的 Disk Management 我們可以看到會有一個新的未啟用的 Disk 手動切割磁區 (Node2)\n我們手動先手動建立跟格式化(ReFS or NTFS 都可以) 之後按右鍵 Change Drive Letter and Paths … 幫它上槽區 確認 Cluster 的 Pool 上是否有建立出一個磁碟 (Node1)\n回到 Node1 的 Failover Cluster Manager \u0026gt; Pool 下可以看到有了槽區並且是 ReFS 格式跟我們剛剛做的符合 確認 Cluster 的 Disk 上的資訊 (Node1)\n我們到 Disks 確認可以看到類似的內容，並且可以注意到它目前狀態是 Avalable Storage 新增到 Cluster Share Volumes (Node1)\n我們右鍵剛剛創建的 Virtual Disk 按下 Add to Cluster Share Volumes 把我們的硬碟加到 Cluster Share Volumes 讓兩個 node 都能用到 確認 Cluster Share Volume 狀態 (Node1)\n加完之後我們就可以看見上面的狀態變成 Cluster Share Volume 下面變成 CSVFS 的格式了 會掛載到每個 Node 的 C:\\ClusterStorage 下 確認是否都有掛載到每個 Node 上 (Node1 and Node2)\n到每個 Node 下去驗證 C:\\ClusterStorage 下是否有空間 補充： # 更換仲裁機制： # Failover Cluster Manager \u0026gt; 右鍵 Cluster \u0026gt; MoreAction \u0026gt; Configure ClusterQuorum Settings… 或是依照前面 Setting USB enable share folder 方式使用 Command Line 來設定新的 Quorum 確認 S2D 損壞硬碟： # 確認硬碟狀態： Get-StoragePool *S2D* | Get-PhysicalDisk 有問題的硬碟狀態會出現類似訊息 OperationalStatus：Lost Communication， HealthStatus：Warning 查看受影響的 VirtualDisk： Get-VirtualDisk 有問題的 VirtualDisk 狀態會出現類似訊息 HealthStatus：Warning 排除 S2D 故障硬碟： # 從硬碟區將故障硬碟過濾出來並存成 $FailDisk 變數 $FailDisk = Get-PhysicalDisk |? OperationalStatus -Notlike OK 設定故障硬碟的使用狀態為 Retired Set-PhysicalDisk -InputObject $FailDisk -Usage Retired 將故障硬碟從 S2D Pool 中移除 Get-StoragePool *S2D* | Remove-PhysicalDisk -PhysicalDisks $FailDisk 確認 S2D Pool 以無故障硬碟 Get-StoragePool *S2D* | Get-PhysicalDisk 新硬碟加入 Storage Pool： # 尋找可以加入 Storage Pool 的新硬碟並存成 $NewDisk 變數 $NewDisk = Get-PhysicalDisk |? CanPool -eq True 將新硬碟加入 Storage Pool 中 (請確保新硬碟尚未初始化、格式化，否則屆時 S2D 將無法順利宣告及使用此顆新硬碟!!) Get-StoragePool *S2D* | Add-PhysicalDisk -PhysicalDisks $NewDisk –Verbose 確認新硬碟是否已加入 Storage Pool Get-StoragePool *S2D* | Get-PhysicalDisk 手動重新平均寫入 Slab 資料 # 正常情況下 S2D 會自己自動執行 S2D Storage Pool Rebalance 的動作把資料平均儲存在每個硬碟上 手動執行 S2D Storage Pool Rebalance Get-StoragePool *S2D* | Optimize-StoragePool 透過 Show-PrettyPool.ps1 這隻腳本可以看到硬碟上已經寫回 Slab 資料 查看平衡進度 Get-StorageJob Reference # 117 期 - 微軟最新 S2D 儲存技術，跨伺服器硬碟組成資源池 (weithenn blog)\n在 Windows Server 上部署儲存空間直接存取 (microsoft.com)\n深入剖析 S2D Storage Pool (weithenn blog)\n儲存空間直接存取的巢狀復原 - Azure Stack HCI (microsoft.com)\nS2D (Storage Spaces Direct) 更換故障硬碟 (weithenn blog)\n","date":"2024年02月08日","externalUrl":null,"permalink":"/zh-tw/posts/builds2d/","section":"Posts","summary":"\u003cp\u003e本文紀錄 Windows Server 2019 上建立 S2D 的過程！！\u003c/p\u003e","title":"Windows Server S2D","type":"posts"},{"content":"本文介紹基礎的 Docker Swarm 該如何使用\n建立測試機並建立測試環境 # 我們這邊用 Docker-Machine 建立測試環境也可以用一般的VM 建立測試環境都OK，只要確保環境上網路能連通 Docker 能用即可！\nDocker-Machine (用來建立虛擬機 for virtualbox)：\ndocker/machine (github.com) ⇒ 改名為 docker-machine.exe\nWindows：放在 C:\\Windows\\System32\nLinux：放在 /usr/bin ⇒ chmod 755 docker-machine\nDocker Swarm 腳色： # Manager 叢集管理 目的就是負責來管理叢集的宿主機，並調用安排每個需要的服務容器應該要被放在哪一台來做啟動，當服務停止時也要負責啟動服務容器使之正常來做服務的提供。\nWorker Nodes 工作節點 Node翻譯成節點，簡單說就是代表一台台的宿主機，而執行Service的地方就是在任意的Node節點上。\nDocker Swarm 優點： # Scaling 自動擴展 Scaling本身概念簡單，也是雲端能帶來的其中一項價值所需，當回應需求服務數量或連線流量過大時，能透過自動擴展機制一次啟動多個相應的服務同時處理需求回應與因應流量，直到流量或需求恢復正常，就可以透過縮容來減少服務數量，以節省主機成本。\nLoad Balacning 負載平衡 當流量進到Docker Swarm的服務中，會透過像輪詢(Round Robin)的機制去把進來的流量做分流，也就是輪流把流量送到各服務去，舉例第一個進來給A容器，第二個進來給B容器，第三個進來再給A，以此類推\u0026hellip;\nService Discovery 服務探索 在 Docker swarm 中每個服務都可以定義自己服務獨有的DNS，而接下來就可以讓其他容器透過自訂的DNS來使用服務。\nDocker Swarm 整體架構圖： # Docker Swarm 網路架構圖： # Docker Swarm Command： # 查看 cluster 內的 server：docker node ls\n建立服務：docker service create --replicas \u0026lt;數量\u0026gt; --name=\u0026lt;service_name\u0026gt; -p \u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt; \u0026lt;image\u0026gt;\n刪除服務：docker service rm \u0026lt;service_name\u0026gt;\n查看服務：docker service ps \u0026lt;service_name\u0026gt;\n查看服務 Log：docker service logs \u0026lt;service_name\u0026gt; -f\n更新服務參數：docker service update \u0026lt;option\u0026gt; \u0026lt;service_name\u0026gt;\n查看服務詳細參數：docker service inspect \u0026lt;service_name\u0026gt;\nDocker Swarm 搭建基礎實作： # init docker swarm (in master)\ndocker swarm init # 機台上有多個 ip 請使用下面的 docker swarm init --advertise-addr \u0026lt;互ping的到的ip\u0026gt; IP 太多的 Error message： init 成功： docker swarm join (in node) 複製上面的 Join Command\ndocker swarm join --token \u0026lt;docker_swarm_token\u0026gt; \u0026lt;IP\u0026gt;:2377 連結成功： 查看 node 是否正確\ndocker node ls 建立服務\ndocker service create 查看服務是否建立\ndocker service ps \u0026#34;gyhello\u0026#34; 查看服務是否正常啟用 查看服務 Logs\ndocker service logs gyhello -f Docker Swarm Load Balancer 實作： # 這邊是示範後端設定 , 前端還需要掛載一個 nginx 去做 Load Balancer , 連到前端 nginx 後會自動導入後端兩台其中一個 ip 去使用服務\n擴增(scaling up)： # docker service scale \u0026lt;service_name\u0026gt;=\u0026lt;數量\u0026gt; # Ex: docker service scale gyhello=5 縮容(scaling down)： # docker service scale \u0026lt;service_name\u0026gt;=\u0026lt;數量\u0026gt; # Ex: docker service scale gyhello=2 負載平衡驗證： # # Linux Command: iptables -L -t nat # filter : 是流量進到宿主機本身來決定是否 Accept or Drop or Forward的方式。 # NAT : 流量本身跟此台宿主機並無直接關係，主要作為來源與目的 IP \u0026amp; Port間轉至後端容器主機。 # Mangle : 屬特殊表格，會去標記某些規格並改寫封包。 驗證會被導入到 172.18.0.2:8080\nifconfig 確認 docker_gwbridge 網路介面相關聯，透過 Ｎode建立Container 後在與容器建立連線，故節點中涵蓋一組容器 IP：172.18.0.2\n檢視 Docker 網路的詳細資訊：\ndocker network inspect docker_gwbridge 這裡有一個被隱藏的 Container 叫 ingress-sbox，看起來流量是先進入此 Container 後再把流量分配到真正的 Service\nIngress： # docker swarm 跟 k8s 依樣是透過在 Master端 建立網段可以與外網溝通並利用 ipvs 方式把 iptables 加在每個 node 中並導出服務的 port , 達到外網只要連線到 master端ip:port 就能使用服務\nReference # 深入浅出Swarm(Blog DaoCloud)\n【云原生】一文理解Swarm解决docker server的集群化管理和部署(知乎)\nDocker Swarm 網路架構介紹 - load balancing traffic path ","date":"2023年11月26日","externalUrl":null,"permalink":"/zh-tw/posts/docker-swarm/","section":"Posts","summary":"\u003cp\u003e本文介紹基礎的 Docker Swarm 該如何使用\u003c/p\u003e","title":"Docker Swarm 入門教學","type":"posts"},{"content":"本文講述 Docker 與 VM 的不同 與 Docker 指令\n重要觀念 Docker != Container # Docker 架構： # VM： # 用來建立虛擬化運算環境的技術(OS層級虛擬化)\n優點:\n安全性較高，因為硬體層以上都虛擬化 可以選擇各種不同的 OS 缺點:\nImage大小通常為GB 啟動速度通常要花個幾分鐘 資源使用較多，因為要將一部分資源分給 VM 的作業系統 Container： # Docker 是個管理容器的服務，提供應用層級虛擬化技術。容器不像虛擬機要在 Host OS 上再安裝 Guest OS，而可以直接共用底層 Host OS 的資源，同時具備其應用程式沙盒的隔離性。\n優點:\nImage大小通常為MB 啟動速度較快 能將更多資源運用在跑服務上 更新較為容易 缺點:\n安全性較差 同一台機器中，每個 Container 的 OS 都是相同 Docker 參數： # 建立網路連接，讓外部可以透過主機端口存取容器內的服務 docker run -p \u0026lt;host端port:container端port\u0026gt; 將主機 (host) 的目錄或檔案掛載到容器內的指定路徑 docker run -v \u0026lt;host端path:container端path\u0026gt; Docker Command： # 把 docker image 下載下來： docker pull \u0026lt;image_name:version_Tag\u0026gt;\n建立當前資料夾下的 docker-compose.yml 檔建立相對應的 container： docker compose up -d\n查看目前有在跑的 container 和 詳細資料： docker compose ps -a\n查看 container 目前有什麼在跑： docker container ls\n查看 container ID and 執行佔用 CPU or Memory …： docker stats\n執行 container： docker run \u0026lt;container_ID or Container_name\u0026gt;\n停止 container： docker stop \u0026lt;container_ID or Container_name\u0026gt;\n移除 container： docker rm \u0026lt;container_ID or Container_name\u0026gt;\n停止 container： docker compose stop \u0026lt;container_ID or compose_name\u0026gt;\n開始 container： docker compose run \u0026lt;container_ID or compose_name\u0026gt;\n重啟 container： docker compose restart \u0026lt;container_ID or compose_name\u0026gt;\n查看所有 docker 上 network 種類： docker network ls\n查詢接上此 network 的資訊： docker network inspect \u0026lt;network_name\u0026gt;\ndocker 跟 container 溝通： docker exec -it \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt;\n以 root權限 跟 container 溝通： docker exec -it —user=root \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt; or docker exec -it —u 0 \u0026lt;container_id or container_name\u0026gt; \u0026lt;Command\u0026gt;\n把docker file 文件打包成一個imag：docker compose build\n看container ip：\ndocker inspect -f \u0026#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; \u0026lt;container_id or container_name\u0026gt; 找資料位置：\n# 列出所有 volumes docker volume ls # 檢視指定容器的所有掛載點 (mount points) 資訊 docker inspect -f \u0026#39;{{.Mounts}}\u0026#39; \u0026lt;Container_ID\u0026gt; 刪除 docker 產物 ：docker \u0026lt;*\u0026gt; prune image：\ndocker image prune docker image prune -a container：\ndocker container prune volumes：\ndocker volume prune network：\ndocker network prune everything：\ndocker system prune WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all dangling images - all build cache docker system prune --volumes WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all volumes not used by at least one container - all dangling images - all build cache Reference # 《Docker —— 從入門到實踐­》正體中文版 (Git book)\nDocker Tips (Git book)\n專題筆記: VM 與 Docker (Hackmd) by.@wei06097\nPrune unused Docker objects | Docker Docs\n","date":"2023年11月19日","externalUrl":null,"permalink":"/zh-tw/posts/docker-vm-df/","section":"Posts","summary":"\u003cp\u003e本文講述 Docker 與 VM 的不同 與 Docker 指令\u003c/p\u003e","title":"Docker 與 VM 的不同 與 Docker 指令","type":"posts"},{"content":"","date":"2023年06月17日","externalUrl":null,"permalink":"/zh-tw/tags/ci/cd/","section":"Tags","summary":"","title":"CI/CD","type":"tags"},{"content":"","date":"2023年06月17日","externalUrl":null,"permalink":"/zh-tw/tags/gitlab/","section":"Tags","summary":"","title":"Gitlab","type":"tags"},{"content":"本文講述 Gitlab Runner 的各種類別與建立使用方法!!\nGitLab CI/CD 的 Runner 是藉由另一台電腦去執行 CI/CD 動作完後再回傳給 GitLab 資訊 自架 Gitlab 要使用到 Gitlab CI/CD 功能需安裝 Git-runner 到一台 Server or Container 下去做使用 Install GitLab Runner | GitLab Gitlab Runner 有三種不同的權限 :\nShared runners：可用於 GitLab 實例中的所有組和項目。 Group runners：可用於小組中的所有項目和子小組。 Specific runners：與特定的項目相關聯。通常，特定的運行器一次用於一個項目。 當你沒有管理 runner 的權限時，可以用這個來建立屬於自己的 gitlab runner Shared runners (適用範圍 GitLab 上全部的 Groups 與 Projects ) 因為是全域 Runner 所以需要 admin 帳戶來創建 Runner Admin Area -\u0026gt; CI/CD -\u0026gt; Runner -\u0026gt; Register an instance runner -\u0026gt; Show runner installation and registration instuctions 到你安裝 GitLab runner 的地方照著 Command to register runner 執行 \\\n# Windows 執行 .\\gitlab-runner.exe register --url \u0026lt;GitLab_Url\u0026gt; --registration-token \u0026lt;admin_registration_token\u0026gt; 有看到以下代表成功 現在你創新的專案都可以看到這個 Runner Group runners (這邊建立的是 Group 下所有的 Projects 皆可使用這個 runner) Select your group -\u0026gt; CI/CD -\u0026gt; Runners -\u0026gt; Register an instance runner -\u0026gt; Show runner installation and registration instuctions 到你安裝 GitLab runner 的地方照著 Command to register runner 執行 \\\n# Windows 執行 .\\gitlab-runner.exe register --url \u0026lt;GitLab_Url\u0026gt; --registration-token \u0026lt;admin_registration_token\u0026gt; 有看到以下代表成功 現在你創新的專案都可以看到這個 Runner Specific runners (專門給某個 Project 去做使用) 先到 project 下 CI/CD -\u0026gt; Jobs -\u0026gt; Creata CI/CD configuration file 之後你就能在你的 Project 下看到多了一個 .gitlab-ci.yml 這個就是用來跟 GitLab Runner 你這專案什麼時候會觸發 CI/CD 並且該做什麼動作等等\u0026hellip; 在 Server 中安裝完 GitLab 之後到 Project -\u0026gt; settings -\u0026gt; CI/CD -\u0026gt; Runners 跟著指令下就可以連結起 Gitlab Runner 跟 GitLab 兩者了 連接好之後就能看到下面會有多一個 Assigned project runners 這樣就代表有連結成功了 register 連接說明 : # Enter the GitLab instance URL ( for example, https://gitlab.com/ )：輸入 GitLab-Url\nEnter the registration token：輸入 admin-registration-token\nEnter tags for the runner (comma-separated)：你 CI/CD 是哪個 Tag 才能使用它\nEnter optional maintenance note for the runner：runner 說明\nEnter an executor: virtualbox, docker-autoscaler, instance, kubernetes, custom, docker-windows, shell, ssh, docker, parallels, docker+machine：輸入你要使用的類型\n遇到問題: # 無法執行沒有 Tag 的 CI/CD 先進到 Runner 設定 Run untagged jobs 打勾 Runner 架在 Windows 無法順利執行 Runner 需修改 GitLab-Runner 資夾下的 config.toml 檔 \u0026ldquo;pwsh\u0026rdquo; -\u0026gt; \u0026ldquo;powershell\u0026rdquo; Reference # Day04 - GitLab CI 設計出自己的工作流程 - 流水線分析建立 .gitlab-ci.yml 概述\n自架GitLab - 為GitLab添加Runner\nGitlab CI/CD 介紹與 Runner 的架設\ngitlab runner 的三种类型，创建以及使用\nDay 28 GitLab Runner - 安裝起來分配工作吧！\ngitlab-runner: prepare environment failed to start process pwsh in windows - Stack Overflow\n","date":"2023年06月17日","externalUrl":null,"permalink":"/zh-tw/posts/gitlab-runner/","section":"Posts","summary":"\u003cp\u003e本文講述 Gitlab Runner 的各種類別與建立使用方法!!\u003c/p\u003e","title":"Gitlab Runner","type":"posts"},{"content":"","date":"2023年05月12日","externalUrl":null,"permalink":"/zh-tw/tags/giscus/","section":"Tags","summary":"","title":"Giscus","type":"tags"},{"content":"","date":"2023年05月12日","externalUrl":null,"permalink":"/zh-tw/categories/hugo/","section":"Categories","summary":"","title":"Hugo","type":"categories"},{"content":"本篇文章是自己記錄下來如何自己修改 hugo-tranquilpeak-theme 添加自己需要的 Giscus 留言板！\n當初網站建好留言板得部分我考慮了很久要用哪個，很多人說 Disqus 會脫慢網站速度，後來就看到 Gitalk 和 Utterances，不過查了老半天突然看到一個另我心動的留言板可以用 emoji 反應在留言板上，覺得超酷超有趣而且還是接在 Github 上就直接選用這個了XD\n建立個人網站留言的儲存庫 並 啟用giscus # 先在 Github 上新建一個 repository，名字取你想要的，並將儲存庫設定為 Public 否則訪客將無法查看 discussion。 安裝 giscus 應用程式，否則訪客將無法留言或回應。 接下來會看到選擇你是要給 giscus 權限是 全部的專案 還是 選擇的專案，我自己是選擇自己剛剛建的那個新的 repository。\n如果選錯可以到 頭像 -\u0026gt; Integrations -\u0026gt; Applications -\u0026gt; giscus -\u0026gt; configure 去調整 到剛剛新建的 repository 下的 Setting -\u0026gt; Features 勾選 Discussions 啟用它。\n之後到 giscus.app 輸入並勾選一些資訊，勾選完輸入完之後就可以在下面啟用 giscus部分看到可以嵌入留言板的code 下面的可以不用照著我的勾選，可以依照你的需求與喜好去做選擇 修改 Hugo theme # 這邊要先說一下每個 Hugo theme 裡面的config.tomal跟一些擺放資料的位置或方法會有些許不一樣\nhugo-tranquilpeak-theme 的改法：\n之後到 hugo web 的資料夾下找到 config.tomal 添加下面的 Code [params.comment.giscus] enable = true 之後到 layouts/partials/post 找到 comment.html，到最下面{{END}}上面添加以下的Code {{ else if .Site.Params.comment.giscus.enable }} 剛剛在 giscus.app 啟用 giscus 的 code 貼過來 nunocoracao/blowfish 的改法：\n在 layouts/partials 下，建一份文件 comments.html\n貼上剛剛在 giscus.app 啟用 giscus 的 code\n就完成拉！現在拉到你的個人網頁下因該就會有這個樣子的留言板了 Reference # 安裝Giscus作為Hugo網站的留言板，支援轉換Gitalk/Utterances的留言 Giscus官方協助安裝網頁\n","date":"2023年05月12日","externalUrl":null,"permalink":"/zh-tw/posts/hugo-giscus/","section":"Posts","summary":"\u003cp\u003e本篇文章是自己記錄下來如何自己修改 hugo-tranquilpeak-theme 添加自己需要的 Giscus 留言板！\u003c/p\u003e","title":"Hugo 加裝 Giscus 留言板","type":"posts"},{"content":"","date":"2023年05月12日","externalUrl":null,"permalink":"/zh-tw/tags/jenkins/","section":"Tags","summary":"","title":"Jenkins","type":"tags"},{"content":"本文講述如何使用 Docker 簡單搭建 Jenkins 服務，並紀錄過程！\n我們的環境是使用 Docker 來搭建，使用下面命令來下載 image 並跑起來服務！\nDocker :\ndocker run --name jenkins -d -p 8080:8080 -p 50000:50000 -v ${HOME}/docker/jenkins:/var/jenkins_home jenkins/jenkins 服務啟動好之後我們需要了解一下 Docker 相關操作不然等等會卡關\ndocker 操作 command : 查看目前有在啟動的 container. =\u0026gt; docker ps 查看全部 container. =\u0026gt; docker ps -a 進container bash =\u0026gt; docker exec -it \u0026lt;container_id or name\u0026gt; /bin/bash 進container root身分進 bash =\u0026gt; docker exec -u 0 -it \u0026lt;container_id or name\u0026gt; /bin/bash 服務啟動好之後我們開啟網頁輸入 http://localhost:8080 就能看到 Jenkins 了！ 先初始化我們的密碼 利用上面剛剛說的 command 就能進到container 底下之後輸入下面的 command 就可以看到初始化密碼了\ncat /var/jenkins_home/secrets/initialAdminPassword 之後我們就能安裝想安裝的 pluging , 並設置我們的帳號密碼\n如果後來忘記密碼QQ # 在使用 jenkins 的時候不小心把 admin 密碼忘記了，下面來修改找回 admin 密碼 Jenkins 專用的 user 資料存放在 JENKINS_HOME/users 目錄。每個user資料分別放在 users/xxx(各種用戶名) ，可以用 find 命令查找對應用戶的路徑：\n# find / -name config.xml /var/jenkins_home/jobs/peter_Test/config.xml /var/jenkins_home/config.xml /var/jenkins_home/users/admin_17608091780692632075/config.xml /var/jenkins_home/users/ziyu_13869244322503421338/config.xml /var/jenkins_home/users/frank_5101403968758794797/config.xml /var/jenkins_home/users/alan_10846704603041450940/config.xml /var/jenkins_home/users/peter_17697102942534321614/config.xml 打開忘記密碼的用戶文件夾，裏面有一個文件config.xml，在裏面找到 位置 把 位置的內容換成 #jbcrypt:$2a$10$DdaWzN64JgUtLdvxWIflcuQu2fgrrMSAMabF5TSrGK5nXitqK9ZMS 儲存，重新啓動 Jenkins container，然後輸入用戶名，密碼：111111 然後就OK了^^\nTroubleshooting： 如果有遇到在 Jenkins 想查用網頁查看文件但沒辦法看的朋友可以用下面方法解決但只是暫時的每次 Jenkins 重啟都要重做一遍。如果想永久解決可以看下面文章內有解決辦法 Jenkins首頁 =\u0026gt; Manage Jenkins =\u0026gt; ScriptConsole 輸入\nSystem.setProperty(\u0026#34;hudson.model.DirectoryBrowserSupport.CSP\u0026#34;,\u0026#34;sandbox allow-scripts; default-src \u0026#39;none\u0026#39;; img-src \u0026#39;self\u0026#39; data: ; style-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39; data: ; script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39; \u0026#39;unsafe-eval\u0026#39; ;\u0026#34;) 要按 2~3次 Run 才會有反應\nReference # 软件测试|Docker 上搭建持续集成平台 Jenkins - 腾讯云开发者社区-腾讯云 (tencent.com)\nJenkins忘记密码解决方法 windows/Linux - 簡書 (jianshu.com)\njenkins初始密碼忘記了+修改密碼 - 台部落 (twblogs.net)\nTroubleshooting # Configuring Content Security Policy - Jenkins\nJenkins error - Blocked script execution in . because the document\u0026rsquo;s frame is sandboxed and the \u0026lsquo;allow-scripts\u0026rsquo; permission is not set\nWhere is jenkins.xml in jenkins docker container\n","date":"2023年05月12日","externalUrl":null,"permalink":"/zh-tw/posts/jenkins-build/","section":"Posts","summary":"\u003cp\u003e本文講述如何使用 Docker 簡單搭建 Jenkins 服務，並紀錄過程！\u003c/p\u003e","title":"Jenkins 環境搭建","type":"posts"},{"content":"","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/tags/fly.io/","section":"Tags","summary":"","title":"Fly.io","type":"tags"},{"content":"","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/tags/line-notify/","section":"Tags","summary":"","title":"Line Notify","type":"tags"},{"content":"本篇文章是因為 Heroku 的免費制度結束，只好把 Service 搬遷到 Fly.io 的故事。\nLINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 原本想說 Line Notify 系列可以結束了，結果沒想到 Heroku 竟然說 2022/11/28 要結束免費方案 OMG！所以只好找了一下其他可以搬家的地方找來找去發現 Fly.io 好像滿不錯的？用起來跟 Heroku 滿像的。 其實有很多可以搬的地方 Ex: Elastic Beanstalk、Netlify、Google App Engine、Render、Railway、Fly.io \u0026hellip; 本次搬家地方：https://fly.io/ 進去就先創建帳號然後綁個信用卡，我看一些文章之前好像不用綁信用卡不知道是不是現在因為太多免費仔所以要綁了？ 他現在知道很多人要從 Heroku 轉出來所以有出這 Turbocharge Your Heroku App with Fly 我看文件因該是，按一按就能把 Heroku 上的資料轉移到 Fly.io 上去運行之後你只要在 Heroku 那邊修改這邊好像會自動同步過來？ 因為我覺得之後還要從 Heroku 那邊上傳很麻煩我就在 Fly.io 創一個一樣的專案就好了！ 我們要用 Fly.io 要先裝他的 Flyctl 去讓我們可以部署專案，我們可以透過官方文章去安裝\n先登入Fly.io =\u0026gt; flyctl auth login\n先創一個資料夾並把我們資料放進去並在此資料夾下執行 Command 我們可以看到 fly.toml 是我們沒有的其他都是我們原本就有的，沒關西因為等等創建專案時 flyctl 會幫你補上。\n使用指令創建專案後並初次佈署\n創建專案指令：flyctl launch 部署指令：fly deploy 過程看得懂英文因該都不難理解不懂就照我圖片做ㄅ。 ? Would you like to set up a Postgresql database now? 比較要注意的是你如果需要用到他的 database 服務這邊請打 yes 專案建立完我們就有fly.toml檔了裡面有紀錄你的一些專案設置跟名稱\n接下來執行 fly deploy 基本上接下來他就會自動部屬了 部屬完我們就可以在 Dashboard 下看到我們的專案是不是很簡單啊！ 你因該部署完會說你的 Code 裡面有一些變數他沒辦法 get 到，但我們還沒設定完還記得之前 Heroku 有設定環境變數嗎？ 我們 Fly.io 也能設定 指令：\nfly secrets set \u0026lt;setting_name\u0026gt; = \u0026lt;your_input\u0026gt; 每次設定完他都會重新部屬所以都會跑很長一條，設定完後基本上就能像之前一樣使用但記得 Line bot 跟 Line Notify 的 callback 網址要去修改喔！！\n最後我要抱怨一下好像是很多人搬到這平台它 deploy 常常會沒辦法正常 deploy 上去，還要看運氣，我第一天用基本上完全無法完整的部署上去我是到隔天早上再試一次才行的。還在想是否要換到別的平台是還是在等等看這平台能不能解決，不過至少這平台的論壇是很多人的而且回的也很快有興趣可以看看有沒有人遇到一樣的問題！ 有問題或有不懂的可以私訊或留言給我，我有空就會看唷！！\nUpdate：LINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 # 目前我是先把通知服務串在 Discord 上，看了一下比較有機會取代的因該是使用 Telegram Bot + Google App Script 取代。 有興趣可以看這系列文章： 利用Google App Script 實作Telegram Bot 系列 - iT邦幫忙\nReference # 平台參考：\nTop 10 Alternatives to Heroku in 2022\n5 個替代 Heroku 的平台免費測試執行\n部署參考：\nHeroku 替代方案 - Fly.io 平台之 ASP.NET Core 部署筆記\nHeroku 的替代方案？ Fly.io 平台 — Python Flask 實際範例\n","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/posts/line-bot-ex/","section":"Posts","summary":"\u003cp\u003e本篇文章是因為 Heroku 的免費制度結束，只好把 Service 搬遷到 Fly.io 的故事。\u003c/p\u003e","title":"Line Notify 搬家計畫","type":"posts"},{"content":"","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/categories/line_bot/","section":"Categories","summary":"","title":"Line_Bot","type":"categories"},{"content":"","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/tags/heroku/","section":"Tags","summary":"","title":"Heroku","type":"tags"},{"content":"本篇是前面三篇文章的綜合懶人包跟總結一下目前的架構與程式！！\nLINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 前情提要： # 本篇是這三篇文章的綜合懶人包！！如果中間有不太懂可以回去翻翻看這三篇～ 讓我們用 Python 開發一個 Line Bot Line Bot 之利用 Line Notify 突破限制吧！ Line Notify 建立資料庫並提供不休息的服務\n我們要最後做出來的架構會是下圖這樣，會是 Line_Bot + Line_Notify + Heroku + GoogleSheet 我們 Line Bot or Line Notify 等等\u0026hellip;，這邊就可以參考前面的文章創出一個基本的 Line Bot + Notify 然後設定一下 Heroku 這邊就不在贅述。 我們這邊的重點先放在理解整個 Line Bot 程式碼！！\n我們先從 route 這邊看\n@app.route(\u0026#34;/callback/notify\u0026#34;, methods=[\u0026#39;GET\u0026#39;]) def callback_notify(): #assert request.headers[\u0026#39;referer\u0026#39;] == \u0026#39;https://notify-bot.line.me/\u0026#39; code = request.args.get(\u0026#39;code\u0026#39;) state = request.args.get(\u0026#39;state\u0026#39;) # Get Access-Token client_id = os.environ[\u0026#39;NOTIFY_CLIENT_ID\u0026#39;] access_token = get_token(code, client_id, client_secret, redirect_uri) google_sheet(access_token) send_message(access_token,text_message=\u0026#34;你好\u0026#34;) #發訊息 return \u0026#39;恭喜完成 LINE Notify 連動！請關閉此視窗。\u0026#39; Q. 有些人會說這邊的 \u0026ldquo;/callback/notify\u0026rdquo; 用在哪裡？ A. 會在 Notify 裡的設定看到，Web 後端接收到這個 URL 的 \u0026ldquo;GET\u0026rdquo; 之後去觸發 Q. 我該如何新增功能？ A. 如果只是要新增利用文字去互動的功能的話只需要在下面增加就可以了\n@handler.add(MessageEvent, message=TextMessage) # 監聽當有新訊息時 def handle_message(event): global Group_id , User_id if event.message.text == \u0026#34;個人訂閱\u0026#34; : url = create_auth_link(event) # 回傳 url 給傳訊息的那 個人 or 群組 line_bot_api.reply_message(event.reply_token,TextSendMessage(text=url) ) # 這邊是利用 event 內的 user_id 去跟 Line 拿到使用者的當前 Line 使用的名子 Ex: Zi-Yu(林子育) User_id = line_bot_api.get_profile(event.source.user_id).display_name Group_id = \u0026#39;\u0026#39; elif event.message.text == \u0026#34;群組訂閱\u0026#34; : url = create_auth_link(event) line_bot_api.reply_message(event.reply_token,TextSendMessage(text=url) ) # 因為 event 內只會回傳個人訊息所以無法找到 Group 的名稱,所以只能改拿 Group 的 id Group_id = (event.source.group_id) # Group_id get! User_id = \u0026#39;\u0026#39; Q. 設定完後，我該如何在別的程式利用 Line Notify 傳訊息？ A. Python 的話套用這個函式就可以，傳送訊息。如果想要 Access Token 不寫死，就是收到人名再去 Google Sheet 搜尋相對應的 Access Token 就能摟！\n#利用notify發出訊息 #==============================================================================================# def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() #==============================================================================================# main: send_message(access_token, text_message) Q. Clock + Line Bot 同時使用導致我的 Heroku 時數爆了整麼辦？ A. 我也是後來才發現有這問題因為我是 30 天都是 24hr 讓他去開著，可是我的免費時數只有 1000hr 實在是不夠， 後來我就想到解決方法把 Clock.py 拿到一台永遠不關機的電腦上跑做到一樣的功能。 整麼解決呢？很簡單就是利用以下程式碼＋工作排程器 我們先在本地打一份 Clock 的 Python程式碼：\nfrom apscheduler.schedulers.blocking import BlockingScheduler from linebot import LineBotApi from linebot.models import TextSendMessage import urllib.request sched = BlockingScheduler() #利用notify發出訊息 def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() #定時去搓url讓服務不中斷 @sched.scheduled_job(\u0026#39;cron\u0026#39;, day_of_week=\u0026#39;mon-sun\u0026#39;, minute=\u0026#39;*/25\u0026#39;) def scheduled_job(): url = \u0026#34;https://\u0026lt;Your Heroku App Name\u0026gt;.herokuapp.com/\u0026#34; conn = urllib.request.urlopen(url) for key, value in conn.getheaders(): print(key, value) print(\u0026#34;戳一下\u0026#34;) 接下來在排程器設定每天執行 然後在動作的地方看要是直接執行python檔或是直接把命令寫成bat檔執行都可以摟！\n最後附上已經用好的模版GitHub： https://github.com/OKHand-Zy/Line-Bot_Module 下載下來後把Heroku資料夾內的檔案移出外面一層然後修改成自己的內容上傳Heroku就可以摟！\n裡面有些檔案裡面要換成自己的 App 名 或是 金鑰 要注意一下唷！\n還有 Heroku 的 環境值 也記得要設定！\\\n大家一起來打造出屬於自己的 Line Bot吧！！ 有問題或有不懂的可以私訊或留言給我，我有空就會看唷！！\n","date":"2023年02月04日","externalUrl":null,"permalink":"/zh-tw/posts/line-bot-end/","section":"Posts","summary":"\u003cp\u003e本篇是前面三篇文章的綜合懶人包跟總結一下目前的架構與程式！！\u003c/p\u003e","title":"Line Bot 懶人包 - 總結","type":"posts"},{"content":"本文是實作如何 Heroku 持續不間段服務 與 連結 Google Sheet 當作我們的資料庫。\nLINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 前情提要： # 繼之前 讓我們用 Python 開發一個 LineBot 跟 Line Bot 之利用 Line Notify 突破限制吧！，我們已經有了 Line Bot 跟 Line Notify 並串接好了，那我們之後就是要去紀錄這些 Access Token 是誰的，當需要傳送資料的時候就知道要傳給誰了！！\n不睡覺的服務： # 身為一個慣老闆下的社畜我也想當一下慣老闆的滋味，於是我們的服務是一直運作也是理所當然的吧！！ 這部分比較簡單原理大概就是因為 Heroku 每 25 分鐘如果沒人使用的話那個 APP 就會進入暫時性的休息，於是我們只要在 24 分的時候去戳一下自己的 Web 讓他以為有人叫他就可以讓他一直工作了。 我們先安裝一個套件 APScheduler =\u0026gt; pip install apscheduler 之後我們就可以製作我們的 clock.py，當然你要定時的去傳送訊息或是做一些事也能打在裡面。\n# clock.py from apscheduler.schedulers.blocking import BlockingScheduler import urllib.request sched = BlockingScheduler() #定時去搓url讓服務不中斷 @sched.scheduled_job(\u0026#39;cron\u0026#39;, day_of_week=\u0026#39;mon-sun\u0026#39;, minute=\u0026#39;*/25\u0026#39;) def scheduled_job(): url = \u0026#34;https://你的Heroku APP名字.herokuapp.com/\u0026#34; conn = urllib.request.urlopen(url) for key, value in conn.getheaders(): print(key, value) print(\u0026#34;戳一下\u0026#34;) sched.start() 我們有了 clock.py 之後我們也要修改一下 requirements.txt and Procfile requirements.txt =\u0026gt; 多加 APScheduler == 3.8.1 Procfile =\u0026gt; 多加 clock: python clock.py 加好之後上傳 Heroku 之後記得去開啟 Clock 才會啟用喔！！ 之後就能去看 Log 或是 app 狀態 觀察它是否一直有在運作。\n建立我們的資料庫 # 我遠本是想用 Heroku 內的資料庫可是我學了一下覺的很難用於是我就把目光轉到 Google Sheet 上了，對於我們只要儲存一些 Access Token 跟使用者名字是夠用的！！(如果想要用Heroku內的資料庫可以去看麥田捕手的文章連結在下面) 我們這邊就講要整麼利用 GoogleSheet 當我們的資料庫 先到 Google Cloud Platform 建立一份 Google Sheet 和一個 Google Sheet 的 API 身份 然後再去申請一下金鑰讓我們可以跟 Google Sheet 去做互動 申請憑證在：側邊欄裡的 API 和服務 =\u0026gt; 憑證 =\u0026gt; 服務帳戶旁邊的管理帳戶 =\u0026gt; 建立服務帳戶 憑證申請完之後會給你下載一個 jason 檔就是之後要引用的金鑰(請保存好沒了就要重申請！) 之後你會在服務帳戶那邊看到電子郵件之後我們去建立一個 GoogleSheet 並且分享編輯權限給這個 Email 安裝環境測試需要的套件 pygsheets 套件 =\u0026gt; pip3 install pygsheets 記得！第一篇有說的 Heroku 的設定檔(requirements.txt)也要加才入套件才能在 Heroku 上使用喔 之後我們就可以開始使用 Google Sheet 當我們的資料庫去做使用了 \\\n# 自己練習跟 Google Sheet 互動的程式碼 import pygsheets #給憑證 gc = pygsheets.authorize(service_file=\u0026#39;你的憑證位置\u0026#39;) # 開啟googlesheet # google sheet連結範例 = https://docs.google.com/spreadsheets/d/\u0026lt;docID\u0026gt;/edit#gid=\u0026lt;sheetID\u0026gt; sheet = gc.open_by_url( \u0026#39;https://docs.google.com/spreadsheets/d/\u0026lt;docID\u0026gt;/\u0026#39; ) #找到下方\u0026#34;工作表1\u0026#34;分頁並在裡面操作 wks = sheet.worksheet_by_title(\u0026#34;工作表1\u0026#34;) #暴力破解直列搜尋 (用來尋找這個人的userid並拿取相對應的accesstoken我們就能傳送訊息給指定的人) Count = int( wks.cell( \u0026#39;C1\u0026#39; ).value ) #人數 #在C1設定目前綁定人數並拿來當計數器 Userid = \u0026#34;\u0026#34; #先clear for i in range(1,Count ) : Userid = str(wks.cell( \u0026#39;A\u0026#39;+str(i) ).value) print(Userid) if Userid.value == \u0026#34;101112\u0026#34; : #找到1011112就做下面 print(\u0026#34;第\u0026#34;+str(i)+\u0026#34;個\u0026#34;) #顯示第幾個 print( wks.cell( \u0026#39;B\u0026#39;+str(i) ).value ) #顯示裡面得值 print(\u0026#34;ok\u0026#34;) break #拿到並跳出 #新增資料方式 (新增綁定人資料並統計人數,並讓下次可以跑進迴圈) wks.update_value(\u0026#39;A6\u0026#39;, \u0026#39;asderrgte231231564gh\u0026#39;) #新增資料 wks.update_value(\u0026#39;C1\u0026#39;, Count+1) #人數+1 A = wks.cell( \u0026#39;A6\u0026#39; ) print(A.value) #檢查新資料 Google sheet 該如何與 Python 運作跟上面的註冊詳細我一樣會把參考資料都放在下面(還不懂的可以看裡面教的比較詳細) 我知道我講的有點簡略如果都不行或是還有疑問就留言吧！如果我會，我就盡量回答！！ \\\nReference # Line Notify：\n賴田捕手 iT幫幫忙\n卡米狗 iT幫幫忙\nGoogle Sheet：\n[資料庫筆記] Python 串接 GoogleSheet 新增、讀取、更新和刪除\nPython 讀寫 Google Sheets 教學\n[Python爬蟲教學]解析如何串接Google Sheet試算表寫入爬取的資料\n","date":"2023年02月02日","externalUrl":null,"permalink":"/zh-tw/posts/line-bot3/","section":"Posts","summary":"\u003cp\u003e本文是實作如何 Heroku 持續不間段服務 與 連結 Google Sheet 當作我們的資料庫。\u003c/p\u003e","title":"Line Notify 建立資料庫並提供不休息的服務","type":"posts"},{"content":"本文主要是實作如何從基本的 Line Bot 串接 Line Notify，回傳出 URL 讓使用者去綁定達到可以去互動的效果！\nLINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 前情提要： # 繼之前 讓我們用Python開發一個LineBot 這篇文，我們已經有了一個基本的 Line Bot，但是 Line 有對 Line Bot 有給免費仔們做一些限制(Ex：每個月主動發送訊息(push_message)只能發送500則訊息，回傳訊息(reply_message)不受限制)，那我們要如何突破他的上限呢？ 那就是利用有官方認證的 Line Notify 去幫我們發送訊息，因為是官方認證的帳號所以可以無限發送訊息重點是還免費啊！ 正題： # 建立個人 Line Notify： 我們要先去 Line Notify 去申請一個我們的 Line Notify ！ 登入之後 =\u0026gt; 右上點你的 Account =\u0026gt; 管理登入服務 =\u0026gt; 下面的登入服務 =\u0026gt; 創建你的 Line Notify 裡面有一個要注意的是 Callback URL 這個，這邊要填入你的 webhook 這樣之後他才能跟我們的程式去做互動。 Ex: https://你的Heroku APP名字.herokuapp.com/callback/notify 讓 Line Bot 發送訊息讓使用者 跟 LineNotify 綁定 ： # 創造綁定的URL： 我們剛剛有了我們創好的 Line Notify，之後我們要叫使用者去綁定我們的 Line Notify 這樣之後才能對使用者發送訊息！ 在剛剛你創好的 Line Notify 裡看到 Client ID 與 Client Secret 接下來就是用程式創造出我們的URL讓使用者去綁定！ \\\n# 創造URL程式碼： # 這邊的 os.environ 就是把資料從 Heroku 的設定檔那邊找到並拿下來用，不知道整麼用的可以看上一篇 # 這段程式碼主要是會回傳一串 URL 這時候就能跟我們上次的 LineBot 去做結合直接回傳回去給使用者去做綁定！ line_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) import os, urllib client_id = os.environ[\u0026#39;NOTIFY_CLIENT_ID\u0026#39;] client_secret = os.environ[\u0026#39;NOTIFY_CLIENT_SECRET\u0026#39;] redirect_uri = f\u0026#34;https://{os.environ[\u0026#39;YOUR_HEROKU_APP_NAME\u0026#39;]}.herokuapp.com/callback/notify\u0026#34; def create_auth_link(user_id, client_id=client_id, redirect_uri=redirect_uri): data = { \u0026#39;response_type\u0026#39;: \u0026#39;code\u0026#39;, \u0026#39;client_id\u0026#39;: client_id, \u0026#39;redirect_uri\u0026#39;: redirect_uri, \u0026#39;scope\u0026#39;: \u0026#39;notify\u0026#39;, \u0026#39;state\u0026#39;: user_id } query_str = urllib.parse.urlencode(data) return f\u0026#39;https://notify-bot.line.me/oauth/authorize?{query_str}\u0026#39; 回傳給 Line Notify 並拿取使用者 Access Token # 我們前面有了 URL 之後就能透過 URL 去做綁定並跟 Line 去做溝通要使用者的 Access Token，我們以後只要透過這個 Access Token 就能傳訊息給我們的使用者或群組惹！\n# 監聽綁定回傳跟綁定完成會發送你好的訊息程式碼 from flask import request @app.route(\u0026#34;/callback/notify\u0026#34;, methods=[\u0026#39;GET\u0026#39;]) def callback_notify(): #assert request.headers[\u0026#39;referer\u0026#39;] == \u0026#39;https://notify-bot.line.me/\u0026#39; code = request.args.get(\u0026#39;code\u0026#39;) state = request.args.get(\u0026#39;state\u0026#39;) #print(\u0026#34;Code:\u0026#34;+code) #print(\u0026#34;state:\u0026#34;+state) #print(event.source.group_id) # Get Access-Token access_token = get_token(code, client_id, client_secret, redirect_uri) #print(\u0026#34;AccessToken=\u0026#34;+access_token) #print(\u0026#34;Clinet_id\u0026#34;+client_id) google_sheet(client_id,access_token) send_message(access_token,text_message=\u0026#34;你好\u0026#34;) #發訊息 return \u0026#39;恭喜完成 LINE Notify 連動！請關閉此視窗。\u0026#39; #拿取幫綁訂人的access_token import json def get_token(code, client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri): url = \u0026#39;https://notify-bot.line.me/oauth/token\u0026#39; headers = { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39; } data = { \u0026#39;grant_type\u0026#39;: \u0026#39;authorization_code\u0026#39;, \u0026#39;code\u0026#39;: code, \u0026#39;redirect_uri\u0026#39;: redirect_uri, \u0026#39;client_id\u0026#39;: client_id, \u0026#39;client_secret\u0026#39;: client_secret } data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() res = json.loads(page.decode(\u0026#39;utf-8\u0026#39;)) #print(data) return res[\u0026#39;access_token\u0026#39;] #利用notify發出訊息 def send_message(access_token, text_message): url = \u0026#39;https://notify-api.line.me/api/notify\u0026#39; headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer \u0026#34;+ access_token} data = {\u0026#39;message\u0026#39;: text_message} data = urllib.parse.urlencode(data).encode() req = urllib.request.Request(url, data=data, headers=headers) page = urllib.request.urlopen(req).read() 這樣基本就完成了 LineBot 讓使用者綁定 Line Notify 了，之後就用下面的函式(send_message)就能把你想要發送的訊息給你指定的群組或使用者了！\n我知道我講的有點簡略，但可以搭配下面前輩的文章一起參考喔！ 如果都不行或是還有疑問就留言吧！如果我會，我就盡量回答！！\nReference # Line Bot 費用方案\n賴田捕手 iT幫幫忙\n卡米狗 iT幫幫忙\n","date":"2023年02月02日","externalUrl":null,"permalink":"/zh-tw/posts/line-bot2/","section":"Posts","summary":"\u003cp\u003e本文主要是實作如何從基本的 Line Bot 串接 Line Notify，回傳出 URL 讓使用者去綁定達到可以去互動的效果！\u003c/p\u003e","title":"Line Bot 之利用 Line Notify 突破限制吧！","type":"posts"},{"content":"本文主要是實作如何從無到有一個簡單的 Line Bot 並把程式上傳到 Heroku 當一個 Service 可以去跟我們做簡單的互動。\nLINE 宣布將於 2025 年 3 月 31 日結束 LINE Notify 服務。 簡單的介紹： # 我們要做 Line Bot 前要先理解一些他們的傳送資料的方法和架構！ 簡單來說就是我們 User 傳送的資料 or 文字都會透過 LineBot-API 先傳到 Line，之後會轉傳到我們掛在 Heroku 上用 Python+Flask 建立的網頁，然後網頁收到請求後去執行對應的程式碼，再回傳回去 Line 並執行對應的動作(Ex：傳資料給 User )。\n註冊： # Line Bot 註冊：\n我們先去 Line Developers 創建我們的 Line Bot 先到我們的 Account 裡選擇 Products 然後選擇 Messaging API 然後點 Start Now 之後就開始填一些基本資料，有些資料可以不用填，這樣我們就有了基本的 LineBot 了。 之後就去註冊 Heroku，然後就可以建立一個 App，之後也是填一下資料就建立好了～ 程式與上傳： # 我們是用 Python+Flask 建構一個網頁掛在 Heroku 上並持續執行 上傳資料到 Heroku 需要安裝 Git 跟 HerokuCLI 我是用 Python 3.8.6 去開發此專案，如果需在本地進行測試環境需安裝一些要使用的套件，如果不需要本地測試就不用安裝摟～\npip install line-bot-sdk pip install Flask 之後就開始看我們的 Line Bot 程式碼了！\n# main.py # 初始化LINT BOT import os from flask import Flask from linebot import LineBotApi, WebhookHandler app = Flask(__name__) line_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) # 利用 handler 處理 LINE 觸發事件 from linebot.models import MessageEvent, TextMessage, TextSendMessage @handler.add(MessageEvent, message=TextMessage) def handle_message(event): line_bot_api.reply_message( event.reply_token, TextSendMessage(text=f\u0026#34;Hello {line_bot_api.get_profile(event.source.user_id).display_name}!\u0026#34;) ) # 利用 route 處理路由 from flask import request, abort from linebot.exceptions import InvalidSignatureError @app.route(\u0026#34;/callback\u0026#34;, methods=[\u0026#39;POST\u0026#39;]) def callback(): signature = request.headers[\u0026#39;X-Line-Signature\u0026#39;] body = request.get_data(as_text=True) app.logger.info(\u0026#34;Request body: \u0026#34; + body) try: handler.handle(body, signature) except InvalidSignatureError: abort(400) return \u0026#39;OK\u0026#39; 我們可以看到程式碼裡面有 CHANNEL_ACCESS_TOKEN 跟 CHANNEL_SECRET 都是在我們剛剛創 Line Bot 的地方可以看到，這個很重要先記著！ Channel secret 在 Basic Setting 下 Channel access token 在 Messaging API 下 之後就要回到 Heroku 的部分因為我們要上傳到 Heroku，我們先把環境設定與程式碼的部分搞定在上傳 我們要把程式上傳到 Heroku 需要幾個東西讓 Heroku 知道要我們要使用的套件與指定要跑的程式等等\u0026hellip; 要上傳Heroku有幾個必要的東西 Procfile，requirements.txt，runtime.txt 這三個設定檔跟你的主程式(main.py)。\nProcfile：主要是寫說你這個程式是什麼東西並主要執行的程式 我們要在裡面填上 web: gunicorn main:app –preload 說明要用 main 這個程式運行一個 app 並且是用 Gunicorn 搭建一個 Web 服務 等等上傳就可以在你的 Heroku 上看到 requirements.txt：這很重要！這是要把我們需要用到的 Library 去跟 Heroku 說，他會在上傳程式碼時一起把套件裝起來 這邊就列出我們需要用的 套件名字==版本\nFlask==2.0.2 gunicorn==19.9.0 line-bot-sdk==2.0.1 requests==2.27.1 psycopg2==2.9.3 numpy==1.19.4 Pillow==8.0.1 pygsheets==2.0.5 runtime.txt：這裡面是說明你要用什麼語言跟版本去執行程式，我使用的是 python-3.8.6 之後我們就照著 Heroku 裡 Deploy 下的步驟一步一步操作就能上傳程式碼到 Heroku 上了 過程跟上傳 Github 的方法87％像，之後我們剛剛可以看到程式碼裡有這兩句\nline_bot_api = LineBotApi(os.environ[\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;]) handler = WebhookHandler(os.environ[\u0026#39;CHANNEL_SECRET\u0026#39;]) 這邊用的 os.environ[\u0026lsquo;CHANNEL_ACCESS_TOKEN\u0026rsquo;]，是利用我們 Heroku 上設定環境變數並當你跟 Heroku 要的時候會吐出指定的東西給他那要整麼設定呢？ 在你的 Heroku App 裡的 Setting 可以看到 Config Vars 把旁邊的點開就能看到兩行可以輸入的東西，我們就在這邊輸入我們 LineBot 的資訊就不用把機密寫在程式裡摟！！ 安全吧！ 我們有了剛剛講的這三個檔案跟主程式(main.py)就可以上傳到你的 Heroku，並且去到 Heroku 設定一下環境設定 就回去剛剛的 LineBot 裡的 Webhook URL 填上 https://你heroku的APP名字.herokuapp.com/callback 按 Verify 正常過的話就是代表能用摟！！\nTrouble shooting # 先檢查 Webhook URL 是否有對到你的 HerokuAPP 再檢查 CHANNEL_ACCESS_TOKEN 跟 CHANNEL_SECRET 是否填對 如果你不覺的是 Heroku 的問題，也能改成直接寫在程式裡在本地執行程式去進行測試\nline_bot_api = LineBotApi(\u0026#39;CHANNEL_ACCESS_TOKEN\u0026#39;) Ex: line_bot_api = LineBotApi(\u0026#39;sdgfdfhfgjfgjerwer3534534\u0026#39;) handler = WebhookHandler(\u0026#39;CHANNEL_SECRET\u0026#39;) Ex: handler = WebhookHandler(\u0026#39;dsfdsf453465sdgsg\u0026#39;) 過來就是檢查上傳 Heroku 的資料是否都有，再檢查是否有上傳成功\n我知道我講的有點簡略，但可以搭配下面前輩的文章一起參考喔！ 如果都不行或是還有疑問就留言吧！如果我會，我就盡量回答！！\nReference # LINE Bot 系列文 — 什麼是 Webhook?\n賴田捕手 iT幫幫忙\n卡米狗 iT幫幫忙\n[ChatBot] 創造自己的 Line bot，第一次就上手！(1) — Line bot 架構及工具簡介\n","date":"2023年02月01日","externalUrl":null,"permalink":"/zh-tw/posts/line-bot1/","section":"Posts","summary":"\u003cp\u003e本文主要是實作如何從無到有一個簡單的 Line Bot 並把程式上傳到 Heroku 當一個 Service 可以去跟我們做簡單的互動。\u003c/p\u003e","title":"讓我們用 Python 開發一個 Line Bot","type":"posts"},{"content":"","externalUrl":null,"permalink":"/zh-tw/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/zh-tw/series/","section":"Series","summary":"","title":"Series","type":"series"}]