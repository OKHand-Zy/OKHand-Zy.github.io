<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLama on OKH@nd&#39;s Blog</title>
    <link>http://localhost:1313/zh-tw/tags/llama/</link>
    <description>Recent content in LLama on OKH@nd&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-tw</language>
    <copyright>© 2025 OKH@nd.ZiYu</copyright>
    <lastBuildDate>Thu, 02 May 2024 20:08:32 +0800</lastBuildDate><atom:link href="http://localhost:1313/zh-tw/tags/llama/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Ollama Deploy LLM</title>
      <link>http://localhost:1313/zh-tw/posts/ollama-deploy/</link>
      <pubDate>Thu, 02 May 2024 20:08:32 +0800</pubDate>
      
      <guid>http://localhost:1313/zh-tw/posts/ollama-deploy/</guid>
      <description>&lt;p&gt;此文章介紹如何從安裝 Nvidia 驅動到從 HuggingFace 下載的 LLM Model 使用 Ollama 啟動 LLM 並使用 OpenWeb ui 進行溝通的部署過程紀錄。&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
